<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>新日暮里的幻想乡</title>
  
  <subtitle>boy next door</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2018-07-15T23:17:42.718Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>wxy555123</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Tensorflow专题4：迁移学习(transfer learning)和微调fine-tune的区别及迁移学习代码实现</title>
    <link href="http://yoursite.com/2018/05/11/tensorflow/Tensorflow%E4%B8%93%E9%A2%984%EF%BC%9A%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0(transfer%20learning)%E5%92%8C%E5%BE%AE%E8%B0%83fine-tune%E7%9A%84%E5%8C%BA%E5%88%AB%E5%8F%8A%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/"/>
    <id>http://yoursite.com/2018/05/11/tensorflow/Tensorflow专题4：迁移学习(transfer learning)和微调fine-tune的区别及迁移学习代码实现/</id>
    <published>2018-05-10T16:11:27.000Z</published>
    <updated>2018-07-15T23:17:42.718Z</updated>
    
    <content type="html"><![CDATA[<p><strong>一：区别</strong></p><p>1：迁移学习是将已经学习到的知识应用到其他领域，比如通用的语音模型迁移到某个人的语音模型上。</p><p>​     <strong>迁移学习就是将一个问题上训练好的模型通过简单的调整使其适用于一个新的问题。</strong></p><p>​    <strong>例如利用ImageNet数据集上训练好的Inception-V3模型来解决一个新的图像分类问题，可以保留训练好的Inception-v3模型中所有卷积层的参数，只是替换最后一层全连接层，在最后这一层全连接层之前的网络层称为瓶颈层。而将新的图像通过训练好的卷积神经网络直到瓶颈层的过程可以看成是对图像进行特征提取的过程，瓶颈层输出再通过一个单层的全连接层神经网络可以很好的区分类别，所以有理由相信将瓶颈层的输出的节点向量可以被称为任何图像的更加精简且表达能力更强的特征向量。所以可以直接利用这个训练好的神经网络对图像进行特征提取，然后再将提取得到特征向量作为输入来训练一个新的单层全连接网络来处理分类问题。</strong></p><p>​    <strong>但是在数据量足够的情况下，迁移学习的效果不如完全重新训练，但是迁移学习所需要的训练时间和训练样本要远远小于训练完整的模型。</strong></p><p>​      比如把已经训练好的模型的某一层的输出拿出来，然后用一个svm、LR等分类，更好的去利用从某一层输出的特征（也叫知识），这也还是迁移学习的思想，如下前三个是transfer learning经常用到的方法。最后一个是finetune的思想。</p><p>把Alexnet里卷积层最后一层输出的特征拿出来，然后直接用SVM分类。这是Transfer Learning，因为你用到了Alexnet中已经学到了的 <strong>“知识”</strong>。把Vggnet卷积层最后的输出拿出来，用贝叶斯分类器分类。思想基本同上。甚至你可以把Alexnet、Vggnet的输出拿出来进行组合，自己设计一个分类器分类。这个过程中你不仅用了Alexnet的“知识”，也用了Vggnet的“知识”。<a href="https://github.com/Gogul09/flower-recognition（此方法实现代码）最后，你也可以直接使用" target="_blank" rel="noopener">https://github.com/Gogul09/flower-recognition（此方法实现代码）最后，你也可以直接使用</a> <strong>fine-tune</strong>这种方法，在Alexnet的基础上，重新加上全连接层，再去训练网络。</p><p>2：finetune（微调）：例子：在Alexnet的基础上，我们重新加上一个层再去训练网络，比如再加入一个全连接层，那就是先</p><p>固定前面的层，让新加的fc层的loss值降低到一个很低的值，再调低学习率，放开所有层一块去训练这样可以收敛到一个不错的效果。</p><p>3：所以我个人认为迁移学习直接将现有的或者从现有的模型中提取出来的有用的东西应用的另一个领域，不在进行训练之前的网络部分，只需要训练我们添加部分网络的部分，将迁移过来的模型的某一层的输出作为我们新增加网络部分的输入。</p><p>而finetune就是微调，思想是：<strong>利用原有模型的参数信息，作为我们要训练的新的模型的初始化参数，这个新的模型可以和原来一样也可以增添几个层（进行适当的调整）。</strong></p><p>4：传统的机器学习框架下，学习的任务是在给定充分训练数据集的基础上学习一个分类模型；然后利用这个学习到的模型来对测试文档进行分类和预测。然而，我们看到机器学习算法在当前web挖掘应用领域存在一个关键问题：一些新出现的领域中的大量训练数据非常难得到。web领域中大量新的数据不断涌现，从传统的新闻，网页，到图片，再到博客，播客等。传统的机器学习需要对每个领域都标定大量训练数据，这将会耗费大量的人力物力，而没有大量的标注数据，会使得很多与学习相关研究与应用无法开展，其次传统的机器学习假设训练数据与测试数据服从相同的数据分布。然而在很多情况下，这种相同分布不满足，通常可能发生的情况如训练数据过期。如果我们有大量的，在不同分布下的训练数据，完全丢弃这些数据也是非常浪费的，如何利用这些数据就是迁移学习主要解决的问题。</p><p>迁移学习可以从现有的数据中迁移知识，用来帮助将来的学习。</p><p>迁移学习的目标是将从一个环境中学到的知识用来帮助新环境中的学习任务，因此迁移学习不会想传统机器学习那样作同分布假设。</p><p>例子：一个会下象棋的人可以更容易的学会下围棋。</p><p>迁移学习目前分为一下三个部分：同构空间下基于实例的迁移学习；同构空间下基于特征的迁移学习；异构空间下的迁移学习。</p><p>基于实例的迁移学习有更强的知识迁移能力，基于特征的迁移学习具有更广规范的知识迁移能力；异构空间的迁移具有广泛的学习与扩展能力。</p><p>迁移学习即一种学习对另一种学习的影响，它广泛的存在于知识技能态度和行为的规范的学习中，任何一种学习都将受先验知识的影响，只要有学习就有迁移，迁移是学习的继续和巩固，优势提高和深化学习的条件，学习与迁移不可分割。</p><p>二：迁移学习实例</p><p>为了能够快速地训练好自己的花朵图片分类器，我们可以使用别人已经训练好的模型参数，在此基础之上训练我们的模型。这个便属于迁移学习。本文提供训练数据集和代码下载。 </p><p>原理：卷积神经网络模型总体上可以分为两部分，前面的卷积层和后面的全连接层。卷积层的作用是图片特征的提取，全连接层作用是特征的分类。我们的思路便是在inception-v3网络模型上，修改全连接层，保留卷积层。卷积层的参数使用的是别人已经训练好的，全连接层的参数需要我们初始化并使用我们自己的数据来训练和学习。</p><p><img src="/2018/05/11/tensorflow/Tensorflow专题4：迁移学习(transfer learning)和微调fine-tune的区别及迁移学习代码实现/Tensorflow专题4：迁移学习(transfer%20learning" alt="">和微调fine-tune的区别及迁移学习代码实现/2018-07-15-19-26-42.png)</p><p>上面inception-v3模型图红色箭头前面部分是卷积层，后面是全连接层。我们需要修改修改全连接层，同时把模型的最终输出改为5。</p><p>由于这里使用了tensorflow框架，所以，我们需要获取上图红色箭头所在位置的张量<code>BOTTLENECK_TENSOR_NAME</code>（最后一个卷积层激活函数的输出值，个数为2048）以及模型最开始的输入数据的张量<code>JPEG_DATA_TENSOR_NAME</code>。获取这两个张量的作用是，图片训练数据通过<code>JPEG_DATA_TENSOR_NAME</code>张量输入模型，通过<code>BOTTLENECK_TENSOR_NAME</code>张量获取通过卷积层之后的图片特征。</p><p>BOTTLENECK_TENSOR_SIZE = 2048</p><p>BOTTLENECK_TENSOR_NAME = ‘pool_3/_reshape:0’</p><p>JPEG_DATA_TENSOR_NAME = ‘DecodeJpeg/contents:0’</p><p>通过下面的代码加载模型，同时获取上面所述的两个张量。</p><p><img src="/2018/05/11/tensorflow/Tensorflow专题4：迁移学习(transfer learning)和微调fine-tune的区别及迁移学习代码实现/Tensorflow专题4：迁移学习(transfer%20learning" alt="">和微调fine-tune的区别及迁移学习代码实现/2018-07-15-19-27-04.png)</p><p>最后便是定义交叉熵损失函数。模型使用反向传播训练，而训练的参数并不是模型的所有参数，仅仅是全连接层的参数，卷积层的参数是不变的。</p><p>定义交叉熵损失函数。</p><p>cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=ground_truth_input)</p><p>cross_entropy_mean = tf.reduce_mean(cross_entropy)</p><p>train_step = tf.train.GradientDescentOptimizer(LEARNING_RATE).minimize(cross_entropy_mean)</p><p>那么接下来的是如何给我们的模型输入数据了，这里提供了几个操作数据的函数。由于训练数据集比较小，</p><p>先把所有的图片通过<code>JPEG_DATA_TENSOR_NAME</code>张量输入模型，然后获取<code>BOTTLENECK_TENSOR_NAME</code>张量的值并保存到硬盘中。</p><p>在模型训练的时候，从硬盘中读取所保存的<code>BOTTLENECK_TENSOR_NAME</code>张量的值作为全连接层的输入数据。因为一张图片可能会被使用多次。</p><p><img src="/2018/05/11/tensorflow/Tensorflow专题4：迁移学习(transfer learning)和微调fine-tune的区别及迁移学习代码实现/Tensorflow专题4：迁移学习(transfer%20learning" alt="">和微调fine-tune的区别及迁移学习代码实现/2018-07-15-19-27-25.png)</p><p>运行代码在到时候再去看我的pycharm中的trasform这个项目。</p><p>这个代码实现部分参考的是<a href="https://blog.csdn.net/liangyihuai/article/details/79219457这个博客的内容" target="_blank" rel="noopener">https://blog.csdn.net/liangyihuai/article/details/79219457这个博客的内容</a></p><p>完整代码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding=utf8</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"><span class="keyword">import</span> os.path</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.python.platform <span class="keyword">import</span> gfile</span><br><span class="line"></span><br><span class="line">BOTTLENECK_TENSOR_SIZE = <span class="number">2048</span><span class="comment">#最后一个卷积层激活函数输出值，个数是2048个1×1的</span></span><br><span class="line">BOTTLENECK_TENSOR_NAME = <span class="string">'pool_3/_reshape:0'</span><span class="comment">#张量获取通过卷积层之后的图片特征</span></span><br><span class="line">JPEG_DATA_TENSOR_NAME = <span class="string">'DecodeJpeg/contents:0'</span><span class="comment">#模型开始的输入数据的张量，张量输入</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">MODEL_DIR = <span class="string">'./inception_dec_2015'</span><span class="comment">#inception模型的闻之</span></span><br><span class="line">MODEL_FILE= <span class="string">'tensorflow_inception_graph.pb'</span><span class="comment">#模型文件的准确位置</span></span><br><span class="line"></span><br><span class="line">CACHE_DIR = <span class="string">'./bottleneck'</span><span class="comment">#最后一个卷积层输出的每一类的特征，这个要输入到fc中然后进行分类用的。</span></span><br><span class="line">INPUT_DATA = <span class="string">'./flower_photos'</span></span><br><span class="line"></span><br><span class="line">VALIDATION_PERCENTAGE = <span class="number">10</span><span class="comment">#</span></span><br><span class="line">TEST_PERCENTAGE = <span class="number">10</span><span class="comment">#验证集测试集都占10%</span></span><br><span class="line"></span><br><span class="line">LEARNING_RATE = <span class="number">0.01</span></span><br><span class="line">STEPS = <span class="number">4000</span></span><br><span class="line">BATCH = <span class="number">100</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_image_lists</span><span class="params">(testing_percentage, validation_percentage)</span>:</span></span><br><span class="line">    result = &#123;&#125;</span><br><span class="line">    sub_dirs = [x[<span class="number">0</span>] <span class="keyword">for</span> x <span class="keyword">in</span> os.walk(INPUT_DATA)]<span class="comment">#os.walk()方法的作用是在目录树中游走输出在目录中的文件名，向上或者向下。</span></span><br><span class="line">    is_root_dir = <span class="keyword">True</span></span><br><span class="line">    <span class="keyword">for</span> sub_dir <span class="keyword">in</span> sub_dirs:</span><br><span class="line">        <span class="keyword">if</span> is_root_dir:</span><br><span class="line">            is_root_dir = <span class="keyword">False</span></span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">        extensions = [<span class="string">'jpg'</span>, <span class="string">'jpeg'</span>, <span class="string">'JPG'</span>, <span class="string">'JPEG'</span>]</span><br><span class="line"></span><br><span class="line">        file_list = []</span><br><span class="line">        dir_name = os.path.basename(sub_dir)</span><br><span class="line">        <span class="keyword">for</span> extension <span class="keyword">in</span> extensions:</span><br><span class="line">            file_glob = os.path.join(INPUT_DATA, dir_name, <span class="string">'*.'</span> + extension)</span><br><span class="line">            file_list.extend(glob.glob(file_glob))</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> file_list: <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">        label_name = dir_name.lower()</span><br><span class="line"></span><br><span class="line">        <span class="comment">#初始化</span></span><br><span class="line">        training_images = []</span><br><span class="line">        testing_images = []</span><br><span class="line">        validation_images = []</span><br><span class="line">        <span class="keyword">for</span> file_name <span class="keyword">in</span> file_list:</span><br><span class="line">            base_name = os.path.basename(file_name)<span class="comment">#这个只是取回去文件名，去掉其路径</span></span><br><span class="line">            <span class="comment">#basename的作用是去掉目录的路径，只返回文件名，而dirname用于 去掉文件名，只返回目录所在的路径。os.split()的作用是返回路径名和文件名的元组</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 随机划分数据</span></span><br><span class="line">            chance = np.random.randint(<span class="number">100</span>)</span><br><span class="line">            <span class="keyword">if</span> chance &lt; validation_percentage:</span><br><span class="line">                validation_images.append(base_name)</span><br><span class="line">            <span class="keyword">elif</span> chance &lt; (testing_percentage + validation_percentage):</span><br><span class="line">                testing_images.append(base_name)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                training_images.append(base_name)</span><br><span class="line"></span><br><span class="line">        result[label_name] = &#123;</span><br><span class="line">            <span class="string">'dir'</span>: dir_name,</span><br><span class="line">            <span class="string">'training'</span>: training_images,</span><br><span class="line">            <span class="string">'testing'</span>: testing_images,</span><br><span class="line">            <span class="string">'validation'</span>: validation_images,</span><br><span class="line">        &#125;</span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_image_path</span><span class="params">(image_lists, image_dir, label_name, index, category)</span>:</span></span><br><span class="line">    label_lists = image_lists[label_name]</span><br><span class="line">    category_list = label_lists[category]</span><br><span class="line">    mod_index = index % len(category_list)</span><br><span class="line">    base_name = category_list[mod_index]</span><br><span class="line">    sub_dir = label_lists[<span class="string">'dir'</span>]</span><br><span class="line">    full_path = os.path.join(image_dir, sub_dir, base_name)</span><br><span class="line">    <span class="keyword">return</span> full_path</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_bottleneck_path</span><span class="params">(image_lists, label_name, index, category)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> get_image_path(image_lists, CACHE_DIR, label_name, index, category) + <span class="string">'.txt'</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_bottleneck_on_image</span><span class="params">(sess, image_data, image_data_tensor, bottleneck_tensor)</span>:</span></span><br><span class="line"></span><br><span class="line">    bottleneck_values = sess.run(bottleneck_tensor, &#123;image_data_tensor: image_data&#125;)</span><br><span class="line"></span><br><span class="line">    bottleneck_values = np.squeeze(bottleneck_values)</span><br><span class="line">    <span class="keyword">return</span> bottleneck_values</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_or_create_bottleneck</span><span class="params">(sess, image_lists, label_name, index, category, jpeg_data_tensor, bottleneck_tensor)</span>:</span></span><br><span class="line">    label_lists = image_lists[label_name]</span><br><span class="line">    sub_dir = label_lists[<span class="string">'dir'</span>]</span><br><span class="line">    sub_dir_path = os.path.join(CACHE_DIR, sub_dir)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(sub_dir_path): os.makedirs(sub_dir_path)</span><br><span class="line">    bottleneck_path = get_bottleneck_path(image_lists, label_name, index, category)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(bottleneck_path):</span><br><span class="line"></span><br><span class="line">        image_path = get_image_path(image_lists, INPUT_DATA, label_name, index, category)</span><br><span class="line"></span><br><span class="line">        image_data = gfile.FastGFile(image_path, <span class="string">'rb'</span>).read()</span><br><span class="line"></span><br><span class="line">        bottleneck_values = run_bottleneck_on_image(sess, image_data, jpeg_data_tensor, bottleneck_tensor)</span><br><span class="line"></span><br><span class="line">        bottleneck_string = <span class="string">','</span>.join(str(x) <span class="keyword">for</span> x <span class="keyword">in</span> bottleneck_values)</span><br><span class="line">        <span class="keyword">with</span> open(bottleneck_path, <span class="string">'w'</span>) <span class="keyword">as</span> bottleneck_file:</span><br><span class="line">            bottleneck_file.write(bottleneck_string)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> open(bottleneck_path, <span class="string">'r'</span>) <span class="keyword">as</span> bottleneck_file:</span><br><span class="line">            bottleneck_string = bottleneck_file.read()</span><br><span class="line">        bottleneck_values = [float(x) <span class="keyword">for</span> x <span class="keyword">in</span> bottleneck_string.split(<span class="string">','</span>)]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> bottleneck_values</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_random_cached_bottlenecks</span><span class="params">(sess, n_classes, image_lists, how_many, category, jpeg_data_tensor, bottleneck_tensor)</span>:</span></span><br><span class="line">    bottlenecks = []</span><br><span class="line">    ground_truths = []</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> range(how_many):</span><br><span class="line">        label_index = random.randrange(n_classes)</span><br><span class="line">        label_name = list(image_lists.keys())[label_index]</span><br><span class="line">        image_index = random.randrange(<span class="number">65536</span>)</span><br><span class="line">        bottleneck = get_or_create_bottleneck(</span><br><span class="line">            sess, image_lists, label_name, image_index, category, jpeg_data_tensor, bottleneck_tensor)</span><br><span class="line">        ground_truth = np.zeros(n_classes, dtype=np.float32)</span><br><span class="line">        ground_truth[label_index] = <span class="number">1.0</span></span><br><span class="line">        bottlenecks.append(bottleneck)</span><br><span class="line">        ground_truths.append(ground_truth)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> bottlenecks, ground_truths</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_test_bottlenecks</span><span class="params">(sess, image_lists, n_classes, jpeg_data_tensor, bottleneck_tensor)</span>:</span></span><br><span class="line">    bottlenecks = []</span><br><span class="line">    ground_truths = []</span><br><span class="line">    label_name_list = list(image_lists.keys())</span><br><span class="line">    <span class="keyword">for</span> label_index, label_name <span class="keyword">in</span> enumerate(label_name_list):</span><br><span class="line">        category = <span class="string">'testing'</span></span><br><span class="line">        <span class="keyword">for</span> index, unused_base_name <span class="keyword">in</span> enumerate(image_lists[label_name][category]):</span><br><span class="line">            bottleneck = get_or_create_bottleneck(sess, image_lists, label_name, index, category,jpeg_data_tensor, bottleneck_tensor)</span><br><span class="line">            ground_truth = np.zeros(n_classes, dtype=np.float32)</span><br><span class="line">            ground_truth[label_index] = <span class="number">1.0</span></span><br><span class="line">            bottlenecks.append(bottleneck)</span><br><span class="line">            ground_truths.append(ground_truth)</span><br><span class="line">    <span class="keyword">return</span> bottlenecks, ground_truths</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    image_lists = create_image_lists(TEST_PERCENTAGE, VALIDATION_PERCENTAGE)</span><br><span class="line">    n_classes = len(image_lists.keys())</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 读取已经训练好的Inception-v3的模型</span></span><br><span class="line">    <span class="keyword">with</span> gfile.FastGFile(os.path.join(MODEL_DIR, MODEL_FILE), <span class="string">'rb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        graph_def = tf.GraphDef()</span><br><span class="line">        graph_def.ParseFromString(f.read())</span><br><span class="line">    bottleneck_tensor, jpeg_data_tensor = tf.import_graph_def(</span><br><span class="line">        graph_def, return_elements=[BOTTLENECK_TENSOR_NAME, JPEG_DATA_TENSOR_NAME])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 定义新的神经网络输入</span></span><br><span class="line">    bottleneck_input = tf.placeholder(tf.float32, [<span class="keyword">None</span>, BOTTLENECK_TENSOR_SIZE], name=<span class="string">'BottleneckInputPlaceholder'</span>)</span><br><span class="line">    ground_truth_input = tf.placeholder(tf.float32, [<span class="keyword">None</span>, n_classes], name=<span class="string">'GroundTruthInput'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 定义一个权链接层</span></span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">'final_training_ops'</span>):</span><br><span class="line">        weights = tf.Variable(tf.truncated_normal([BOTTLENECK_TENSOR_SIZE, n_classes], stddev=<span class="number">0.001</span>))</span><br><span class="line">        biases = tf.Variable(tf.zeros([n_classes]))</span><br><span class="line">        logits = tf.matmul(bottleneck_input, weights) + biases</span><br><span class="line">        final_tensor = tf.nn.softmax(logits)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 定义交叉商损失函数</span></span><br><span class="line">    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=ground_truth_input)</span><br><span class="line">    cross_entropy_mean = tf.reduce_mean(cross_entropy)</span><br><span class="line">    train_step = tf.train.GradientDescentOptimizer(LEARNING_RATE).minimize(cross_entropy_mean)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算准确率</span></span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">'evaluation'</span>):</span><br><span class="line">        correct_prediction = tf.equal(tf.argmax(final_tensor, <span class="number">1</span>), tf.argmax(ground_truth_input, <span class="number">1</span>))</span><br><span class="line">        <span class="comment">#tf.argmax()的用法，tf.argmax(final_tensor,1)返回的是final_tensor中，值最大的一个值，1在这里是指的返回一个值</span></span><br><span class="line">        <span class="comment">#final_tensor返回的是概率的大小，返回的是概率的最大值作为最后的值</span></span><br><span class="line">        <span class="comment">#tf.equal()的用法是比较tf.argmax(final_tensor, 1)和 tf.argmax(ground_truth_input, 1)对应位置的值是否相等，</span></span><br><span class="line">        <span class="comment">#相等的时候返回true，否则返回false，然后统计true多占的比列就是最后的准确率。</span></span><br><span class="line">        evaluation_step = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</span><br><span class="line">        <span class="comment">#tf.cast()的作用是改变数据类型的，改变correct_prediction的数据类型为float32</span></span><br><span class="line">        <span class="comment">#tf.reduce_mean（）的用法，在tensor的某一维度上，计算元素的平均值，由于输出的维度比原tensor降低了，所以也叫做降为。</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line"></span><br><span class="line">        sess.run(tf.global_variables_initializer())</span><br><span class="line">        <span class="comment"># 训练过程</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(STEPS):</span><br><span class="line"></span><br><span class="line">            train_bottlenecks, train_ground_truth = get_random_cached_bottlenecks(</span><br><span class="line">                sess, n_classes, image_lists, BATCH, <span class="string">'training'</span>, jpeg_data_tensor, bottleneck_tensor)</span><br><span class="line">            sess.run(train_step,</span><br><span class="line">                     feed_dict=&#123;bottleneck_input: train_bottlenecks, ground_truth_input: train_ground_truth&#125;)</span><br><span class="line">            <span class="comment">#这里是train_bottlenecks，从磁盘读入的张量值作为输入向量，来训练全链接层，</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> i % <span class="number">100</span> == <span class="number">0</span> <span class="keyword">or</span> i + <span class="number">1</span> == STEPS:</span><br><span class="line">                validation_bottlenecks, validation_ground_truth = get_random_cached_bottlenecks(</span><br><span class="line">                    sess, n_classes, image_lists, BATCH, <span class="string">'validation'</span>, jpeg_data_tensor, bottleneck_tensor)</span><br><span class="line">                validation_accuracy = sess.run(evaluation_step, feed_dict=&#123;</span><br><span class="line">                    bottleneck_input: validation_bottlenecks, ground_truth_input: validation_ground_truth&#125;)</span><br><span class="line">                print(<span class="string">'Step %d: Validation accuracy on random sampled %d examples = %.1f%%'</span> %</span><br><span class="line">                      (i, BATCH, validation_accuracy * <span class="number">100</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 在最后的测试数据上测试正确率</span></span><br><span class="line">        test_bottlenecks, test_ground_truth = get_test_bottlenecks(</span><br><span class="line">            sess, image_lists, n_classes, jpeg_data_tensor, bottleneck_tensor)</span><br><span class="line">        test_accuracy = sess.run(evaluation_step, feed_dict=&#123;</span><br><span class="line">            bottleneck_input: test_bottlenecks, ground_truth_input: test_ground_truth&#125;)</span><br><span class="line">        print(<span class="string">'Final test accuracy = %.1f%%'</span> % (test_accuracy * <span class="number">100</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:<span class="comment">#防止导入的包中的内容，也就是import 后面的内容也被运行</span></span><br><span class="line">    main()</span><br><span class="line">    <span class="comment">#python是脚本语言，不像编译语言一样，先将程序编译成二进制再运行 ，而是动态的逐行解释运行，也就是从脚本的第一行开始运行，没有统一的入口。</span></span><br><span class="line">    <span class="comment">#一个python源码除了可以直接运行外，还可以最为模块，也就是库导入，不管是导入还是运行，最顶层的代码都会被运行，python用缩进来区分代码层次，而</span></span><br><span class="line">    <span class="comment">#实际上在导入的时候，有一部分代码我们是不希望被运行的。</span></span><br><span class="line">    <span class="comment">#if __name__ =='main'就相当于程序的入口，python本身并没有规定这莫写，这只是一种编程习惯，由于模块之间相互引用，不同模块可能有这样的定义</span></span><br><span class="line">    <span class="comment">#，而入口程序只能有一个，到底那一额入口程序被选中，这就取决于 __name__的值。</span></span><br><span class="line">    <span class="comment">#__name__可以清晰的反映一个模块在包中的层次，其实，所谓模块的在包中的层次。__name__是内置变量，用于表示当前模块的名字，同时还能反映一个</span></span><br><span class="line">    <span class="comment">#包的结构，如果模块直接运行的，则代码被运行，如果模块被导入的，则代码不能运行。</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;一：区别&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;1：迁移学习是将已经学习到的知识应用到其他领域，比如通用的语音模型迁移到某个人的语音模型上。&lt;/p&gt;
&lt;p&gt;​     &lt;strong&gt;迁移学习就是将一个问题上训练好的模型通过简单的调整使其适用于一个新的问题。&lt;/s
      
    
    </summary>
    
      <category term="tensorflow" scheme="http://yoursite.com/categories/tensorflow/"/>
    
    
      <category term="transfer learning" scheme="http://yoursite.com/tags/transfer-learning/"/>
    
      <category term="fine-tune" scheme="http://yoursite.com/tags/fine-tune/"/>
    
  </entry>
  
  <entry>
    <title>Tensorflow专题3：模型优化策略</title>
    <link href="http://yoursite.com/2018/05/10/tensorflow/Tensorflow%E4%B8%93%E9%A2%983%EF%BC%9A%E6%A8%A1%E5%9E%8B%E4%BC%98%E5%8C%96%E7%AD%96%E7%95%A5/"/>
    <id>http://yoursite.com/2018/05/10/tensorflow/Tensorflow专题3：模型优化策略/</id>
    <published>2018-05-09T16:11:27.000Z</published>
    <updated>2018-05-11T16:55:13.531Z</updated>
    
    <content type="html"><![CDATA[<h2 id="初始化优化"><a href="#初始化优化" class="headerlink" title="初始化优化"></a>初始化优化</h2><ul><li>权值W使用：tf.random_truncated<br>偏置值b使用：0.1<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">W1 = tf.Variable(tf.truncated_normal([784,128], 0.,0.5))</span><br><span class="line">b1 = tf.Variable(tf.zeros([128]) + 0.1)</span><br></pre></td></tr></table></figure></li></ul><h2 id="过拟合优化"><a href="#过拟合优化" class="headerlink" title="过拟合优化"></a>过拟合优化</h2><ul><li>增加数据集</li><li>正则化</li><li>dropout：每次停用部分神经元<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># keep_prob是设置层L1工作神经元的百分比</span></span><br><span class="line">tf.nn.dopout(L1, keep_prob)</span><br></pre></td></tr></table></figure></li></ul><h2 id="收敛速度优化"><a href="#收敛速度优化" class="headerlink" title="收敛速度优化"></a>收敛速度优化</h2><ul><li>更改损失函数 loss，如交叉熵</li><li>更改优化器算法 optimizer，如自适应优化算法</li><li>更改学习率。如动态学习率</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;初始化优化&quot;&gt;&lt;a href=&quot;#初始化优化&quot; class=&quot;headerlink&quot; title=&quot;初始化优化&quot;&gt;&lt;/a&gt;初始化优化&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;权值W使用：tf.random_truncated&lt;br&gt;偏置值b使用：0.1&lt;figure class
      
    
    </summary>
    
      <category term="tensorflow" scheme="http://yoursite.com/categories/tensorflow/"/>
    
    
      <category term="模型优化" scheme="http://yoursite.com/tags/%E6%A8%A1%E5%9E%8B%E4%BC%98%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>Tensorflow专题2：优化器Optimizer</title>
    <link href="http://yoursite.com/2018/05/10/tensorflow/Tensorflow%E4%B8%93%E9%A2%982%EF%BC%9A%E4%BC%98%E5%8C%96%E5%99%A8Optimizer/"/>
    <id>http://yoursite.com/2018/05/10/tensorflow/Tensorflow专题2：优化器Optimizer/</id>
    <published>2018-05-09T16:11:27.000Z</published>
    <updated>2018-05-11T16:52:16.004Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一、优化器介绍"><a href="#一、优化器介绍" class="headerlink" title="一、优化器介绍"></a>一、优化器介绍</h1><h2 id="tensorflow优化器"><a href="#tensorflow优化器" class="headerlink" title="tensorflow优化器"></a>tensorflow优化器</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">tf.train.GradientDescentOptimizer</span><br><span class="line">tf.train.AdadeltaOptimizer</span><br><span class="line">tf.train.AdagradOptimizer</span><br><span class="line">tf.train.AdagradDAOptimizer</span><br><span class="line">tf.train.MomentumOptimizer</span><br><span class="line">tf.train.AdamOptimizer</span><br><span class="line">tf.train.FtrlOptimizer</span><br><span class="line">tf.train.ProximalGradientDescentOptimizer</span><br><span class="line">tf.train.ProximalAdagradOptimizer</span><br><span class="line">tf.train.RMSPropOptimizer1234567891011</span><br></pre></td></tr></table></figure><h2 id="1）GradientDescent梯度下降法"><a href="#1）GradientDescent梯度下降法" class="headerlink" title="1）GradientDescent梯度下降法"></a>1）GradientDescent梯度下降法</h2><h3 id="TF函数实现："><a href="#TF函数实现：" class="headerlink" title="TF函数实现："></a>TF函数实现：</h3><p><code>tf.train.GradientDescentOptimizer</code></p><p>设：<br>$h_W(x)=W_1x$，其参数是W_1，则其损失函数是：<br>$J(W_1)=\frac{1}{2m}\sum^{m}_{i=1}(h_W(x^{i})-y^{i})^2$<br>则W1W1通过如下求得：<br>$minimize\ J(W_1)$</p><p>标准梯度下降法：标准梯度下降先计算所有样本汇总误差，然后根据总误差来更新权值。<br>随机梯度下降法：随机梯度下降随机抽取一个样本来计算误差，然后更新权值。<br>批量梯度下降法：批量梯度下降算是一种折中的方案，从总样本中选取一个批次（比如一共有10000个样本，随机选取100个样本作为一个batch），然后计算这个batch的总误差，根据总误差来更新权值。</p><h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><p>1.合适的学习率，α 比较难获得<br>α 过大导致震荡无法得到最优解，过小导致学习过程漫长。<br>2.对所有参数学习率只有一个，如果数据是稀疏的，并且特征具有不同的频率时，更倾向于对不同频率特征使用不同的学习率，对很少发生的特征采用较大的学习率。<br>3.目标函数门限需要提前定义，一旦计算中小于门限就停止，数据调度训练的选择对其有影响，通常使用shuffle打断以减小这种影响。<br>4.高维非凸误差函数最小求解技术难度大。</p><h2 id="2）Momentum"><a href="#2）Momentum" class="headerlink" title="2）Momentum"></a>2）Momentum</h2><h3 id="TF函数实现：-1"><a href="#TF函数实现：-1" class="headerlink" title="TF函数实现："></a>TF函数实现：</h3><p><code>tf.train.MomentumOptimizer</code><br>动量法<br>ρ：动力通常设为 0.9</p><p>$W_t=ρW_{t-1}-η\nabla_W {J(W)}$<br>当前权值的改变会受到上一次全职改变的影响，类似小球向下滚动的时候带上了惯性。这样可以加快小球向下的速度。</p><h2 id="3）NAG（Nesterov-accelerated-gradient）"><a href="#3）NAG（Nesterov-accelerated-gradient）" class="headerlink" title="3）NAG（Nesterov accelerated gradient）"></a>3）NAG（Nesterov accelerated gradient）</h2><h3 id="TF函数实现：-2"><a href="#TF函数实现：-2" class="headerlink" title="TF函数实现："></a>TF函数实现：</h3><p><code>tf.train.MomentumOptimizer</code></p><p>$W_t=ρW_{t-1}-η\nabla_W {J(W-ρW_{t-1})}$<br>NAG在TF中跟Momentum合并在同一个函数tf.train.MomentumOptimizer中，可以通过参数配置启用。在Momentum中小球会盲目跟从下坡的梯度，容易发生错误，所以我们需要一个更聪明的小球，这个小球提前知道它要去哪里，它还要知道走到坡底的时候速度慢下来而不是又冲上另一个坡。我们可以提前计算下一个位置的梯度，然后使用到当前位置。</p><h2 id="4）Adagrad"><a href="#4）Adagrad" class="headerlink" title="4）Adagrad"></a>4）Adagrad</h2><h3 id="TF函数实现：-3"><a href="#TF函数实现：-3" class="headerlink" title="TF函数实现："></a>TF函数实现：</h3><p><code>tf.train.AdagradOptimizer</code><br><code>tf.train.AdagradDAOptimizer</code></p><p>Adagrad会累加之前所有的梯度平方。<br>$ΔW_t=-\frac η{\sqrt{\sum_{τ}^{t}g_τ^2+ϵ}}⨀g_t$<br>$W_{t+1}=W_t-\frac η{\sqrt{\sum_{τ}^{t}g_τ^2+ϵ}}⨀g_t$<br>通常上述的求和针对一个窗长w求解，以减小运算量。</p><p>它是基于SGD的一种算法，它的核心思想是对比比较常见的数据给予它比较小的学习率去调整参数，对于比较罕见的数据给予它较大的学习率去调整参数。它很适合应用于数据稀疏的数据集（比如一个图片的数据集，有10000张狗的照片，10000张猫的照片，只有100张大象的照片）。<br>Adagrad主要的优势在于不需要人为的调节学习率，它可以自动调节。它的缺点在于，随着迭代次数的增多，学习率也会越来越低，最终会趋向于0。</p><h2 id="5）RMSprop"><a href="#5）RMSprop" class="headerlink" title="5）RMSprop"></a>5）RMSprop</h2><h3 id="TF函数实现：-4"><a href="#TF函数实现：-4" class="headerlink" title="TF函数实现："></a>TF函数实现：</h3><p><code>tf.train.RMSPropOptimizer</code></p><p>$E|g^2|_t=0.9E|g^2|_{t-1}+0.1g^2_t$<br>$W_{t+1}=W_t-\frac η{\sqrt {E|g2|_t+ϵ}}⨀g_t$<br>学习速率梯度均方根均值指数衰减。</p><p>RMSprop借鉴了一些Adagrad的思想，不过这里RMSprop只用到了前t-1次梯度平方的平均值加上当前梯度的平方的和的开平方作为学习率的分母。这样RMSprop不会出现学习率越来越低的问题，而且也能自己调节学习率，并且可以有一个比较好的效果。</p><h2 id="6）Adadelta"><a href="#6）Adadelta" class="headerlink" title="6）Adadelta"></a>6）Adadelta</h2><h3 id="TF函数实现：-5"><a href="#TF函数实现：-5" class="headerlink" title="TF函数实现："></a>TF函数实现：</h3><p><code>tf.train.AdadeltaOptimizer</code></p><p>该算法不需要手动调优学习速率α，抗噪声能力强，可以选择不同的模型结构。<br>Adadelta是对Adagrad的扩展。Adadelta只累加固定大小的项，并且也不直接存储这些项，仅仅是计算对应的平均值。<br>上一节的参数更新模型是：<br>$W_{t+1}=W_t - α\frac{dJ(W)}{dW_t}$<br>为方便，把$\frac{dJ(W)}{dW_t}$记作$g_t$，把平滑后的梯度记作$E|g|_t$,则其平方表示如下：<br>$E|g^2|_t = ρE|g^2|_{t-1}+(1-ρ)g^2_t$<br>其中ρ是平滑/衰减因子。其均方根得到的该值如下：<br>$RMS|g|_t=\sqrt {E|g^2|_t+ϵ}$<br>其中ϵ是为了防止后续计算分母为零而引入的参数常量。<br>$ΔW=-\frac{RMS|ΔW|_{t-1}}{RMS|g|_t}g_t$<br>$W_t+1=W_t+ΔW_t$</p><h3 id="Adadelta-t时刻跟新过程如下："><a href="#Adadelta-t时刻跟新过程如下：" class="headerlink" title="Adadelta t时刻跟新过程如下："></a>Adadelta t时刻跟新过程如下：</h3><p>前提衰减因子ρ，常数ϵ，初始的W值。</p><p>1 计算变量E|g2|0=0E|g2|0=0，E|ΔW2|0=0E|ΔW2|0=0<br>2: for t=1:T do %%Loop over #of updates</p><blockquote><p>3: 计算梯度：$g_t $<br>4: 滑动平均梯度:$E|g^2|_t = ρE|g^2|_{t-1}+(1-ρ)g^2_t$</p><ol><li>计算参数跟新$ΔW=-\frac{RMS|ΔW|_{t-1}}{RMS|g|_t}g_t$</li><li>计算更新$E|Δx^2|_t=ρE|ΔW^2|_{t-1} + (1-ρ)W^2$</li><li>更新参数$W_{t+1}=W_t+ΔW_t$</li></ol></blockquote><p>8.end for</p><h2 id="7）Adam"><a href="#7）Adam" class="headerlink" title="7）Adam"></a>7）Adam</h2><h3 id="TF函数实现：-6"><a href="#TF函数实现：-6" class="headerlink" title="TF函数实现："></a>TF函数实现：</h3><p><code>tf.train.AdamOptimizer</code></p><p>Adam(Adaptive Moment Estimation)加上了bias校正和momentum，在优化末期，梯度更稀疏时，它比RMSprop稍微好点。<br>$m_t=β_1m_{t-1}+(1-β_1)g_t$<br>$v_t=β_2v_{t-1}+(1-β_2)g^2_t$<br>其中$m_t$是梯度均值，$v_t$是梯度偏方差。这两个值初始化时为0的张量。在训练开始时，$m_t$和$v_t$趋向于零。可以使用如下估计方法抵消：<br>$\hat m_t=\frac{m_t}{1-β^t_1}$<br>$\hat v_t=\frac {v_t}{1-β^t_2}$<br>$W_{t+1}=W_t-\frac η{\sqrt{\hat v_t+ϵ}}\hat m_t$<br>就像Adadelta和RMSprop一样Adam会存储之前衰减的平方梯度，同时它也会保存之前衰减的梯度。经过一些处理之后再使用类似Adadelta和RMSprop的方式更新参数。</p><h2 id="tf-train-FtrlOptimizer"><a href="#tf-train-FtrlOptimizer" class="headerlink" title="tf.train.FtrlOptimizer"></a>tf.train.FtrlOptimizer</h2><h2 id="tf-train-ProximalGradientDescentOptimizer"><a href="#tf-train-ProximalGradientDescentOptimizer" class="headerlink" title="tf.train.ProximalGradientDescentOptimizer"></a>tf.train.ProximalGradientDescentOptimizer</h2><h2 id="tf-train-ProximalAdagradOptimizer"><a href="#tf-train-ProximalAdagradOptimizer" class="headerlink" title="tf.train.ProximalAdagradOptimizer"></a>tf.train.ProximalAdagradOptimizer</h2><h2 id="其它梯度优化方法"><a href="#其它梯度优化方法" class="headerlink" title="其它梯度优化方法"></a>其它梯度优化方法</h2><p>1.数据重拍(shuffle函数)和数据多次重复训练<br>2.批量归一化，防止逐级训练中的梯度消失和溢出<br>3.提前终止，防止过拟合，监控验证数据集在训练中的损失，合适时提前终止。<br>4.增加高斯分布的梯度噪声，<br>$g_{t,i}=g_{t,i}+N(0,δ^2)$<br>$δ^2_t=\frac η{(1+t)^γ}$<br>这使得网络对初始化不敏感。</p><h1 id="二、总结"><a href="#二、总结" class="headerlink" title="二、总结"></a>二、总结</h1><h2 id="如何选用optimizer"><a href="#如何选用optimizer" class="headerlink" title="如何选用optimizer"></a>如何选用optimizer</h2><ul><li>对于稀疏数据：<br>使用学习率可自适应的优化方法如：RMSprop，不用手动调节，而且最好采用默认值 </li><li>追求精度：<br>SGD。虽然通常训练时间更长，容易陷入鞍点，但是在好的初始化和学习率调度方案的情况下，结果更可靠 </li><li>如果在意更快的收敛，并且需要训练较深较复杂的网络时：<br>推荐使用学习率自适应的优化方法，如：Adadelta，RMSprop，Adam是比较相近的算法，在相似的情况下表现差不多。NAG收敛也比较快。</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;一、优化器介绍&quot;&gt;&lt;a href=&quot;#一、优化器介绍&quot; class=&quot;headerlink&quot; title=&quot;一、优化器介绍&quot;&gt;&lt;/a&gt;一、优化器介绍&lt;/h1&gt;&lt;h2 id=&quot;tensorflow优化器&quot;&gt;&lt;a href=&quot;#tensorflow优化器&quot; class
      
    
    </summary>
    
      <category term="tensorflow" scheme="http://yoursite.com/categories/tensorflow/"/>
    
    
      <category term="Optimizer" scheme="http://yoursite.com/tags/Optimizer/"/>
    
  </entry>
  
  <entry>
    <title>Tensorflow专题1：生成随机数</title>
    <link href="http://yoursite.com/2018/05/01/tensorflow/Tensorflow%E4%B8%93%E9%A2%981%EF%BC%9A%E7%94%9F%E6%88%90%E9%9A%8F%E6%9C%BA%E6%95%B0/"/>
    <id>http://yoursite.com/2018/05/01/tensorflow/Tensorflow专题1：生成随机数/</id>
    <published>2018-05-01T12:51:27.000Z</published>
    <updated>2018-05-11T16:52:08.702Z</updated>
    
    <content type="html"><![CDATA[<h1 id="随机数函数-tf-random-normal-amp-tf-random-uniform-amp-tf-truncated-normal-amp-tf-random-shuffle"><a href="#随机数函数-tf-random-normal-amp-tf-random-uniform-amp-tf-truncated-normal-amp-tf-random-shuffle" class="headerlink" title="随机数函数 tf.random_normal &amp; tf.random_uniform &amp; tf.truncated_normal &amp; tf.random_shuffle"></a>随机数函数 tf.random_normal &amp; tf.random_uniform &amp; tf.truncated_normal &amp; tf.random_shuffle</h1><p><br></p><h2 id="tf-random-normal"><a href="#tf-random-normal" class="headerlink" title="tf.random_normal"></a>tf.random_normal</h2><p>从正态分布输出随机值。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">random_normal(shape,mean=<span class="number">0.0</span>,stddev=<span class="number">1.0</span>,dtype=tf.float32,seed=<span class="keyword">None</span>,name=<span class="keyword">None</span>)</span><br></pre></td></tr></table></figure><p>shape：一个一维整数张量或Python数组。代表张量的形状。<br>mean：数据类型为dtype的张量值或Python值。是正态分布的均值。<br>stddev：数据类型为dtype的张量值或Python值。是正态分布的标准差<br>dtype： 输出的数据类型。<br>seed：一个Python整数。是随机种子。<br>name： 操作的名称(可选)</p><h2 id="tf-random-uniform"><a href="#tf-random-uniform" class="headerlink" title="tf.random_uniform"></a>tf.random_uniform</h2><p>从均匀分布中返回随机值。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">random_uniform(  </span><br><span class="line">    shape,<span class="comment"># 生成的张量的形状  </span></span><br><span class="line">    minval=<span class="number">0</span>,  </span><br><span class="line">    maxval=<span class="keyword">None</span>,  </span><br><span class="line">    dtype=tf.float32,  </span><br><span class="line">    seed=<span class="keyword">None</span>,  </span><br><span class="line">    name=<span class="keyword">None</span>  </span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>返回值的范围默认是0到1的左闭右开区间，即[0，1)。minval为指定最小边界，默认为1。maxval为指定的最大边界，如果是数据浮点型则默认为1，如果数据为整形则必须指定。</p><h2 id="tf-truncated-normal"><a href="#tf-truncated-normal" class="headerlink" title="tf.truncated_normal"></a>tf.truncated_normal</h2><p>截断的正态分布函数。生成的值遵循一个正态分布，但如果生成的值大于平均值2个标准偏差的值则丢弃重新选择。<br>故，只取横轴区间（μ-2σ，μ+2σ）内的值，面积为95.449974%</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">truncated_normal(  </span><br><span class="line">    shape,<span class="comment">#一个一维整数张量或Python数组。代表张量的形状。  </span></span><br><span class="line">    mean=<span class="number">0.0</span>,<span class="comment">#数据类型为dtype的张量值或Python值。是正态分布的均值。  </span></span><br><span class="line">    stddev=<span class="number">1.0</span>,<span class="comment">#数据类型为dtype的张量值或Python值。是正态分布的标准差  </span></span><br><span class="line">    dtype=tf.float32,<span class="comment">#输出的数据类型。  </span></span><br><span class="line">    seed=<span class="keyword">None</span>,<span class="comment">#一个Python整数。是随机种子。  </span></span><br><span class="line">    name=<span class="keyword">None</span><span class="comment">#操作的名称(可选)  </span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><h2 id="tf-random-shuffle"><a href="#tf-random-shuffle" class="headerlink" title="tf.random_shuffle"></a>tf.random_shuffle</h2><p>沿着要被洗牌的张量的第一个维度，随机打乱。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">random_shuffle(  </span><br><span class="line">    value,<span class="comment"># 要被洗牌的张量  </span></span><br><span class="line">    seed=<span class="keyword">None</span>,  </span><br><span class="line">    name=<span class="keyword">None</span>  </span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>即下面这种效果：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">1</span>, <span class="number">2</span>],       [[<span class="number">5</span>, <span class="number">6</span>],  </span><br><span class="line"> [3, 4],  ==&gt;   [1, 2],  </span><br><span class="line"> [<span class="number">5</span>, <span class="number">6</span>]]        [<span class="number">3</span>, <span class="number">4</span>]]</span><br></pre></td></tr></table></figure></p><h2 id="附录1：生成随机数的操作的源码random-ops-py"><a href="#附录1：生成随机数的操作的源码random-ops-py" class="headerlink" title="附录1：生成随机数的操作的源码random_ops.py"></a>附录1：生成随机数的操作的源码random_ops.py</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># Copyright 2015 The TensorFlow Authors. All Rights Reserved.  </span></span><br><span class="line"><span class="comment">#  </span></span><br><span class="line"><span class="comment"># Licensed under the Apache License, Version 2.0 (the "License");  </span></span><br><span class="line"><span class="comment"># you may not use this file except in compliance with the License.  </span></span><br><span class="line"><span class="comment"># You may obtain a copy of the License at  </span></span><br><span class="line"><span class="comment">#  </span></span><br><span class="line"><span class="comment">#     http://www.apache.org/licenses/LICENSE-2.0  </span></span><br><span class="line"><span class="comment">#  </span></span><br><span class="line"><span class="comment"># Unless required by applicable law or agreed to in writing, software  </span></span><br><span class="line"><span class="comment"># distributed under the License is distributed on an "AS IS" BASIS,  </span></span><br><span class="line"><span class="comment"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  </span></span><br><span class="line"><span class="comment"># See the License for the specific language governing permissions and  </span></span><br><span class="line"><span class="comment"># limitations under the License.  </span></span><br><span class="line"><span class="comment"># ==============================================================================  </span></span><br><span class="line"><span class="string">"""Operations for generating random numbers."""</span>  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> absolute_import  </span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> division  </span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np  </span><br><span class="line"><span class="keyword">from</span> tensorflow.python.framework <span class="keyword">import</span> dtypes  </span><br><span class="line"><span class="keyword">from</span> tensorflow.python.framework <span class="keyword">import</span> ops  </span><br><span class="line"><span class="keyword">from</span> tensorflow.python.framework <span class="keyword">import</span> random_seed  </span><br><span class="line"><span class="keyword">from</span> tensorflow.python.ops <span class="keyword">import</span> array_ops  </span><br><span class="line"><span class="keyword">from</span> tensorflow.python.ops <span class="keyword">import</span> control_flow_ops  </span><br><span class="line"><span class="keyword">from</span> tensorflow.python.ops <span class="keyword">import</span> gen_random_ops  </span><br><span class="line"><span class="keyword">from</span> tensorflow.python.ops <span class="keyword">import</span> math_ops  </span><br><span class="line"><span class="comment"># go/tf-wildcard-import  </span></span><br><span class="line"><span class="comment"># pylint: disable=wildcard-import  </span></span><br><span class="line"><span class="keyword">from</span> tensorflow.python.ops.gen_random_ops <span class="keyword">import</span> *  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># pylint: enable=wildcard-import  </span></span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_ShapeTensor</span><span class="params">(shape)</span>:</span>  </span><br><span class="line">  <span class="string">"""Convert to an int32 or int64 tensor, defaulting to int32 if empty."""</span>  </span><br><span class="line">  <span class="keyword">if</span> isinstance(shape, (tuple, list)) <span class="keyword">and</span> <span class="keyword">not</span> shape:  </span><br><span class="line">    dtype = dtypes.int32  </span><br><span class="line">  <span class="keyword">else</span>:  </span><br><span class="line">    dtype = <span class="keyword">None</span>  </span><br><span class="line">  <span class="keyword">return</span> ops.convert_to_tensor(shape, dtype=dtype, name=<span class="string">"shape"</span>)  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># pylint: disable=protected-access  </span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">random_normal</span><span class="params">(shape,  </span></span></span><br><span class="line"><span class="function"><span class="params">                  mean=<span class="number">0.0</span>,  </span></span></span><br><span class="line"><span class="function"><span class="params">                  stddev=<span class="number">1.0</span>,  </span></span></span><br><span class="line"><span class="function"><span class="params">                  dtype=dtypes.float32,  </span></span></span><br><span class="line"><span class="function"><span class="params">                  seed=None,  </span></span></span><br><span class="line"><span class="function"><span class="params">                  name=None)</span>:</span>  </span><br><span class="line">  <span class="string">"""Outputs random values from a normal distribution. </span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">  Args: </span></span><br><span class="line"><span class="string">    shape: A 1-D integer Tensor or Python array. The shape of the output tensor. </span></span><br><span class="line"><span class="string">    mean: A 0-D Tensor or Python value of type `dtype`. The mean of the normal </span></span><br><span class="line"><span class="string">      distribution. </span></span><br><span class="line"><span class="string">    stddev: A 0-D Tensor or Python value of type `dtype`. The standard deviation </span></span><br><span class="line"><span class="string">      of the normal distribution. </span></span><br><span class="line"><span class="string">    dtype: The type of the output. </span></span><br><span class="line"><span class="string">    seed: A Python integer. Used to create a random seed for the distribution. </span></span><br><span class="line"><span class="string">      See </span></span><br><span class="line"><span class="string">      @&#123;tf.set_random_seed&#125; </span></span><br><span class="line"><span class="string">      for behavior. </span></span><br><span class="line"><span class="string">    name: A name for the operation (optional). </span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">  Returns: </span></span><br><span class="line"><span class="string">    A tensor of the specified shape filled with random normal values. </span></span><br><span class="line"><span class="string">  """</span>  </span><br><span class="line">  <span class="keyword">with</span> ops.name_scope(name, <span class="string">"random_normal"</span>, [shape, mean, stddev]) <span class="keyword">as</span> name:  </span><br><span class="line">    shape_tensor = _ShapeTensor(shape)  </span><br><span class="line">    mean_tensor = ops.convert_to_tensor(mean, dtype=dtype, name=<span class="string">"mean"</span>)  </span><br><span class="line">    stddev_tensor = ops.convert_to_tensor(stddev, dtype=dtype, name=<span class="string">"stddev"</span>)  </span><br><span class="line">    seed1, seed2 = random_seed.get_seed(seed)  </span><br><span class="line">    rnd = gen_random_ops._random_standard_normal(  </span><br><span class="line">        shape_tensor, dtype, seed=seed1, seed2=seed2)  </span><br><span class="line">    mul = rnd * stddev_tensor  </span><br><span class="line">    value = math_ops.add(mul, mean_tensor, name=name)  </span><br><span class="line">    <span class="keyword">return</span> value  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">ops.NotDifferentiable(<span class="string">"RandomStandardNormal"</span>)  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parameterized_truncated_normal</span><span class="params">(shape,  </span></span></span><br><span class="line"><span class="function"><span class="params">                                   means=<span class="number">0.0</span>,  </span></span></span><br><span class="line"><span class="function"><span class="params">                                   stddevs=<span class="number">1.0</span>,  </span></span></span><br><span class="line"><span class="function"><span class="params">                                   minvals=<span class="number">-2.0</span>,  </span></span></span><br><span class="line"><span class="function"><span class="params">                                   maxvals=<span class="number">2.0</span>,  </span></span></span><br><span class="line"><span class="function"><span class="params">                                   dtype=dtypes.float32,  </span></span></span><br><span class="line"><span class="function"><span class="params">                                   seed=None,  </span></span></span><br><span class="line"><span class="function"><span class="params">                                   name=None)</span>:</span>  </span><br><span class="line">  <span class="string">"""Outputs random values from a truncated normal distribution. </span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">  The generated values follow a normal distribution with specified mean and </span></span><br><span class="line"><span class="string">  standard deviation, except that values whose magnitude is more than 2 standard </span></span><br><span class="line"><span class="string">  deviations from the mean are dropped and re-picked. </span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">  Args: </span></span><br><span class="line"><span class="string">    shape: A 1-D integer Tensor or Python array. The shape of the output tensor. </span></span><br><span class="line"><span class="string">    means: A 0-D Tensor or Python value of type `dtype`. The mean of the </span></span><br><span class="line"><span class="string">      truncated normal distribution. </span></span><br><span class="line"><span class="string">    stddevs: A 0-D Tensor or Python value of type `dtype`. The standard </span></span><br><span class="line"><span class="string">      deviation of the truncated normal distribution. </span></span><br><span class="line"><span class="string">    minvals: A 0-D Tensor or Python value of type `dtype`. The minimum value of </span></span><br><span class="line"><span class="string">      the truncated normal distribution. </span></span><br><span class="line"><span class="string">    maxvals: A 0-D Tensor or Python value of type `dtype`. The maximum value of </span></span><br><span class="line"><span class="string">      the truncated normal distribution. </span></span><br><span class="line"><span class="string">    dtype: The type of the output. </span></span><br><span class="line"><span class="string">    seed: A Python integer. Used to create a random seed for the distribution. </span></span><br><span class="line"><span class="string">      See </span></span><br><span class="line"><span class="string">      @&#123;tf.set_random_seed&#125; </span></span><br><span class="line"><span class="string">      for behavior. </span></span><br><span class="line"><span class="string">    name: A name for the operation (optional). </span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">  Returns: </span></span><br><span class="line"><span class="string">    A tensor of the specified shape filled with random truncated normal values. </span></span><br><span class="line"><span class="string">  """</span>  </span><br><span class="line">  <span class="keyword">with</span> ops.name_scope(name, <span class="string">"parameterized_truncated_normal"</span>,  </span><br><span class="line">                      [shape, means, stddevs, minvals, maxvals]) <span class="keyword">as</span> name:  </span><br><span class="line">    shape_tensor = _ShapeTensor(shape)  </span><br><span class="line">    means_tensor = ops.convert_to_tensor(means, dtype=dtype, name=<span class="string">"means"</span>)  </span><br><span class="line">    stddevs_tensor = ops.convert_to_tensor(stddevs, dtype=dtype, name=<span class="string">"stddevs"</span>)  </span><br><span class="line">    minvals_tensor = ops.convert_to_tensor(minvals, dtype=dtype, name=<span class="string">"minvals"</span>)  </span><br><span class="line">    maxvals_tensor = ops.convert_to_tensor(maxvals, dtype=dtype, name=<span class="string">"maxvals"</span>)  </span><br><span class="line">    seed1, seed2 = random_seed.get_seed(seed)  </span><br><span class="line">    rnd = gen_random_ops._parameterized_truncated_normal(  </span><br><span class="line">        shape_tensor,  </span><br><span class="line">        means_tensor,  </span><br><span class="line">        stddevs_tensor,  </span><br><span class="line">        minvals_tensor,  </span><br><span class="line">        maxvals_tensor,  </span><br><span class="line">        seed=seed1,  </span><br><span class="line">        seed2=seed2)  </span><br><span class="line">    <span class="keyword">return</span> rnd  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">truncated_normal</span><span class="params">(shape,  </span></span></span><br><span class="line"><span class="function"><span class="params">                     mean=<span class="number">0.0</span>,  </span></span></span><br><span class="line"><span class="function"><span class="params">                     stddev=<span class="number">1.0</span>,  </span></span></span><br><span class="line"><span class="function"><span class="params">                     dtype=dtypes.float32,  </span></span></span><br><span class="line"><span class="function"><span class="params">                     seed=None,  </span></span></span><br><span class="line"><span class="function"><span class="params">                     name=None)</span>:</span>  </span><br><span class="line">  <span class="string">"""Outputs random values from a truncated normal distribution. </span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">  The generated values follow a normal distribution with specified mean and </span></span><br><span class="line"><span class="string">  standard deviation, except that values whose magnitude is more than 2 standard </span></span><br><span class="line"><span class="string">  deviations from the mean are dropped and re-picked. </span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">  Args: </span></span><br><span class="line"><span class="string">    shape: A 1-D integer Tensor or Python array. The shape of the output tensor. </span></span><br><span class="line"><span class="string">    mean: A 0-D Tensor or Python value of type `dtype`. The mean of the </span></span><br><span class="line"><span class="string">      truncated normal distribution. </span></span><br><span class="line"><span class="string">    stddev: A 0-D Tensor or Python value of type `dtype`. The standard deviation </span></span><br><span class="line"><span class="string">      of the truncated normal distribution. </span></span><br><span class="line"><span class="string">    dtype: The type of the output. </span></span><br><span class="line"><span class="string">    seed: A Python integer. Used to create a random seed for the distribution. </span></span><br><span class="line"><span class="string">      See </span></span><br><span class="line"><span class="string">      @&#123;tf.set_random_seed&#125; </span></span><br><span class="line"><span class="string">      for behavior. </span></span><br><span class="line"><span class="string">    name: A name for the operation (optional). </span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">  Returns: </span></span><br><span class="line"><span class="string">    A tensor of the specified shape filled with random truncated normal values. </span></span><br><span class="line"><span class="string">  """</span>  </span><br><span class="line">  <span class="keyword">with</span> ops.name_scope(name, <span class="string">"truncated_normal"</span>, [shape, mean, stddev]) <span class="keyword">as</span> name:  </span><br><span class="line">    shape_tensor = _ShapeTensor(shape)  </span><br><span class="line">    mean_tensor = ops.convert_to_tensor(mean, dtype=dtype, name=<span class="string">"mean"</span>)  </span><br><span class="line">    stddev_tensor = ops.convert_to_tensor(stddev, dtype=dtype, name=<span class="string">"stddev"</span>)  </span><br><span class="line">    seed1, seed2 = random_seed.get_seed(seed)  </span><br><span class="line">    rnd = gen_random_ops._truncated_normal(  </span><br><span class="line">        shape_tensor, dtype, seed=seed1, seed2=seed2)  </span><br><span class="line">    mul = rnd * stddev_tensor  </span><br><span class="line">    value = math_ops.add(mul, mean_tensor, name=name)  </span><br><span class="line">    <span class="keyword">return</span> value  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">ops.NotDifferentiable(<span class="string">"ParameterizedTruncatedNormal"</span>)  </span><br><span class="line">ops.NotDifferentiable(<span class="string">"TruncatedNormal"</span>)  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">random_uniform</span><span class="params">(shape,  </span></span></span><br><span class="line"><span class="function"><span class="params">                   minval=<span class="number">0</span>,  </span></span></span><br><span class="line"><span class="function"><span class="params">                   maxval=None,  </span></span></span><br><span class="line"><span class="function"><span class="params">                   dtype=dtypes.float32,  </span></span></span><br><span class="line"><span class="function"><span class="params">                   seed=None,  </span></span></span><br><span class="line"><span class="function"><span class="params">                   name=None)</span>:</span>  </span><br><span class="line">  <span class="string">"""Outputs random values from a uniform distribution. </span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">  The generated values follow a uniform distribution in the range </span></span><br><span class="line"><span class="string">  `[minval, maxval)`. The lower bound `minval` is included in the range, while </span></span><br><span class="line"><span class="string">  the upper bound `maxval` is excluded. </span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">  For floats, the default range is `[0, 1)`.  For ints, at least `maxval` must </span></span><br><span class="line"><span class="string">  be specified explicitly. </span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">  In the integer case, the random integers are slightly biased unless </span></span><br><span class="line"><span class="string">  `maxval - minval` is an exact power of two.  The bias is small for values of </span></span><br><span class="line"><span class="string">  `maxval - minval` significantly smaller than the range of the output (either </span></span><br><span class="line"><span class="string">  `2**32` or `2**64`). </span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">  Args: </span></span><br><span class="line"><span class="string">    shape: A 1-D integer Tensor or Python array. The shape of the output tensor. </span></span><br><span class="line"><span class="string">    minval: A 0-D Tensor or Python value of type `dtype`. The lower bound on the </span></span><br><span class="line"><span class="string">      range of random values to generate.  Defaults to 0. </span></span><br><span class="line"><span class="string">    maxval: A 0-D Tensor or Python value of type `dtype`. The upper bound on </span></span><br><span class="line"><span class="string">      the range of random values to generate.  Defaults to 1 if `dtype` is </span></span><br><span class="line"><span class="string">      floating point. </span></span><br><span class="line"><span class="string">    dtype: The type of the output: `float32`, `float64`, `int32`, or `int64`. </span></span><br><span class="line"><span class="string">    seed: A Python integer. Used to create a random seed for the distribution. </span></span><br><span class="line"><span class="string">      See @&#123;tf.set_random_seed&#125; </span></span><br><span class="line"><span class="string">      for behavior. </span></span><br><span class="line"><span class="string">    name: A name for the operation (optional). </span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">  Returns: </span></span><br><span class="line"><span class="string">    A tensor of the specified shape filled with random uniform values. </span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">  Raises: </span></span><br><span class="line"><span class="string">    ValueError: If `dtype` is integral and `maxval` is not specified. </span></span><br><span class="line"><span class="string">  """</span>  </span><br><span class="line">  dtype = dtypes.as_dtype(dtype)  </span><br><span class="line">  <span class="keyword">if</span> maxval <span class="keyword">is</span> <span class="keyword">None</span>:  </span><br><span class="line">    <span class="keyword">if</span> dtype.is_integer:  </span><br><span class="line">      <span class="keyword">raise</span> ValueError(<span class="string">"Must specify maxval for integer dtype %r"</span> % dtype)  </span><br><span class="line">    maxval = <span class="number">1</span>  </span><br><span class="line">  <span class="keyword">with</span> ops.name_scope(name, <span class="string">"random_uniform"</span>, [shape, minval, maxval]) <span class="keyword">as</span> name:  </span><br><span class="line">    shape = _ShapeTensor(shape)  </span><br><span class="line">    minval = ops.convert_to_tensor(minval, dtype=dtype, name=<span class="string">"min"</span>)  </span><br><span class="line">    maxval = ops.convert_to_tensor(maxval, dtype=dtype, name=<span class="string">"max"</span>)  </span><br><span class="line">    seed1, seed2 = random_seed.get_seed(seed)  </span><br><span class="line">    <span class="keyword">if</span> dtype.is_integer:  </span><br><span class="line">      <span class="keyword">return</span> gen_random_ops._random_uniform_int(  </span><br><span class="line">          shape, minval, maxval, seed=seed1, seed2=seed2, name=name)  </span><br><span class="line">    <span class="keyword">else</span>:  </span><br><span class="line">      rnd = gen_random_ops._random_uniform(  </span><br><span class="line">          shape, dtype, seed=seed1, seed2=seed2)  </span><br><span class="line">      <span class="keyword">return</span> math_ops.add(rnd * (maxval - minval), minval, name=name)  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">ops.NotDifferentiable(<span class="string">"RandomUniform"</span>)  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">random_shuffle</span><span class="params">(value, seed=None, name=None)</span>:</span>  </span><br><span class="line">  <span class="string">"""Randomly shuffles a tensor along its first dimension. </span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">  The tensor is shuffled along dimension 0, such that each `value[j]` is mapped </span></span><br><span class="line"><span class="string">  to one and only one `output[i]`. For example, a mapping that might occur for a </span></span><br><span class="line"><span class="string">  3x2 tensor is: </span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">  ```python </span></span><br><span class="line"><span class="string">  [[1, 2],       [[5, 6], </span></span><br><span class="line"><span class="string">   [3, 4],  ==&gt;   [1, 2], </span></span><br><span class="line"><span class="string">   [5, 6]]        [3, 4]] </span></span><br><span class="line"><span class="string">  ``` </span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">  Args: </span></span><br><span class="line"><span class="string">    value: A Tensor to be shuffled. </span></span><br><span class="line"><span class="string">    seed: A Python integer. Used to create a random seed for the distribution. </span></span><br><span class="line"><span class="string">      See </span></span><br><span class="line"><span class="string">      @&#123;tf.set_random_seed&#125; </span></span><br><span class="line"><span class="string">      for behavior. </span></span><br><span class="line"><span class="string">    name: A name for the operation (optional). </span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">  Returns: </span></span><br><span class="line"><span class="string">    A tensor of same shape and type as `value`, shuffled along its first </span></span><br><span class="line"><span class="string">    dimension. </span></span><br><span class="line"><span class="string">  """</span>  </span><br><span class="line">  seed1, seed2 = random_seed.get_seed(seed)  </span><br><span class="line">  <span class="keyword">return</span> gen_random_ops._random_shuffle(  </span><br><span class="line">      value, seed=seed1, seed2=seed2, name=name)  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">random_crop</span><span class="params">(value, size, seed=None, name=None)</span>:</span>  </span><br><span class="line">  <span class="string">"""Randomly crops a tensor to a given size. </span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">  Slices a shape `size` portion out of `value` at a uniformly chosen offset. </span></span><br><span class="line"><span class="string">  Requires `value.shape &gt;= size`. </span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">  If a dimension should not be cropped, pass the full size of that dimension. </span></span><br><span class="line"><span class="string">  For example, RGB images can be cropped with </span></span><br><span class="line"><span class="string">  `size = [crop_height, crop_width, 3]`. </span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">  Args: </span></span><br><span class="line"><span class="string">    value: Input tensor to crop. </span></span><br><span class="line"><span class="string">    size: 1-D tensor with size the rank of `value`. </span></span><br><span class="line"><span class="string">    seed: Python integer. Used to create a random seed. See </span></span><br><span class="line"><span class="string">      @&#123;tf.set_random_seed&#125; </span></span><br><span class="line"><span class="string">      for behavior. </span></span><br><span class="line"><span class="string">    name: A name for this operation (optional). </span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">  Returns: </span></span><br><span class="line"><span class="string">    A cropped tensor of the same rank as `value` and shape `size`. </span></span><br><span class="line"><span class="string">  """</span>  </span><br><span class="line">  <span class="comment"># TODO(shlens): Implement edge case to guarantee output size dimensions.  </span></span><br><span class="line">  <span class="comment"># If size &gt; value.shape, zero pad the result so that it always has shape  </span></span><br><span class="line">  <span class="comment"># exactly size.  </span></span><br><span class="line">  <span class="keyword">with</span> ops.name_scope(name, <span class="string">"random_crop"</span>, [value, size]) <span class="keyword">as</span> name:  </span><br><span class="line">    value = ops.convert_to_tensor(value, name=<span class="string">"value"</span>)  </span><br><span class="line">    size = ops.convert_to_tensor(size, dtype=dtypes.int32, name=<span class="string">"size"</span>)  </span><br><span class="line">    shape = array_ops.shape(value)  </span><br><span class="line">    check = control_flow_ops.Assert(  </span><br><span class="line">        math_ops.reduce_all(shape &gt;= size),  </span><br><span class="line">        [<span class="string">"Need value.shape &gt;= size, got "</span>, shape, size],  </span><br><span class="line">        summarize=<span class="number">1000</span>)  </span><br><span class="line">    shape = control_flow_ops.with_dependencies([check], shape)  </span><br><span class="line">    limit = shape - size + <span class="number">1</span>  </span><br><span class="line">    offset = random_uniform(  </span><br><span class="line">        array_ops.shape(shape),  </span><br><span class="line">        dtype=size.dtype,  </span><br><span class="line">        maxval=size.dtype.max,  </span><br><span class="line">        seed=seed) % limit  </span><br><span class="line">    <span class="keyword">return</span> array_ops.slice(value, offset, size, name=name)  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">multinomial</span><span class="params">(logits, num_samples, seed=None, name=None)</span>:</span>  </span><br><span class="line">  <span class="string">"""Draws samples from a multinomial distribution. </span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">  Example: </span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">  ```python </span></span><br><span class="line"><span class="string">  # samples has shape [1, 5], where each value is either 0 or 1 with equal </span></span><br><span class="line"><span class="string">  # probability. </span></span><br><span class="line"><span class="string">  samples = tf.multinomial(tf.log([[10., 10.]]), 5) </span></span><br><span class="line"><span class="string">  ``` </span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">  Args: </span></span><br><span class="line"><span class="string">    logits: 2-D Tensor with shape `[batch_size, num_classes]`.  Each slice </span></span><br><span class="line"><span class="string">      `[i, :]` represents the log-odds for all classes. </span></span><br><span class="line"><span class="string">    num_samples: 0-D.  Number of independent samples to draw for each row slice. </span></span><br><span class="line"><span class="string">    seed: A Python integer. Used to create a random seed for the distribution. </span></span><br><span class="line"><span class="string">      See </span></span><br><span class="line"><span class="string">      @&#123;tf.set_random_seed&#125; </span></span><br><span class="line"><span class="string">      for behavior. </span></span><br><span class="line"><span class="string">    name: Optional name for the operation. </span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">  Returns: </span></span><br><span class="line"><span class="string">    The drawn samples of shape `[batch_size, num_samples]`. </span></span><br><span class="line"><span class="string">  """</span>  </span><br><span class="line">  <span class="keyword">with</span> ops.name_scope(name, <span class="string">"multinomial"</span>, [logits]):  </span><br><span class="line">    logits = ops.convert_to_tensor(logits, name=<span class="string">"logits"</span>)  </span><br><span class="line">    seed1, seed2 = random_seed.get_seed(seed)  </span><br><span class="line">    <span class="keyword">return</span> gen_random_ops.multinomial(  </span><br><span class="line">        logits, num_samples, seed=seed1, seed2=seed2)  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">ops.NotDifferentiable(<span class="string">"Multinomial"</span>)  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">random_gamma</span><span class="params">(shape,  </span></span></span><br><span class="line"><span class="function"><span class="params">                 alpha,  </span></span></span><br><span class="line"><span class="function"><span class="params">                 beta=None,  </span></span></span><br><span class="line"><span class="function"><span class="params">                 dtype=dtypes.float32,  </span></span></span><br><span class="line"><span class="function"><span class="params">                 seed=None,  </span></span></span><br><span class="line"><span class="function"><span class="params">                 name=None)</span>:</span>  </span><br><span class="line">  <span class="string">"""Draws `shape` samples from each of the given Gamma distribution(s). </span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">  `alpha` is the shape parameter describing the distribution(s), and `beta` is </span></span><br><span class="line"><span class="string">  the inverse scale parameter(s). </span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">  Example: </span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">    samples = tf.random_gamma([10], [0.5, 1.5]) </span></span><br><span class="line"><span class="string">    # samples has shape [10, 2], where each slice [:, 0] and [:, 1] represents </span></span><br><span class="line"><span class="string">    # the samples drawn from each distribution </span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">    samples = tf.random_gamma([7, 5], [0.5, 1.5]) </span></span><br><span class="line"><span class="string">    # samples has shape [7, 5, 2], where each slice [:, :, 0] and [:, :, 1] </span></span><br><span class="line"><span class="string">    # represents the 7x5 samples drawn from each of the two distributions </span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">    samples = tf.random_gamma([30], [[1.],[3.],[5.]], beta=[[3., 4.]]) </span></span><br><span class="line"><span class="string">    # samples has shape [30, 3, 2], with 30 samples each of 3x2 distributions. </span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">    Note: Because internal calculations are done using `float64` and casting has </span></span><br><span class="line"><span class="string">    `floor` semantics, we must manually map zero outcomes to the smallest </span></span><br><span class="line"><span class="string">    possible positive floating-point value, i.e., `np.finfo(dtype).tiny`.  This </span></span><br><span class="line"><span class="string">    means that `np.finfo(dtype).tiny` occurs more frequently than it otherwise </span></span><br><span class="line"><span class="string">    should.  This bias can only happen for small values of `alpha`, i.e., </span></span><br><span class="line"><span class="string">    `alpha &lt;&lt; 1` or large values of `beta`, i.e., `beta &gt;&gt; 1`. </span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">  Args: </span></span><br><span class="line"><span class="string">    shape: A 1-D integer Tensor or Python array. The shape of the output samples </span></span><br><span class="line"><span class="string">      to be drawn per alpha/beta-parameterized distribution. </span></span><br><span class="line"><span class="string">    alpha: A Tensor or Python value or N-D array of type `dtype`. `alpha` </span></span><br><span class="line"><span class="string">      provides the shape parameter(s) describing the gamma distribution(s) to </span></span><br><span class="line"><span class="string">      sample. Must be broadcastable with `beta`. </span></span><br><span class="line"><span class="string">    beta: A Tensor or Python value or N-D array of type `dtype`. Defaults to 1. </span></span><br><span class="line"><span class="string">      `beta` provides the inverse scale parameter(s) of the gamma </span></span><br><span class="line"><span class="string">      distribution(s) to sample. Must be broadcastable with `alpha`. </span></span><br><span class="line"><span class="string">    dtype: The type of alpha, beta, and the output: `float16`, `float32`, or </span></span><br><span class="line"><span class="string">      `float64`. </span></span><br><span class="line"><span class="string">    seed: A Python integer. Used to create a random seed for the distributions. </span></span><br><span class="line"><span class="string">      See </span></span><br><span class="line"><span class="string">      @&#123;tf.set_random_seed&#125; </span></span><br><span class="line"><span class="string">      for behavior. </span></span><br><span class="line"><span class="string">    name: Optional name for the operation. </span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">  Returns: </span></span><br><span class="line"><span class="string">    samples: a `Tensor` of shape `tf.concat(shape, tf.shape(alpha + beta))` </span></span><br><span class="line"><span class="string">      with values of type `dtype`. </span></span><br><span class="line"><span class="string">  """</span>  </span><br><span class="line">  <span class="keyword">with</span> ops.name_scope(name, <span class="string">"random_gamma"</span>, [shape, alpha, beta]):  </span><br><span class="line">    shape = ops.convert_to_tensor(shape, name=<span class="string">"shape"</span>, dtype=dtypes.int32)  </span><br><span class="line">    alpha = ops.convert_to_tensor(alpha, name=<span class="string">"alpha"</span>, dtype=dtype)  </span><br><span class="line">    beta = ops.convert_to_tensor(  </span><br><span class="line">        beta <span class="keyword">if</span> beta <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span> <span class="keyword">else</span> <span class="number">1</span>, name=<span class="string">"beta"</span>, dtype=dtype)  </span><br><span class="line">    alpha_broadcast = alpha + array_ops.zeros_like(beta)  </span><br><span class="line">    seed1, seed2 = random_seed.get_seed(seed)  </span><br><span class="line">    <span class="keyword">return</span> math_ops.maximum(  </span><br><span class="line">        np.finfo(dtype.as_numpy_dtype).tiny,  </span><br><span class="line">        gen_random_ops._random_gamma(  </span><br><span class="line">            shape, alpha_broadcast, seed=seed1, seed2=seed2) / beta)  </span><br><span class="line">  </span><br><span class="line">ops.NotDifferentiable(<span class="string">"RandomGamma"</span>)  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">random_poisson</span><span class="params">(lam, shape, dtype=dtypes.float32, seed=None, name=None)</span>:</span>  </span><br><span class="line">  <span class="string">"""Draws `shape` samples from each of the given Poisson distribution(s). </span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">  `lam` is the rate parameter describing the distribution(s). </span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">  Example: </span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">    samples = tf.random_poisson([0.5, 1.5], [10]) </span></span><br><span class="line"><span class="string">    # samples has shape [10, 2], where each slice [:, 0] and [:, 1] represents </span></span><br><span class="line"><span class="string">    # the samples drawn from each distribution </span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">    samples = tf.random_poisson([12.2, 3.3], [7, 5]) </span></span><br><span class="line"><span class="string">    # samples has shape [7, 5, 2], where each slice [:, :, 0] and [:, :, 1] </span></span><br><span class="line"><span class="string">    # represents the 7x5 samples drawn from each of the two distributions </span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">  Args: </span></span><br><span class="line"><span class="string">    lam: A Tensor or Python value or N-D array of type `dtype`. </span></span><br><span class="line"><span class="string">      `lam` provides the rate parameter(s) describing the poisson </span></span><br><span class="line"><span class="string">      distribution(s) to sample. </span></span><br><span class="line"><span class="string">    shape: A 1-D integer Tensor or Python array. The shape of the output samples </span></span><br><span class="line"><span class="string">      to be drawn per "rate"-parameterized distribution. </span></span><br><span class="line"><span class="string">    dtype: The type of `lam` and the output: `float16`, `float32`, or </span></span><br><span class="line"><span class="string">      `float64`. </span></span><br><span class="line"><span class="string">    seed: A Python integer. Used to create a random seed for the distributions. </span></span><br><span class="line"><span class="string">      See </span></span><br><span class="line"><span class="string">      @&#123;tf.set_random_seed&#125; </span></span><br><span class="line"><span class="string">      for behavior. </span></span><br><span class="line"><span class="string">    name: Optional name for the operation. </span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">  Returns: </span></span><br><span class="line"><span class="string">    samples: a `Tensor` of shape `tf.concat(shape, tf.shape(lam))` with </span></span><br><span class="line"><span class="string">      values of type `dtype`. </span></span><br><span class="line"><span class="string">  """</span>  </span><br><span class="line">  <span class="keyword">with</span> ops.name_scope(name, <span class="string">"random_poisson"</span>, [lam, shape]):  </span><br><span class="line">    lam = ops.convert_to_tensor(lam, name=<span class="string">"lam"</span>, dtype=dtype)  </span><br><span class="line">    shape = ops.convert_to_tensor(shape, name=<span class="string">"shape"</span>, dtype=dtypes.int32)  </span><br><span class="line">    seed1, seed2 = random_seed.get_seed(seed)  </span><br><span class="line">    <span class="keyword">return</span> gen_random_ops._random_poisson(shape, lam, seed=seed1, seed2=seed2)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;随机数函数-tf-random-normal-amp-tf-random-uniform-amp-tf-truncated-normal-amp-tf-random-shuffle&quot;&gt;&lt;a href=&quot;#随机数函数-tf-random-normal-amp-tf-
      
    
    </summary>
    
      <category term="tensorflow" scheme="http://yoursite.com/categories/tensorflow/"/>
    
    
      <category term="tf.random*" scheme="http://yoursite.com/tags/tf-random/"/>
    
  </entry>
  
  <entry>
    <title>Python专题：pickle序列化</title>
    <link href="http://yoursite.com/2018/05/01/python/Python%E4%B8%93%E9%A2%98%EF%BC%9Apickle%E5%BA%8F%E5%88%97%E5%8C%96/"/>
    <id>http://yoursite.com/2018/05/01/python/Python专题：pickle序列化/</id>
    <published>2018-05-01T11:51:27.000Z</published>
    <updated>2018-06-05T04:47:34.704Z</updated>
    
    <content type="html"><![CDATA[<p>pickle提供了一个简单的持久化功能。可以将对象以文件的形式存放在磁盘上。</p><hr><p>pickle.dump(obj, file[, protocol])<br>　　序列化对象，并将结果数据流写入到文件对象中。参数protocol是序列化模式，默认值为0，表示以文本的形式序列化。protocol的值还可以是1或2，表示以二进制的形式序列化。</p><hr><p>pickle.load(file)<br>　　反序列化对象。将文件中的数据解析为一个Python对象。</p><p>其中要注意的是，在load(file)的时候，要让python能够找到类的定义，否则会报错：</p><p>比如下面的例子<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,n,a)</span>:</span></span><br><span class="line">        self.name=n</span><br><span class="line">        self.age=a</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">show</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">print</span> self.name+<span class="string">"_"</span>+str(self.age)</span><br><span class="line">aa = Person(<span class="string">"JGood"</span>, <span class="number">2</span>)</span><br><span class="line">aa.show()</span><br><span class="line">f=open(<span class="string">'d:\\p.txt'</span>,<span class="string">'w'</span>)</span><br><span class="line">pickle.dump(aa,f,<span class="number">0</span>)</span><br><span class="line">f.close()</span><br><span class="line"><span class="comment">#del Person</span></span><br><span class="line">f=open(<span class="string">'d:\\p.txt'</span>,<span class="string">'r'</span>)</span><br><span class="line">bb=pickle.load(f)</span><br><span class="line">f.close()</span><br><span class="line">bb.show()</span><br></pre></td></tr></table></figure></p><p>如果不注释掉del Person的话，那么会报错如下：</p><p><img src="/2018/05/01/python/Python专题：pickle序列化/2018-06-05-12-46-29.png" alt=""><br>意思就是当前模块找不到类的定义了。</p><hr><p>clear_memo()<br>　　清空pickler的“备忘”。使用Pickler实例在序列化对象的时候，它会“记住”已经被序列化的对象引用，所以对同一对象多次调用dump(obj)，pickler不会“傻傻”的去多次序列化。<br>看下面的例子：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> StringIO  </span><br><span class="line"><span class="keyword">import</span> pickle  </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span>:</span>  </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,n,a)</span>:</span>  </span><br><span class="line">        self.name=n  </span><br><span class="line">        self.age=a  </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">show</span><span class="params">(self)</span>:</span>  </span><br><span class="line">        <span class="keyword">print</span> self.name+<span class="string">"_"</span>+str(self.age)  </span><br><span class="line">aa = Person(<span class="string">"JGood"</span>, <span class="number">2</span>)  </span><br><span class="line">aa.show()  </span><br><span class="line">fle = StringIO.StringIO()   </span><br><span class="line">pick = pickle.Pickler(fle)  </span><br><span class="line">pick.dump(aa)  </span><br><span class="line">val1=fle.getvalue()  </span><br><span class="line"><span class="keyword">print</span> len(val1)  </span><br><span class="line">pick.clear_memo()  </span><br><span class="line">pick.dump(aa)  </span><br><span class="line">val2=fle.getvalue()  </span><br><span class="line"><span class="keyword">print</span> len(val2)  </span><br><span class="line">fle.close()</span><br></pre></td></tr></table></figure><p>上面的代码运行如下：</p><p><img src="/2018/05/01/python/Python专题：pickle序列化/2018-06-05-12-47-10.png" alt=""></p><p>如果不注释掉，则运行结果是第一个。如果注释掉，那么运行结果是第二个。</p><p>主要是因为，python的pickle如果不clear_memo，则不会多次去序列化对象。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;pickle提供了一个简单的持久化功能。可以将对象以文件的形式存放在磁盘上。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;pickle.dump(obj, file[, protocol])&lt;br&gt;　　序列化对象，并将结果数据流写入到文件对象中。参数protocol是序列化模式，默认值为0，表
      
    
    </summary>
    
      <category term="python" scheme="http://yoursite.com/categories/python/"/>
    
    
      <category term="Python技巧" scheme="http://yoursite.com/tags/Python%E6%8A%80%E5%B7%A7/"/>
    
  </entry>
  
  <entry>
    <title>Python屏蔽警告方法</title>
    <link href="http://yoursite.com/2018/05/01/python/Python%E5%B1%8F%E8%94%BD%E8%AD%A6%E5%91%8A%E6%96%B9%E6%B3%95/"/>
    <id>http://yoursite.com/2018/05/01/python/Python屏蔽警告方法/</id>
    <published>2018-05-01T11:51:27.000Z</published>
    <updated>2018-05-06T04:52:09.375Z</updated>
    
    <content type="html"><![CDATA[<p>只需要在相应的.py文件头这样写：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">import os</span><br><span class="line">os.environ[&apos;TF_CPP_MIN_LOG_LEVEL&apos;]=&apos;2&apos;</span><br><span class="line">import tensorflow as tf</span><br></pre></td></tr></table></figure></p><p>然后就没有问题啦～</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.environ[<span class="string">'TF_CPP_MIN_LOG_LEVEL'</span>]=<span class="string">'1'</span> <span class="comment"># 这是默认的显示等级，显示所有信息</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2级</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.environ[<span class="string">'TF_CPP_MIN_LOG_LEVEL'</span>]=<span class="string">'2'</span> <span class="comment"># 只显示 warning 和 Error</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3级</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.environ[<span class="string">'TF_CPP_MIN_LOG_LEVEL'</span>]=<span class="string">'3'</span> <span class="comment"># 只显示 Error</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;只需要在相应的.py文件头这样写：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;
      
    
    </summary>
    
      <category term="python" scheme="http://yoursite.com/categories/python/"/>
    
    
      <category term="Python技巧" scheme="http://yoursite.com/tags/Python%E6%8A%80%E5%B7%A7/"/>
    
  </entry>
  
  <entry>
    <title>4线性方程求解</title>
    <link href="http://yoursite.com/2018/04/29/math/linear_algebra/4%E7%BA%BF%E6%80%A7%E6%96%B9%E7%A8%8B%E6%B1%82%E8%A7%A3/"/>
    <id>http://yoursite.com/2018/04/29/math/linear_algebra/4线性方程求解/</id>
    <published>2018-04-28T16:51:27.000Z</published>
    <updated>2018-05-03T13:31:39.792Z</updated>
    
    <content type="html"><![CDATA[<h1 id="线性方程求解方法"><a href="#线性方程求解方法" class="headerlink" title="线性方程求解方法"></a>线性方程求解方法</h1><h2 id="Gauss消去法"><a href="#Gauss消去法" class="headerlink" title="Gauss消去法"></a>Gauss消去法</h2><p><img src="/2018/04/29/math/linear_algebra/4线性方程求解/2018-05-03-21-18-09.png" alt=""><br>1转化为（同解）的三角形方程组<br>2化阶梯形矩阵 且 要保证解不变，所以需要组成增广阵再进行 初等行变换（同解变换）<br>实际过程就是一行一行消元，用上面行消去下面行第一个项，有利于解出最后一个回代</p><p>举例：<br><img src="/2018/04/29/math/linear_algebra/4线性方程求解/2018-05-03-21-19-06.png" alt=""><br><img src="/2018/04/29/math/linear_algebra/4线性方程求解/2018-05-03-21-19-18.png" alt=""><br>适用性：<br>系数矩阵A规模比较小的，否则很慢<br>系数矩阵A是非奇异的，否则没有唯一解</p><h2 id="Jacobi迭代法"><a href="#Jacobi迭代法" class="headerlink" title="Jacobi迭代法"></a>Jacobi迭代法</h2><p><img src="/2018/04/29/math/linear_algebra/4线性方程求解/2018-05-03-21-23-45.png" alt=""><br><img src="/2018/04/29/math/linear_algebra/4线性方程求解/2018-05-03-21-24-05.png" alt=""><br><img src="/2018/04/29/math/linear_algebra/4线性方程求解/2018-05-03-21-24-14.png" alt=""><br><img src="/2018/04/29/math/linear_algebra/4线性方程求解/2018-05-03-21-24-21.png" alt=""><br><img src="/2018/04/29/math/linear_algebra/4线性方程求解/2018-05-03-21-24-35.png" alt=""></p><h3 id="雅克比迭代法矩阵描述"><a href="#雅克比迭代法矩阵描述" class="headerlink" title="雅克比迭代法矩阵描述"></a>雅克比迭代法矩阵描述</h3><p><img src="/2018/04/29/math/linear_algebra/4线性方程求解/2018-05-03-21-25-30.png" alt=""></p><h3 id="矩阵迭代公式"><a href="#矩阵迭代公式" class="headerlink" title="矩阵迭代公式"></a>矩阵迭代公式</h3><p><img src="/2018/04/29/math/linear_algebra/4线性方程求解/2018-05-03-21-25-46.png" alt=""><br>DX = (L+U)X + b<br>L和U都没更新，写在右边<br><img src="/2018/04/29/math/linear_algebra/4线性方程求解/2018-05-03-21-26-14.png" alt=""></p><h2 id="Gauss-Seildel迭代法"><a href="#Gauss-Seildel迭代法" class="headerlink" title="Gauss-Seildel迭代法"></a>Gauss-Seildel迭代法</h2><p><img src="/2018/04/29/math/linear_algebra/4线性方程求解/2018-05-03-21-26-47.png" alt=""><br>及时更新下半三角系数的迭代</p><h3 id="矩阵迭代公式一"><a href="#矩阵迭代公式一" class="headerlink" title="矩阵迭代公式一"></a>矩阵迭代公式一</h3><p><img src="/2018/04/29/math/linear_algebra/4线性方程求解/2018-05-03-21-27-19.png" alt=""><br>(D-L)X = UX + b<br>只有上半部的U没更新，写在右边</p><h3 id="矩阵迭代公式二"><a href="#矩阵迭代公式二" class="headerlink" title="矩阵迭代公式二"></a>矩阵迭代公式二</h3><p><img src="/2018/04/29/math/linear_algebra/4线性方程求解/2018-05-03-21-27-39.png" alt=""><br>这样D的逆更方便求出来</p><h2 id="迭代法的收敛"><a href="#迭代法的收敛" class="headerlink" title="迭代法的收敛"></a>迭代法的收敛</h2><p>严格对角占优矩阵<br><img src="/2018/04/29/math/linear_algebra/4线性方程求解/2018-05-03-21-28-47.png" alt=""></p><p>定义：对角线元素的绝对值和 &gt; 其所在 行/列 元素的绝对值和 的矩阵</p><p><img src="/2018/04/29/math/linear_algebra/4线性方程求解/2018-05-03-21-29-02.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;线性方程求解方法&quot;&gt;&lt;a href=&quot;#线性方程求解方法&quot; class=&quot;headerlink&quot; title=&quot;线性方程求解方法&quot;&gt;&lt;/a&gt;线性方程求解方法&lt;/h1&gt;&lt;h2 id=&quot;Gauss消去法&quot;&gt;&lt;a href=&quot;#Gauss消去法&quot; class=&quot;head
      
    
    </summary>
    
      <category term="math" scheme="http://yoursite.com/categories/math/"/>
    
      <category term="linear_algebra" scheme="http://yoursite.com/categories/math/linear-algebra/"/>
    
    
  </entry>
  
  <entry>
    <title>Tensorflow学习3：非线性回归</title>
    <link href="http://yoursite.com/2018/04/29/tensorflow/Tensorflow%E5%AD%A6%E4%B9%A03%EF%BC%9A%E9%9D%9E%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"/>
    <id>http://yoursite.com/2018/04/29/tensorflow/Tensorflow学习3：非线性回归/</id>
    <published>2018-04-28T16:51:27.000Z</published>
    <updated>2018-07-14T12:32:24.675Z</updated>
    
    <content type="html"><![CDATA[<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用numpy生成200个随机点</span></span><br><span class="line">x_data = np.linspace(<span class="number">-0.5</span>, <span class="number">0.5</span>, <span class="number">200</span>)[:,np.newaxis] <span class="comment">#增加一个维度，变成单列矩阵</span></span><br><span class="line">noise = np.random.normal(<span class="number">0</span>,<span class="number">0.02</span>,x_data.shape)</span><br><span class="line">y_data = np.square(x_data) + noise</span><br><span class="line"></span><br><span class="line"><span class="comment">#</span></span><br><span class="line">x = tf.placeholder(tf.float32,[<span class="keyword">None</span>,<span class="number">1</span>])</span><br><span class="line">y = tf.placeholder(tf.float32,[<span class="keyword">None</span>,<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">Weights_L1 = tf.Variable(tf.random_normal((<span class="number">1</span>,<span class="number">10</span>)))</span><br><span class="line">biases_L1 = tf.Variable(tf.zeros((<span class="number">1</span>,<span class="number">10</span>)))</span><br><span class="line">Wx_plus_b_L1 = tf.matmul(x, Weights_L1) + biases_L1</span><br><span class="line">L1 = tf.nn.softplus(Wx_plus_b_L1)</span><br><span class="line"></span><br><span class="line">Weights_L2 = tf.Variable(tf.random_normal((<span class="number">10</span>,<span class="number">1</span>)))</span><br><span class="line">biases_L2 = tf.Variable(tf.zeros((<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">Wx_plus_Biases_L2 = tf.matmul(L1, Weights_L2) + biases_L2</span><br><span class="line"><span class="comment">#predict_y = tf.nn.tanh(Wx_plus_Biases_L2)</span></span><br><span class="line">predict_y = Wx_plus_Biases_L2</span><br><span class="line"></span><br><span class="line">loss = tf.reduce_mean(tf.square(predict_y - y))</span><br><span class="line">train = tf.train.GradientDescentOptimizer(<span class="number">0.1</span>).minimize(loss)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line">        sess.run(train, feed_dict=&#123;x:x_data, y:y_data&#125;)</span><br><span class="line">        </span><br><span class="line">    _predict_y = sess.run(predict_y, feed_dict=&#123;x:x_data&#125;)</span><br><span class="line">    plt.figure()</span><br><span class="line">    plt.scatter(x_data, y_data)</span><br><span class="line">    plt.plot(x_data, _predict_y, <span class="string">"red"</span>, lw=<span class="number">5</span>)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure><p><img src="/2018/04/29/tensorflow/Tensorflow学习3：非线性回归/output_2_0.png" alt="png"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span clas
      
    
    </summary>
    
      <category term="tensorflow" scheme="http://yoursite.com/categories/tensorflow/"/>
    
    
  </entry>
  
  <entry>
    <title>Tensorflow学习4： MNIST数据集手写数字识别</title>
    <link href="http://yoursite.com/2018/04/29/tensorflow/Tensorflow%E5%AD%A6%E4%B9%A04%EF%BC%9AMNIST%E6%95%B0%E6%8D%AE%E9%9B%86%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB/"/>
    <id>http://yoursite.com/2018/04/29/tensorflow/Tensorflow学习4：MNIST数据集手写数字识别/</id>
    <published>2018-04-28T16:51:27.000Z</published>
    <updated>2018-07-14T09:35:54.176Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-MNIST数据集手写数字识别（简单版）"><a href="#1-MNIST数据集手写数字识别（简单版）" class="headerlink" title="1 MNIST数据集手写数字识别（简单版）"></a>1 MNIST数据集手写数字识别（简单版）</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#载入数据集</span></span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">"MNIST_data"</span>, one_hot=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#每个批次大小</span></span><br><span class="line">batch_size = <span class="number">100</span></span><br><span class="line"><span class="comment">#计算有多少批次</span></span><br><span class="line">batch_num = mnist.train.num_examples // batch_size</span><br><span class="line">input_x = tf.placeholder(tf.float32, [<span class="keyword">None</span>, <span class="number">784</span>])</span><br><span class="line">input_y = tf.placeholder(tf.float32, [<span class="keyword">None</span>, <span class="number">10</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment">#创建神经网络模型</span></span><br><span class="line">W1 = tf.Variable(tf.truncated_normal([<span class="number">784</span>,<span class="number">128</span>], <span class="number">0.</span>,<span class="number">0.5</span>))</span><br><span class="line">b1 = tf.Variable(tf.zeros([<span class="number">128</span>]) + <span class="number">0.1</span>)</span><br><span class="line">L1 = tf.nn.relu(tf.matmul(input_x, W1) + b1)</span><br><span class="line"></span><br><span class="line">W2 = tf.Variable(tf.truncated_normal([<span class="number">128</span>,<span class="number">10</span>], <span class="number">0.</span>,<span class="number">0.5</span>))</span><br><span class="line">b2 = tf.Variable(tf.zeros([<span class="number">10</span>]) + <span class="number">0.1</span>)</span><br><span class="line">L2 = tf.matmul(L1, W2) + b2</span><br><span class="line"></span><br><span class="line"><span class="comment">#tf.nn.softmax_cross_entropy_with_logits</span></span><br><span class="line">loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=L2, labels=input_y))</span><br><span class="line"><span class="comment">#loss = tf.reduce_mean(tf.square(L2 - input_y))</span></span><br><span class="line">train = tf.train.GradientDescentOptimizer(<span class="number">0.2</span>).minimize(loss)</span><br><span class="line"></span><br><span class="line"><span class="comment">#获取用于显示的精度——优化效果</span></span><br><span class="line">correct_indices = tf.equal(tf.argmax(input_y, <span class="number">1</span>), tf.argmax(L2, <span class="number">1</span>))</span><br><span class="line">accuracy = tf.reduce_mean(tf.cast(correct_indices, tf.float32))</span><br><span class="line"></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">20</span>):</span><br><span class="line">        <span class="keyword">for</span> batch <span class="keyword">in</span> range(batch_num):</span><br><span class="line">            batch_xs, batch_ys = mnist.train.next_batch(batch_size)</span><br><span class="line">            sess.run(train, feed_dict=&#123;input_x:batch_xs, input_y:batch_ys&#125;)</span><br><span class="line">        acc = sess.run(accuracy, feed_dict=&#123;input_x:mnist.test.images, input_y:mnist.test.labels&#125;)</span><br><span class="line">        print(<span class="string">"epoch:"</span>+ str(epoch) + <span class="string">", accuracy:"</span>+ str(acc))</span><br></pre></td></tr></table></figure><p>Extracting MNIST_data\train-images-idx3-ubyte.gz<br>Extracting MNIST_data\train-labels-idx1-ubyte.gz<br>Extracting MNIST_data\t10k-images-idx3-ubyte.gz<br>Extracting MNIST_data\t10k-labels-idx1-ubyte.gz<br>epoch:0, accuracy:0.9072<br>epoch:1, accuracy:0.9248<br>epoch:2, accuracy:0.9319<br>epoch:3, accuracy:0.9375<br>epoch:4, accuracy:0.9432<br>epoch:5, accuracy:0.9469<br>epoch:6, accuracy:0.9502<br>epoch:7, accuracy:0.9534<br>epoch:8, accuracy:0.9533<br>epoch:9, accuracy:0.9574<br>epoch:10, accuracy:0.9557<br>epoch:11, accuracy:0.9577<br>epoch:12, accuracy:0.9558<br>epoch:13, accuracy:0.9588<br>epoch:14, accuracy:0.9593<br>epoch:15, accuracy:0.9595<br>epoch:16, accuracy:0.9604<br>epoch:17, accuracy:0.9613<br>epoch:18, accuracy:0.9608<br>epoch:19, accuracy:0.962</p><hr><p>总结：<br>1 整除 //<br>2 最后一层不使用激活函数，可以使用softmax</p><h1 id="2-MNIST数据集手写数字识别（优化版）"><a href="#2-MNIST数据集手写数字识别（优化版）" class="headerlink" title="2 MNIST数据集手写数字识别（优化版）"></a>2 MNIST数据集手写数字识别（优化版）</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#载入数据集</span></span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">"MNIST_data"</span>, one_hot=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#每个批次大小</span></span><br><span class="line">batch_size = <span class="number">100</span></span><br><span class="line"><span class="comment">#计算有多少批次</span></span><br><span class="line">batch_num = mnist.train.num_examples // batch_size</span><br><span class="line"></span><br><span class="line">keep_prob = tf.constant(<span class="number">1.</span>, tf.float32)</span><br><span class="line">lr = tf.Variable(<span class="number">0.01</span>, dtype=tf.float32)</span><br><span class="line">input_x = tf.placeholder(tf.float32, [<span class="keyword">None</span>, <span class="number">784</span>])</span><br><span class="line">input_y = tf.placeholder(tf.float32, [<span class="keyword">None</span>, <span class="number">10</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment">#创建神经网络模型</span></span><br><span class="line"></span><br><span class="line">W1 = tf.Variable(tf.truncated_normal([<span class="number">784</span>,<span class="number">300</span>], <span class="number">0.</span>,<span class="number">0.5</span>))</span><br><span class="line">b1 = tf.Variable(tf.zeros([<span class="number">300</span>]) + <span class="number">0.1</span>)</span><br><span class="line">L1 = tf.nn.relu(tf.matmul(input_x, W1) + b1)</span><br><span class="line">L1_drop = tf.nn.dropout(L1, keep_prob=keep_prob)</span><br><span class="line"></span><br><span class="line">W2 = tf.Variable(tf.truncated_normal([<span class="number">300</span>,<span class="number">100</span>], <span class="number">0.</span>,<span class="number">0.5</span>))</span><br><span class="line">b2 = tf.Variable(tf.zeros([<span class="number">100</span>]) + <span class="number">0.1</span>)</span><br><span class="line">L2 = tf.nn.relu(tf.matmul(L1_drop, W2) + b2)</span><br><span class="line"></span><br><span class="line">W3 = tf.Variable(tf.truncated_normal([<span class="number">100</span>,<span class="number">10</span>], <span class="number">0.</span>,<span class="number">0.5</span>))</span><br><span class="line">b3 = tf.Variable(tf.zeros([<span class="number">10</span>]) + <span class="number">0.1</span>)</span><br><span class="line">L3 = tf.matmul(L2, W3) + b3</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#tf.nn.softmax_cross_entropy_with_logits</span></span><br><span class="line">loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=L3, labels=input_y))</span><br><span class="line"><span class="comment"># train = tf.train.RMSPropOptimizer(lr).minimize(loss)</span></span><br><span class="line">train = tf.train.RMSPropOptimizer(lr).minimize(loss)</span><br><span class="line"></span><br><span class="line"><span class="comment">#获取用于显示的精度——优化效果</span></span><br><span class="line">correct_indices = tf.equal(tf.argmax(input_y, <span class="number">1</span>), tf.argmax(L3, <span class="number">1</span>))</span><br><span class="line">accuracy = tf.reduce_mean(tf.cast(correct_indices, tf.float32))</span><br><span class="line"></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">20</span>):</span><br><span class="line">        <span class="comment">#每次迭代更新学习率</span></span><br><span class="line">        sess.run(tf.assign(lr, <span class="number">0.01</span>*(<span class="number">0.9</span>**epoch) ))</span><br><span class="line">        <span class="keyword">for</span> batch <span class="keyword">in</span> range(batch_num):</span><br><span class="line">            batch_xs, batch_ys = mnist.train.next_batch(batch_size)</span><br><span class="line">            sess.run(train, feed_dict=&#123;input_x:batch_xs, input_y:batch_ys&#125;)</span><br><span class="line">        _accuracy = sess.run(accuracy, feed_dict=&#123;input_x:mnist.test.images, input_y:mnist.test.labels&#125;)</span><br><span class="line">        print(<span class="string">"epoch:"</span>+ str(epoch) + <span class="string">", accuracy:"</span>+ str(_accuracy))</span><br></pre></td></tr></table></figure><p>Extracting MNIST_data\train-images-idx3-ubyte.gz<br>Extracting MNIST_data\train-labels-idx1-ubyte.gz<br>Extracting MNIST_data\t10k-images-idx3-ubyte.gz<br>Extracting MNIST_data\t10k-labels-idx1-ubyte.gz<br>epoch:0, accuracy:0.9192<br>epoch:1, accuracy:0.9496<br>epoch:2, accuracy:0.9543<br>epoch:3, accuracy:0.951<br>epoch:4, accuracy:0.9553<br>epoch:5, accuracy:0.9631<br>epoch:6, accuracy:0.9695<br>epoch:7, accuracy:0.9679<br>epoch:8, accuracy:0.968<br>epoch:9, accuracy:0.9705<br>epoch:10, accuracy:0.9659<br>epoch:11, accuracy:0.9745<br>epoch:12, accuracy:0.9742<br>epoch:13, accuracy:0.9757<br>epoch:14, accuracy:0.9765<br>epoch:15, accuracy:0.9769<br>epoch:16, accuracy:0.9768<br>epoch:17, accuracy:0.9771<br>epoch:18, accuracy:0.977<br>epoch:19, accuracy:0.9771</p><hr><p>总结：<br>1 动态学习率<br>2 dropout<br>3 加1个隐层<br>4 使用RMSPropOptimizer优化器</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-MNIST数据集手写数字识别（简单版）&quot;&gt;&lt;a href=&quot;#1-MNIST数据集手写数字识别（简单版）&quot; class=&quot;headerlink&quot; title=&quot;1 MNIST数据集手写数字识别（简单版）&quot;&gt;&lt;/a&gt;1 MNIST数据集手写数字识别（简单版）&lt;/
      
    
    </summary>
    
      <category term="tensorflow" scheme="http://yoursite.com/categories/tensorflow/"/>
    
    
      <category term="MNIST" scheme="http://yoursite.com/tags/MNIST/"/>
    
  </entry>
  
  <entry>
    <title>欢迎光临，BLOG刚弄不久正在施工 文章陆续上传中...</title>
    <link href="http://yoursite.com/2018/04/29/OTHERS/%E7%BD%AE%E9%A1%B6%E4%BF%A1%E6%81%AF/"/>
    <id>http://yoursite.com/2018/04/29/OTHERS/置顶信息/</id>
    <published>2018-04-28T16:51:27.000Z</published>
    <updated>2018-05-04T04:39:25.923Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="其他" scheme="http://yoursite.com/categories/%E5%85%B6%E4%BB%96/"/>
    
    
  </entry>
  
  <entry>
    <title>Tensorflow学习10-2：验证码识别——训练和测试</title>
    <link href="http://yoursite.com/2018/04/26/tensorflow/Tensorflow%E5%AD%A6%E4%B9%A010-2%EF%BC%9A%E9%AA%8C%E8%AF%81%E7%A0%81%E8%AF%86%E5%88%AB%E2%80%94%E2%80%94%E8%AE%AD%E7%BB%83%E5%92%8C%E6%B5%8B%E8%AF%95/"/>
    <id>http://yoursite.com/2018/04/26/tensorflow/Tensorflow学习10-2：验证码识别——训练和测试/</id>
    <published>2018-04-25T16:10:27.000Z</published>
    <updated>2018-07-16T06:31:47.690Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-简介"><a href="#1-简介" class="headerlink" title="1 简介"></a>1 简介</h2><p>如题，本篇介绍的是tensorflow实现验证码的识别，之前我们已经生成了数据集，并且转换成了tfrecord格式的文件，现在我们开始利用这个文件来进行训练及识别。</p><p>补充一点，我们可以有两种方法进行验证码识别，其一，把标签转为向量，向量长度为40，比如一个验证码为0782，它的标签可以转为长度为40的向量 1000000000 0000000100 0000000010 0010000000，接下来，训练方法和手写数字识别类似。其二，也是我们今天重点要实现的方法，使用的是多任务的学习方法，拆分为4个标签</p><p><img src="/2018/04/26/tensorflow/Tensorflow学习10-2：验证码识别——训练和测试/2018-07-16-14-01-04.png" alt=""></p><p>采用multi-task learning 多任务学习。<br><img src="/2018/04/26/tensorflow/Tensorflow学习10-2：验证码识别——训练和测试/2018-07-16-14-01-26.png" alt=""><br>以验证码识别为例：</p><p>多任务学习是一种联合学习，多个任务并行学习，结果相互影响。所谓多任务学习，就是同时求解多个问题。个性化问题就是一种典型的多任务学习问题，它同时学习多个用户的兴趣偏好。</p><p>多任务学习有交替训练和联合训练。由于数据集相同，我们采用的是多任务学习中的联合训练。</p><h2 id="2-准备工作"><a href="#2-准备工作" class="headerlink" title="2 准备工作"></a>2 准备工作</h2><p>言归正传，我们下面用代码实现这个多任务学习。上篇已经按照之前的步骤生成好了tfrecord文件，我们使用alexnet_v2模型来完成。注意需要修改alexnet代码，该代码位于slim/nets文件夹下：<br><img src="/2018/04/26/tensorflow/Tensorflow学习10-2：验证码识别——训练和测试/2018-07-16-14-05-15.png" alt=""></p><p>我们将nets拷贝到当前工程目录下。</p><p>修改alexnet代码，将最后一层分为4个输出（4个学习任务）。修改后其完整代码如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> absolute_import</span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> division</span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">slim = tf.contrib.slim</span><br><span class="line">trunc_normal = <span class="keyword">lambda</span> stddev: tf.truncated_normal_initializer(<span class="number">0.0</span>, stddev)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">alexnet_v2_arg_scope</span><span class="params">(weight_decay=<span class="number">0.0005</span>)</span>:</span></span><br><span class="line">  <span class="keyword">with</span> slim.arg_scope([slim.conv2d, slim.fully_connected],</span><br><span class="line">                      activation_fn=tf.nn.relu,</span><br><span class="line">                      biases_initializer=tf.constant_initializer(<span class="number">0.1</span>),</span><br><span class="line">                      weights_regularizer=slim.l2_regularizer(weight_decay)):</span><br><span class="line">    <span class="keyword">with</span> slim.arg_scope([slim.conv2d], padding=<span class="string">'SAME'</span>):</span><br><span class="line">      <span class="keyword">with</span> slim.arg_scope([slim.max_pool2d], padding=<span class="string">'VALID'</span>) <span class="keyword">as</span> arg_sc:</span><br><span class="line">        <span class="keyword">return</span> arg_sc</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">alexnet_v2</span><span class="params">(inputs,</span></span></span><br><span class="line"><span class="function"><span class="params">               num_classes=<span class="number">1000</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">               is_training=True,</span></span></span><br><span class="line"><span class="function"><span class="params">               dropout_keep_prob=<span class="number">0.5</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">               spatial_squeeze=True,</span></span></span><br><span class="line"><span class="function"><span class="params">               scope=<span class="string">'alexnet_v2'</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">               global_pool=False)</span>:</span></span><br><span class="line">  <span class="string">"""AlexNet version 2.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Described in: http://arxiv.org/pdf/1404.5997v2.pdf</span></span><br><span class="line"><span class="string">  Parameters from:</span></span><br><span class="line"><span class="string">  github.com/akrizhevsky/cuda-convnet2/blob/master/layers/</span></span><br><span class="line"><span class="string">  layers-imagenet-1gpu.cfg</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Note: All the fully_connected layers have been transformed to conv2d layers.</span></span><br><span class="line"><span class="string">        To use in classification mode, resize input to 224x224 or set</span></span><br><span class="line"><span class="string">        global_pool=True. To use in fully convolutional mode, set</span></span><br><span class="line"><span class="string">        spatial_squeeze to false.</span></span><br><span class="line"><span class="string">        The LRN layers have been removed and change the initializers from</span></span><br><span class="line"><span class="string">        random_normal_initializer to xavier_initializer.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Args:</span></span><br><span class="line"><span class="string">    inputs: a tensor of size [batch_size, height, width, channels].</span></span><br><span class="line"><span class="string">    num_classes: the number of predicted classes. If 0 or None, the logits layer</span></span><br><span class="line"><span class="string">    is omitted and the input features to the logits layer are returned instead.</span></span><br><span class="line"><span class="string">    is_training: whether or not the model is being trained.</span></span><br><span class="line"><span class="string">    dropout_keep_prob: the probability that activations are kept in the dropout</span></span><br><span class="line"><span class="string">      layers during training.</span></span><br><span class="line"><span class="string">    spatial_squeeze: whether or not should squeeze the spatial dimensions of the</span></span><br><span class="line"><span class="string">      logits. Useful to remove unnecessary dimensions for classification.</span></span><br><span class="line"><span class="string">    scope: Optional scope for the variables.</span></span><br><span class="line"><span class="string">    global_pool: Optional boolean flag. If True, the input to the classification</span></span><br><span class="line"><span class="string">      layer is avgpooled to size 1x1, for any input size. (This is not part</span></span><br><span class="line"><span class="string">      of the original AlexNet.)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Returns:</span></span><br><span class="line"><span class="string">    net: the output of the logits layer (if num_classes is a non-zero integer),</span></span><br><span class="line"><span class="string">      or the non-dropped-out input to the logits layer (if num_classes is 0</span></span><br><span class="line"><span class="string">      or None).</span></span><br><span class="line"><span class="string">    end_points: a dict of tensors with intermediate activations.</span></span><br><span class="line"><span class="string">  """</span></span><br><span class="line">  <span class="keyword">with</span> tf.variable_scope(scope, <span class="string">'alexnet_v2'</span>, [inputs]) <span class="keyword">as</span> sc:</span><br><span class="line">    end_points_collection = sc.name + <span class="string">'_end_points'</span></span><br><span class="line">    <span class="comment"># Collect outputs for conv2d, fully_connected and max_pool2d.</span></span><br><span class="line">    <span class="keyword">with</span> slim.arg_scope([slim.conv2d, slim.fully_connected, slim.max_pool2d],</span><br><span class="line">                        outputs_collections=[end_points_collection]):</span><br><span class="line">      net = slim.conv2d(inputs, <span class="number">64</span>, [<span class="number">11</span>, <span class="number">11</span>], <span class="number">4</span>, padding=<span class="string">'VALID'</span>,</span><br><span class="line">                        scope=<span class="string">'conv1'</span>)</span><br><span class="line">      net = slim.max_pool2d(net, [<span class="number">3</span>, <span class="number">3</span>], <span class="number">2</span>, scope=<span class="string">'pool1'</span>)</span><br><span class="line">      net = slim.conv2d(net, <span class="number">192</span>, [<span class="number">5</span>, <span class="number">5</span>], scope=<span class="string">'conv2'</span>)</span><br><span class="line">      net = slim.max_pool2d(net, [<span class="number">3</span>, <span class="number">3</span>], <span class="number">2</span>, scope=<span class="string">'pool2'</span>)</span><br><span class="line">      net = slim.conv2d(net, <span class="number">384</span>, [<span class="number">3</span>, <span class="number">3</span>], scope=<span class="string">'conv3'</span>)</span><br><span class="line">      net = slim.conv2d(net, <span class="number">384</span>, [<span class="number">3</span>, <span class="number">3</span>], scope=<span class="string">'conv4'</span>)</span><br><span class="line">      net = slim.conv2d(net, <span class="number">256</span>, [<span class="number">3</span>, <span class="number">3</span>], scope=<span class="string">'conv5'</span>)</span><br><span class="line">      net = slim.max_pool2d(net, [<span class="number">3</span>, <span class="number">3</span>], <span class="number">2</span>, scope=<span class="string">'pool5'</span>)</span><br><span class="line"></span><br><span class="line">      <span class="comment"># Use conv2d instead of fully_connected layers.</span></span><br><span class="line">      <span class="keyword">with</span> slim.arg_scope([slim.conv2d],</span><br><span class="line">                          weights_initializer=trunc_normal(<span class="number">0.005</span>),</span><br><span class="line">                          biases_initializer=tf.constant_initializer(<span class="number">0.1</span>)):</span><br><span class="line">        net = slim.conv2d(net, <span class="number">4096</span>, [<span class="number">5</span>, <span class="number">5</span>], padding=<span class="string">'VALID'</span>,</span><br><span class="line">                          scope=<span class="string">'fc6'</span>)</span><br><span class="line">        net = slim.dropout(net, dropout_keep_prob, is_training=is_training,</span><br><span class="line">                           scope=<span class="string">'dropout6'</span>)</span><br><span class="line">        net = slim.conv2d(net, <span class="number">4096</span>, [<span class="number">1</span>, <span class="number">1</span>], scope=<span class="string">'fc7'</span>)</span><br><span class="line">        net = slim.dropout(net, dropout_keep_prob, is_training=is_training,</span><br><span class="line">                           scope=<span class="string">'dropout7'</span>)</span><br><span class="line">        <span class="comment">#分成4个输出</span></span><br><span class="line">        net0 = slim.conv2d(net, num_classes, [<span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">                            activation_fn=<span class="keyword">None</span>,</span><br><span class="line">                            normalizer_fn=<span class="keyword">None</span>,</span><br><span class="line">                            biases_initializer=tf.zeros_initializer(),</span><br><span class="line">                            scope=<span class="string">'fc8_0'</span>)</span><br><span class="line">        net1 = slim.conv2d(net, num_classes, [<span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">                            activation_fn=<span class="keyword">None</span>,</span><br><span class="line">                            normalizer_fn=<span class="keyword">None</span>,</span><br><span class="line">                            biases_initializer=tf.zeros_initializer(),</span><br><span class="line">                            scope=<span class="string">'fc8_1'</span>)</span><br><span class="line">        net2 = slim.conv2d(net, num_classes, [<span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">                            activation_fn=<span class="keyword">None</span>,</span><br><span class="line">                            normalizer_fn=<span class="keyword">None</span>,</span><br><span class="line">                            biases_initializer=tf.zeros_initializer(),</span><br><span class="line">                            scope=<span class="string">'fc8_2'</span>)</span><br><span class="line">        net3 = slim.conv2d(net, num_classes, [<span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">                            activation_fn=<span class="keyword">None</span>,</span><br><span class="line">                            normalizer_fn=<span class="keyword">None</span>,</span><br><span class="line">                            biases_initializer=tf.zeros_initializer(),</span><br><span class="line">                            scope=<span class="string">'fc8_3'</span>)</span><br><span class="line">        <span class="comment"># Convert end_points_collection into a end_point dict.</span></span><br><span class="line">        end_points = slim.utils.convert_collection_to_dict(end_points_collection)</span><br><span class="line">        <span class="comment"># if global_pool:</span></span><br><span class="line">          <span class="comment"># net = tf.reduce_mean(net, [1, 2], keep_dims=True, name='global_pool')</span></span><br><span class="line">          <span class="comment"># end_points['global_pool'] = net</span></span><br><span class="line">        <span class="comment">#if num_classes:</span></span><br><span class="line"></span><br><span class="line">          <span class="comment">#net = slim.conv2d(net, num_classes, [1, 1],</span></span><br><span class="line">                            <span class="comment">#activation_fn=None,</span></span><br><span class="line">                            <span class="comment">#normalizer_fn=None,</span></span><br><span class="line">                            <span class="comment">#biases_initializer=tf.zeros_initializer(),</span></span><br><span class="line">                            <span class="comment">#scope='fc8')</span></span><br><span class="line">        <span class="keyword">if</span> spatial_squeeze:</span><br><span class="line">            net0 = tf.squeeze(net0, [<span class="number">1</span>, <span class="number">2</span>], name=<span class="string">'fc8_0/squeezed'</span>)</span><br><span class="line">            end_points[sc.name + <span class="string">'/fc8_0'</span>] = net0</span><br><span class="line">            net1 = tf.squeeze(net1, [<span class="number">1</span>, <span class="number">2</span>], name=<span class="string">'fc8_1/squeezed'</span>)</span><br><span class="line">            end_points[sc.name + <span class="string">'/fc8_1'</span>] = net1</span><br><span class="line">            net2 = tf.squeeze(net2, [<span class="number">1</span>, <span class="number">2</span>], name=<span class="string">'fc8_2/squeezed'</span>)</span><br><span class="line">            end_points[sc.name + <span class="string">'/fc8_2'</span>] = net2</span><br><span class="line">            net3 = tf.squeeze(net3, [<span class="number">1</span>, <span class="number">2</span>], name=<span class="string">'fc8_3/squeezed'</span>)</span><br><span class="line">            end_points[sc.name + <span class="string">'/fc8_3'</span>] = net3</span><br><span class="line">        <span class="keyword">return</span> net0, net1, net2, net3, end_points</span><br><span class="line">alexnet_v2.default_image_size = <span class="number">224</span></span><br></pre></td></tr></table></figure></p><h2 id="3-训练"><a href="#3-训练" class="headerlink" title="3 训练"></a>3 训练</h2><p>训练代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> nets <span class="keyword">import</span> nets_factory</span><br><span class="line"><span class="comment">#不同字符数量</span></span><br><span class="line">CHAR_SET_LEN = <span class="number">10</span></span><br><span class="line"><span class="comment">#图片高度</span></span><br><span class="line">IMAGE_HEIGHT = <span class="number">60</span></span><br><span class="line"><span class="comment">#图片宽度</span></span><br><span class="line">IMAGE_WIDTH = <span class="number">160</span></span><br><span class="line"><span class="comment">#批次</span></span><br><span class="line">BATCH_SIZE = <span class="number">25</span></span><br><span class="line"></span><br><span class="line">MOD_DIR = <span class="string">"D:/Tensorflow/captcha/model/"</span></span><br><span class="line"><span class="comment">#tfrecord存放路径</span></span><br><span class="line">TFRECORD_FILE = <span class="string">"D:/Tensorflow/captcha/train.tfrecord"</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#placeholder</span></span><br><span class="line">x = tf.placeholder(tf.float32, [<span class="keyword">None</span>, <span class="number">224</span>, <span class="number">224</span>])</span><br><span class="line">y0 = tf.placeholder(tf.float32, [<span class="keyword">None</span>])</span><br><span class="line">y1 = tf.placeholder(tf.float32, [<span class="keyword">None</span>])</span><br><span class="line">y2 = tf.placeholder(tf.float32, [<span class="keyword">None</span>])</span><br><span class="line">y3 = tf.placeholder(tf.float32, [<span class="keyword">None</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment">#学习率</span></span><br><span class="line">lr = tf.Variable(<span class="number">0.003</span>, dtype=tf.float32)</span><br><span class="line"></span><br><span class="line"><span class="comment">#读取tfrecord</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_and_decode</span><span class="params">(filename)</span>:</span></span><br><span class="line">    <span class="comment">#根据文件名生成一个队列</span></span><br><span class="line">    filename_queue = tf.train.string_input_producer([filename])</span><br><span class="line">    reader = tf.TFRecordReader()</span><br><span class="line">    <span class="comment">#返回文件名和文件</span></span><br><span class="line">    _, serialized_example = reader.read(filename_queue)</span><br><span class="line">    features = tf.parse_single_example(serialized_example,</span><br><span class="line">                                      features= &#123;</span><br><span class="line">                                          <span class="string">"image"</span> : tf.FixedLenFeature([], tf.string),</span><br><span class="line">                                          <span class="string">"label0"</span>: tf.FixedLenFeature([], tf.int64),</span><br><span class="line">                                          <span class="string">"label1"</span>: tf.FixedLenFeature([], tf.int64),</span><br><span class="line">                                          <span class="string">"label2"</span>: tf.FixedLenFeature([], tf.int64),</span><br><span class="line">                                          <span class="string">"label3"</span>: tf.FixedLenFeature([], tf.int64),</span><br><span class="line">                                      &#125;)</span><br><span class="line">    <span class="comment">#获取图片数据</span></span><br><span class="line">    image = tf.decode_raw(features[<span class="string">"image"</span>], tf.uint8)</span><br><span class="line">    <span class="comment">#tf.train.shuffle_batch必须确定shape</span></span><br><span class="line">    image = tf.reshape(image, [<span class="number">224</span>,<span class="number">224</span>])</span><br><span class="line">    <span class="comment">#图片预处理</span></span><br><span class="line">    image = tf.cast(image, tf.float32) / <span class="number">255.0</span></span><br><span class="line">    image = tf.subtract(image, <span class="number">0.5</span>)</span><br><span class="line">    image = tf.multiply(image, <span class="number">2.0</span>)</span><br><span class="line">    <span class="comment">#获取Label</span></span><br><span class="line">    label0 = tf.cast(features[<span class="string">"label0"</span>], tf.int32)</span><br><span class="line">    label1 = tf.cast(features[<span class="string">"label1"</span>], tf.int32)</span><br><span class="line">    label2 = tf.cast(features[<span class="string">"label2"</span>], tf.int32)</span><br><span class="line">    label3 = tf.cast(features[<span class="string">"label3"</span>], tf.int32)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> image, label0, label1, label2, label3</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#获取图片数据和标签</span></span><br><span class="line">image, label0, label1, label2, label3 = read_and_decode(TFRECORD_FILE)</span><br><span class="line"></span><br><span class="line"><span class="comment">#使用shuffle_batch可以随机打乱 next_batch挨着往下取</span></span><br><span class="line"><span class="comment"># shuffle_batch才能实现[img,label]的同步,也即特征和label的同步,不然可能输入的特征和label不匹配</span></span><br><span class="line"><span class="comment"># 比如只有这样使用,才能使img和label一一对应,每次提取一个image和对应的label</span></span><br><span class="line"><span class="comment"># shuffle_batch返回的值就是RandomShuffleQueue.dequeue_many()的结果</span></span><br><span class="line"><span class="comment"># Shuffle_batch构建了一个RandomShuffleQueue，并不断地把单个的[img,label],送入队列中</span></span><br><span class="line">image_batch, label_batch0, label_batch1,label_batch2,label_batch3 = tf.train.shuffle_batch(</span><br><span class="line">        [image, label0, label1, label2, label3], batch_size = BATCH_SIZE,</span><br><span class="line">        capacity = <span class="number">5000</span>, min_after_dequeue=<span class="number">1000</span>, num_threads=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义网络结构</span></span><br><span class="line">train_network_fn = nets_factory.get_network_fn(</span><br><span class="line">    <span class="string">"alexnet_v2"</span>,</span><br><span class="line">    num_classes=CHAR_SET_LEN,</span><br><span class="line">    weight_decay=<span class="number">0.0005</span>,</span><br><span class="line">    is_training=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    <span class="comment">#inputs: a tensor of size [batch_size, height, width, channels]</span></span><br><span class="line">    X = tf.reshape(x, [BATCH_SIZE, <span class="number">224</span>, <span class="number">224</span>, <span class="number">1</span>])</span><br><span class="line">    <span class="comment">#数据输入网络得到输出值</span></span><br><span class="line">    logits0,logits1,logits2,logits3,end_points = train_network_fn(X)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#把标签转成one_hot形式</span></span><br><span class="line">    one_hot_labels0 = tf.one_hot(indices=tf.cast(y0, tf.int32), depth=CHAR_SET_LEN)</span><br><span class="line">    one_hot_labels1 = tf.one_hot(indices=tf.cast(y1, tf.int32), depth=CHAR_SET_LEN)</span><br><span class="line">    one_hot_labels2 = tf.one_hot(indices=tf.cast(y2, tf.int32), depth=CHAR_SET_LEN)</span><br><span class="line">    one_hot_labels3 = tf.one_hot(indices=tf.cast(y3, tf.int32), depth=CHAR_SET_LEN)</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="comment">#计算loss</span></span><br><span class="line">    loss0 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits0, labels=one_hot_labels0))</span><br><span class="line">    loss1 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits1, labels=one_hot_labels1))</span><br><span class="line">    loss2 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits2, labels=one_hot_labels2))</span><br><span class="line">    loss3 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits3, labels=one_hot_labels3))</span><br><span class="line">    <span class="comment">#计算总loss</span></span><br><span class="line">    total_loss = (loss0+loss1+loss2+loss3) / <span class="number">4.0</span></span><br><span class="line">    <span class="comment">#优化器</span></span><br><span class="line">    optimizer = tf.train.AdamOptimizer(learning_rate=lr).minimize(total_loss)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#计算准确率</span></span><br><span class="line">    correct_prediction0 = tf.equal(tf.argmax(one_hot_labels0,<span class="number">1</span>), tf.argmax(logits0,<span class="number">1</span>))</span><br><span class="line">    accuracy0 = tf.reduce_mean(tf.cast(correct_prediction0, tf.float32))</span><br><span class="line">    </span><br><span class="line">    correct_prediction1 = tf.equal(tf.argmax(one_hot_labels1,<span class="number">1</span>), tf.argmax(logits1,<span class="number">1</span>))</span><br><span class="line">    accuracy1 = tf.reduce_mean(tf.cast(correct_prediction1, tf.float32))</span><br><span class="line">    </span><br><span class="line">    correct_prediction2 = tf.equal(tf.argmax(one_hot_labels2,<span class="number">1</span>), tf.argmax(logits2,<span class="number">1</span>))</span><br><span class="line">    accuracy2 = tf.reduce_mean(tf.cast(correct_prediction2, tf.float32))</span><br><span class="line">    </span><br><span class="line">    correct_prediction3 = tf.equal(tf.argmax(one_hot_labels3,<span class="number">1</span>), tf.argmax(logits3,<span class="number">1</span>))</span><br><span class="line">    accuracy3 = tf.reduce_mean(tf.cast(correct_prediction3, tf.float32))</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#用于保存模型</span></span><br><span class="line">    saver = tf.train.Saver()</span><br><span class="line">    </span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#创建一个协调器，管理线程</span></span><br><span class="line">    coord = tf.train.Coordinator()</span><br><span class="line">    <span class="comment">#启动Queue Runners，此时文件名队列已经进队</span></span><br><span class="line">    threads = tf.train.start_queue_runners(sess=sess, coord=coord)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">3001</span>):</span><br><span class="line">        <span class="comment">#获取一个批次是数据和标签</span></span><br><span class="line">        b_image,b_label0,b_label1,b_label2,b_label3 = sess.run([image_batch, label_batch0, label_batch1,label_batch2,label_batch3])</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#优化模型</span></span><br><span class="line">        sess.run(optimizer, feed_dict=&#123;x:b_image, y0:b_label0, y1:b_label1, y2:b_label2, y3:b_label3&#125;)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#每迭代20次计算一下loss 和 accuracy</span></span><br><span class="line">        <span class="keyword">if</span> i%<span class="number">20</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="comment">#每迭代1000次降低一下学习率</span></span><br><span class="line">            <span class="keyword">if</span> i%<span class="number">1000</span> == <span class="number">0</span>:</span><br><span class="line">                sess.run(tf.assign(lr, lr/<span class="number">3</span>))</span><br><span class="line">                </span><br><span class="line"><span class="comment">#             print("y0:",b_label0, "y1:",b_label1, "y2:",b_label2, "y3:",b_label3)</span></span><br><span class="line"><span class="comment">#             _logits0,_logits1,_logits2,_logits3 = sess.run([logits0,logits1,logits2,logits3], feed_dict=&#123;x:b_image&#125;)</span></span><br><span class="line"><span class="comment">#             print("logits0:",_logits0, "logits1:",_logits1,"logits2:",_logits2,"logits3:",_logits3)</span></span><br><span class="line">                  </span><br><span class="line">            acc0,acc1,acc2,acc3,loss_ = sess.run([accuracy0,accuracy1,accuracy2,accuracy3,total_loss], feed_dict=&#123;</span><br><span class="line">                                                                        x:b_image, y0:b_label0, y1:b_label1, y2:b_label2, y3:b_label3</span><br><span class="line">                                                                    &#125;)</span><br><span class="line">            learning_rate = sess.run(lr)</span><br><span class="line">            print(<span class="string">"Iter:%d Loss:%.3f Accuracy:%.2f,%.2f,%.2f,%.2f Learning Rate:%.4f"</span> % (i,loss_,acc0,acc1,acc2,acc3, learning_rate))</span><br><span class="line">            </span><br><span class="line">            <span class="comment">#满足设置条件，就停止训练保存模型</span></span><br><span class="line">            <span class="keyword">if</span> i==<span class="number">3000</span>:</span><br><span class="line">                saver.save(sess, MOD_DIR + <span class="string">"captcha.model"</span>, global_step=i) <span class="comment">#global_step——保存后缀为3000</span></span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#通知其他线程关闭</span></span><br><span class="line">    coord.request_stop()</span><br><span class="line">    <span class="comment">#其他所有线程关闭后，这个函数才能返回</span></span><br><span class="line">    coord.join(threads)</span><br></pre></td></tr></table></figure><p>WARNING:tensorflow:From <ipython-input-3-e19f7531f5fb>:34: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.<br>Instructions for updating:</ipython-input-3-e19f7531f5fb></p><p>Future major versions of TensorFlow will allow gradients to flow<br>into the labels input on backprop by default.</p><p>See @{tf.nn.softmax_cross_entropy_with_logits_v2}.</p><p>Iter:0 Loss:1566.136 Accuracy:0.32,0.12,0.16,0.20 Learning Rate:0.0010<br>Iter:20 Loss:2.314 Accuracy:0.12,0.08,0.12,0.08 Learning Rate:0.0010<br>Iter:40 Loss:2.297 Accuracy:0.24,0.04,0.12,0.04 Learning Rate:0.0010<br>Iter:60 Loss:2.296 Accuracy:0.20,0.04,0.04,0.08 Learning Rate:0.0010<br>Iter:80 Loss:2.310 Accuracy:0.04,0.04,0.04,0.20 Learning Rate:0.0010<br>Iter:100 Loss:2.322 Accuracy:0.00,0.04,0.08,0.04 Learning Rate:0.0010<br>Iter:120 Loss:2.277 Accuracy:0.08,0.32,0.08,0.16 Learning Rate:0.0010<br>Iter:140 Loss:2.328 Accuracy:0.12,0.08,0.04,0.08 Learning Rate:0.0010<br>Iter:160 Loss:2.294 Accuracy:0.08,0.16,0.12,0.08 Learning Rate:0.0010<br>Iter:180 Loss:2.295 Accuracy:0.04,0.08,0.24,0.20 Learning Rate:0.0010<br>Iter:200 Loss:2.314 Accuracy:0.16,0.04,0.04,0.04 Learning Rate:0.0010<br>Iter:220 Loss:2.299 Accuracy:0.08,0.16,0.12,0.04 Learning Rate:0.0010<br>Iter:240 Loss:2.310 Accuracy:0.04,0.00,0.12,0.12 Learning Rate:0.0010<br>Iter:260 Loss:2.315 Accuracy:0.00,0.16,0.12,0.16 Learning Rate:0.0010<br>Iter:280 Loss:2.305 Accuracy:0.12,0.28,0.08,0.04 Learning Rate:0.0010<br>Iter:300 Loss:2.299 Accuracy:0.04,0.08,0.08,0.16 Learning Rate:0.0010<br>Iter:320 Loss:2.293 Accuracy:0.12,0.08,0.16,0.20 Learning Rate:0.0010<br>Iter:340 Loss:2.265 Accuracy:0.12,0.28,0.12,0.24 Learning Rate:0.0010<br>Iter:360 Loss:2.307 Accuracy:0.16,0.16,0.08,0.12 Learning Rate:0.0010<br>Iter:380 Loss:2.305 Accuracy:0.16,0.12,0.04,0.08 Learning Rate:0.0010<br>Iter:400 Loss:2.312 Accuracy:0.16,0.20,0.00,0.04 Learning Rate:0.0010<br>Iter:420 Loss:2.302 Accuracy:0.16,0.00,0.12,0.08 Learning Rate:0.0010<br>Iter:440 Loss:2.278 Accuracy:0.08,0.24,0.36,0.08 Learning Rate:0.0010<br>Iter:460 Loss:2.290 Accuracy:0.04,0.12,0.08,0.12 Learning Rate:0.0010<br>Iter:480 Loss:2.294 Accuracy:0.20,0.16,0.08,0.12 Learning Rate:0.0010<br>Iter:500 Loss:2.319 Accuracy:0.08,0.12,0.00,0.12 Learning Rate:0.0010<br>Iter:520 Loss:2.294 Accuracy:0.12,0.04,0.20,0.20 Learning Rate:0.0010<br>Iter:540 Loss:2.297 Accuracy:0.16,0.12,0.08,0.00 Learning Rate:0.0010<br>Iter:560 Loss:2.309 Accuracy:0.08,0.08,0.04,0.04 Learning Rate:0.0010<br>Iter:580 Loss:2.294 Accuracy:0.12,0.08,0.24,0.08 Learning Rate:0.0010<br>Iter:600 Loss:2.284 Accuracy:0.16,0.08,0.08,0.24 Learning Rate:0.0010<br>Iter:620 Loss:2.281 Accuracy:0.08,0.00,0.28,0.32 Learning Rate:0.0010<br>Iter:640 Loss:2.318 Accuracy:0.04,0.16,0.08,0.00 Learning Rate:0.0010<br>Iter:660 Loss:2.291 Accuracy:0.08,0.20,0.20,0.12 Learning Rate:0.0010<br>Iter:680 Loss:2.311 Accuracy:0.04,0.04,0.00,0.12 Learning Rate:0.0010<br>Iter:700 Loss:2.220 Accuracy:0.20,0.04,0.08,0.20 Learning Rate:0.0010<br>Iter:720 Loss:2.196 Accuracy:0.48,0.16,0.00,0.24 Learning Rate:0.0010<br>Iter:740 Loss:2.215 Accuracy:0.20,0.08,0.04,0.20 Learning Rate:0.0010<br>Iter:760 Loss:2.084 Accuracy:0.36,0.12,0.08,0.12 Learning Rate:0.0010<br>Iter:780 Loss:2.087 Accuracy:0.36,0.12,0.00,0.04 Learning Rate:0.0010<br>Iter:800 Loss:2.121 Accuracy:0.36,0.08,0.08,0.08 Learning Rate:0.0010<br>Iter:820 Loss:1.991 Accuracy:0.48,0.20,0.16,0.12 Learning Rate:0.0010<br>Iter:840 Loss:1.926 Accuracy:0.60,0.12,0.32,0.16 Learning Rate:0.0010<br>Iter:860 Loss:1.868 Accuracy:0.52,0.24,0.12,0.24 Learning Rate:0.0010<br>Iter:880 Loss:1.876 Accuracy:0.48,0.12,0.16,0.20 Learning Rate:0.0010<br>Iter:900 Loss:1.693 Accuracy:0.64,0.24,0.28,0.40 Learning Rate:0.0010<br>Iter:920 Loss:1.768 Accuracy:0.72,0.28,0.20,0.24 Learning Rate:0.0010<br>Iter:940 Loss:1.582 Accuracy:0.64,0.32,0.36,0.48 Learning Rate:0.0010<br>Iter:960 Loss:1.673 Accuracy:0.60,0.24,0.24,0.32 Learning Rate:0.0010<br>Iter:980 Loss:1.530 Accuracy:0.84,0.28,0.28,0.36 Learning Rate:0.0010<br>Iter:1000 Loss:1.550 Accuracy:0.68,0.28,0.40,0.40 Learning Rate:0.0003<br>Iter:1020 Loss:1.446 Accuracy:0.56,0.20,0.48,0.36 Learning Rate:0.0003<br>Iter:1040 Loss:1.445 Accuracy:0.68,0.44,0.20,0.52 Learning Rate:0.0003<br>Iter:1060 Loss:1.425 Accuracy:0.80,0.48,0.24,0.60 Learning Rate:0.0003<br>Iter:1080 Loss:1.273 Accuracy:0.80,0.56,0.40,0.56 Learning Rate:0.0003<br>Iter:1100 Loss:1.171 Accuracy:0.76,0.44,0.36,0.68 Learning Rate:0.0003<br>Iter:1120 Loss:1.080 Accuracy:0.84,0.44,0.52,0.56 Learning Rate:0.0003<br>Iter:1140 Loss:1.242 Accuracy:0.88,0.40,0.56,0.32 Learning Rate:0.0003<br>Iter:1160 Loss:1.071 Accuracy:0.88,0.60,0.52,0.52 Learning Rate:0.0003<br>Iter:1180 Loss:1.176 Accuracy:0.80,0.44,0.56,0.48 Learning Rate:0.0003<br>Iter:1200 Loss:1.131 Accuracy:0.84,0.48,0.52,0.44 Learning Rate:0.0003<br>Iter:1220 Loss:1.138 Accuracy:0.76,0.52,0.64,0.56 Learning Rate:0.0003<br>Iter:1240 Loss:1.035 Accuracy:0.84,0.56,0.56,0.52 Learning Rate:0.0003<br>Iter:1260 Loss:0.820 Accuracy:0.92,0.68,0.64,0.68 Learning Rate:0.0003<br>Iter:1280 Loss:1.083 Accuracy:0.92,0.36,0.52,0.64 Learning Rate:0.0003<br>Iter:1300 Loss:0.966 Accuracy:1.00,0.52,0.44,0.60 Learning Rate:0.0003<br>Iter:1320 Loss:0.804 Accuracy:0.84,0.68,0.60,0.64 Learning Rate:0.0003<br>Iter:1340 Loss:0.845 Accuracy:0.92,0.72,0.48,0.56 Learning Rate:0.0003<br>Iter:1360 Loss:0.923 Accuracy:0.80,0.48,0.64,0.56 Learning Rate:0.0003<br>Iter:1380 Loss:0.664 Accuracy:0.96,0.60,0.60,0.88 Learning Rate:0.0003<br>Iter:1400 Loss:0.915 Accuracy:0.88,0.72,0.40,0.72 Learning Rate:0.0003<br>Iter:1420 Loss:0.724 Accuracy:0.92,0.72,0.64,0.72 Learning Rate:0.0003<br>Iter:1440 Loss:0.574 Accuracy:0.96,0.76,0.76,0.76 Learning Rate:0.0003<br>Iter:1460 Loss:0.550 Accuracy:0.88,0.80,0.72,0.88 Learning Rate:0.0003<br>Iter:1480 Loss:0.588 Accuracy:0.88,0.72,0.84,0.84 Learning Rate:0.0003<br>Iter:1500 Loss:0.611 Accuracy:0.80,0.76,0.68,0.84 Learning Rate:0.0003<br>Iter:1520 Loss:0.487 Accuracy:0.88,0.84,0.80,0.96 Learning Rate:0.0003<br>Iter:1540 Loss:0.648 Accuracy:0.88,0.68,0.72,0.80 Learning Rate:0.0003<br>Iter:1560 Loss:0.600 Accuracy:0.84,0.76,0.68,0.84 Learning Rate:0.0003<br>Iter:1580 Loss:0.714 Accuracy:0.88,0.68,0.68,0.76 Learning Rate:0.0003<br>Iter:1600 Loss:0.497 Accuracy:0.96,0.72,0.76,0.84 Learning Rate:0.0003<br>Iter:1620 Loss:0.519 Accuracy:0.88,0.80,0.72,0.84 Learning Rate:0.0003<br>Iter:1640 Loss:0.551 Accuracy:0.92,0.72,0.68,0.92 Learning Rate:0.0003<br>Iter:1660 Loss:0.539 Accuracy:0.92,0.80,0.64,0.88 Learning Rate:0.0003<br>Iter:1680 Loss:0.484 Accuracy:0.92,0.80,0.80,0.76 Learning Rate:0.0003<br>Iter:1700 Loss:0.428 Accuracy:0.96,0.80,0.84,0.88 Learning Rate:0.0003<br>Iter:1720 Loss:0.510 Accuracy:0.92,0.68,0.84,0.80 Learning Rate:0.0003<br>Iter:1740 Loss:0.548 Accuracy:0.88,0.80,0.72,0.80 Learning Rate:0.0003<br>Iter:1760 Loss:0.358 Accuracy:0.92,0.80,0.84,1.00 Learning Rate:0.0003<br>Iter:1780 Loss:0.374 Accuracy:0.92,0.76,0.92,0.84 Learning Rate:0.0003<br>Iter:1800 Loss:0.442 Accuracy:0.88,0.80,0.68,0.88 Learning Rate:0.0003<br>Iter:1820 Loss:0.432 Accuracy:0.96,0.80,0.72,0.88 Learning Rate:0.0003<br>Iter:1840 Loss:0.399 Accuracy:1.00,0.84,0.80,0.76 Learning Rate:0.0003<br>Iter:1860 Loss:0.541 Accuracy:1.00,0.68,0.64,0.88 Learning Rate:0.0003<br>Iter:1880 Loss:0.495 Accuracy:0.92,0.64,0.76,0.80 Learning Rate:0.0003<br>Iter:1900 Loss:0.275 Accuracy:0.88,0.88,0.88,0.88 Learning Rate:0.0003<br>Iter:1920 Loss:0.319 Accuracy:0.96,0.92,0.88,0.80 Learning Rate:0.0003<br>Iter:1940 Loss:0.259 Accuracy:1.00,0.96,0.84,0.92 Learning Rate:0.0003<br>Iter:1960 Loss:0.379 Accuracy:0.96,0.76,0.76,0.84 Learning Rate:0.0003<br>Iter:1980 Loss:0.388 Accuracy:0.92,0.92,0.80,0.84 Learning Rate:0.0003<br>Iter:2000 Loss:0.350 Accuracy:0.96,0.88,0.72,0.96 Learning Rate:0.0001<br>Iter:2020 Loss:0.448 Accuracy:0.96,0.72,0.92,0.84 Learning Rate:0.0001<br>Iter:2040 Loss:0.232 Accuracy:0.96,0.84,0.92,0.92 Learning Rate:0.0001<br>Iter:2060 Loss:0.196 Accuracy:0.92,0.92,0.92,0.84 Learning Rate:0.0001<br>Iter:2080 Loss:0.346 Accuracy:0.96,0.92,0.72,0.84 Learning Rate:0.0001<br>Iter:2100 Loss:0.181 Accuracy:0.96,0.92,0.96,0.96 Learning Rate:0.0001<br>Iter:2120 Loss:0.231 Accuracy:0.96,0.80,0.88,1.00 Learning Rate:0.0001<br>Iter:2140 Loss:0.201 Accuracy:1.00,1.00,0.76,0.92 Learning Rate:0.0001<br>Iter:2160 Loss:0.271 Accuracy:0.96,0.92,0.88,0.92 Learning Rate:0.0001<br>Iter:2180 Loss:0.214 Accuracy:0.96,0.92,0.96,0.92 Learning Rate:0.0001<br>Iter:2200 Loss:0.241 Accuracy:0.96,0.92,1.00,0.88 Learning Rate:0.0001<br>Iter:2220 Loss:0.268 Accuracy:0.92,0.92,0.88,0.92 Learning Rate:0.0001<br>Iter:2240 Loss:0.249 Accuracy:0.92,0.92,0.84,0.96 Learning Rate:0.0001<br>Iter:2260 Loss:0.188 Accuracy:0.96,0.92,0.92,0.92 Learning Rate:0.0001<br>Iter:2280 Loss:0.196 Accuracy:0.96,0.88,0.92,1.00 Learning Rate:0.0001<br>Iter:2300 Loss:0.186 Accuracy:1.00,0.80,0.92,1.00 Learning Rate:0.0001<br>Iter:2320 Loss:0.167 Accuracy:1.00,0.88,0.88,0.96 Learning Rate:0.0001<br>Iter:2340 Loss:0.282 Accuracy:0.96,0.84,0.92,0.92 Learning Rate:0.0001<br>Iter:2360 Loss:0.224 Accuracy:1.00,0.88,0.88,0.96 Learning Rate:0.0001<br>Iter:2380 Loss:0.209 Accuracy:0.92,0.84,0.96,1.00 Learning Rate:0.0001<br>Iter:2400 Loss:0.100 Accuracy:1.00,1.00,0.96,1.00 Learning Rate:0.0001<br>Iter:2420 Loss:0.227 Accuracy:0.96,0.96,0.88,0.84 Learning Rate:0.0001<br>Iter:2440 Loss:0.228 Accuracy:0.96,0.96,0.92,0.88 Learning Rate:0.0001<br>Iter:2460 Loss:0.169 Accuracy:1.00,0.92,0.84,0.96 Learning Rate:0.0001<br>Iter:2480 Loss:0.162 Accuracy:0.96,0.84,1.00,0.96 Learning Rate:0.0001<br>Iter:2500 Loss:0.149 Accuracy:0.96,0.92,0.96,0.88 Learning Rate:0.0001<br>Iter:2520 Loss:0.198 Accuracy:0.96,0.96,0.88,0.92 Learning Rate:0.0001<br>Iter:2540 Loss:0.134 Accuracy:0.96,1.00,0.92,0.96 Learning Rate:0.0001<br>Iter:2560 Loss:0.181 Accuracy:0.96,0.96,0.92,0.92 Learning Rate:0.0001<br>Iter:2580 Loss:0.230 Accuracy:0.96,0.92,0.84,0.88 Learning Rate:0.0001<br>Iter:2600 Loss:0.137 Accuracy:1.00,1.00,0.92,0.92 Learning Rate:0.0001<br>Iter:2620 Loss:0.111 Accuracy:1.00,0.96,1.00,1.00 Learning Rate:0.0001<br>Iter:2640 Loss:0.142 Accuracy:1.00,0.92,0.96,0.92 Learning Rate:0.0001<br>Iter:2660 Loss:0.158 Accuracy:0.96,0.96,0.84,0.96 Learning Rate:0.0001<br>Iter:2680 Loss:0.070 Accuracy:0.96,0.96,0.96,1.00 Learning Rate:0.0001<br>Iter:2700 Loss:0.119 Accuracy:1.00,1.00,0.92,0.96 Learning Rate:0.0001<br>Iter:2720 Loss:0.074 Accuracy:0.96,0.96,0.96,1.00 Learning Rate:0.0001<br>Iter:2740 Loss:0.125 Accuracy:1.00,1.00,1.00,0.92 Learning Rate:0.0001<br>Iter:2760 Loss:0.072 Accuracy:1.00,1.00,0.96,1.00 Learning Rate:0.0001<br>Iter:2780 Loss:0.109 Accuracy:0.96,0.88,0.92,1.00 Learning Rate:0.0001<br>Iter:2800 Loss:0.181 Accuracy:1.00,0.96,0.96,0.92 Learning Rate:0.0001<br>Iter:2820 Loss:0.121 Accuracy:1.00,0.88,1.00,1.00 Learning Rate:0.0001<br>Iter:2840 Loss:0.102 Accuracy:1.00,0.96,0.96,0.96 Learning Rate:0.0001<br>Iter:2860 Loss:0.241 Accuracy:0.92,0.88,0.92,0.84 Learning Rate:0.0001<br>Iter:2880 Loss:0.129 Accuracy:1.00,0.92,0.96,0.92 Learning Rate:0.0001<br>Iter:2900 Loss:0.214 Accuracy:0.96,0.88,0.92,0.88 Learning Rate:0.0001<br>Iter:2920 Loss:0.138 Accuracy:1.00,0.96,0.92,0.96 Learning Rate:0.0001<br>Iter:2940 Loss:0.110 Accuracy:0.92,0.88,1.00,1.00 Learning Rate:0.0001<br>Iter:2960 Loss:0.103 Accuracy:0.96,0.96,0.96,1.00 Learning Rate:0.0001<br>Iter:2980 Loss:0.083 Accuracy:0.96,1.00,0.96,0.96 Learning Rate:0.0001<br>Iter:3000 Loss:0.111 Accuracy:0.96,0.92,0.96,0.92 Learning Rate:0.0000</p><p>经过大约3000次迭代 accuracy 可以达到要求。</p><h2 id="4-测试"><a href="#4-测试" class="headerlink" title="4 测试"></a>4 测试</h2><p>测试代码如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 验证码测试</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> nets <span class="keyword">import</span> nets_factory</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 不同字符数量</span></span><br><span class="line">CHAR_SET_LEN = <span class="number">10</span></span><br><span class="line"><span class="comment"># 图片高度</span></span><br><span class="line">IMAGE_HEIGHT = <span class="number">60</span></span><br><span class="line"><span class="comment"># 图片宽度</span></span><br><span class="line">IMAGE_WIDTH = <span class="number">160</span></span><br><span class="line"><span class="comment"># 批次</span></span><br><span class="line">BATCH_SIZE = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">MOD_DIR = <span class="string">"D:/Tensorflow/captcha/model/"</span></span><br><span class="line"><span class="comment"># tfrecord文件存放路径</span></span><br><span class="line">TFRECORD_FILE = <span class="string">"D:/Tensorflow/captcha/validation.tfrecord"</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># placeholder</span></span><br><span class="line">x = tf.placeholder(tf.float32,[<span class="keyword">None</span>,<span class="number">224</span>,<span class="number">224</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 从tfrecord读出数据</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_and_decode</span><span class="params">(filename)</span>:</span></span><br><span class="line">    <span class="comment"># 根据文件名生成一个队列</span></span><br><span class="line">    filename_queue = tf.train.string_input_producer([filename])</span><br><span class="line">    <span class="comment"># create a reader from file queue</span></span><br><span class="line">    reader = tf.TFRecordReader()</span><br><span class="line">    <span class="comment"># reader从文件队列中读入一个序列化的样本,返回文件名和文件</span></span><br><span class="line">    _, serialized_example = reader.read(filename_queue)</span><br><span class="line">    <span class="comment"># get feature from serialized example</span></span><br><span class="line">    <span class="comment"># 解析符号化的样本</span></span><br><span class="line">    features = tf.parse_single_example(</span><br><span class="line">        serialized_example,</span><br><span class="line">        features=&#123;</span><br><span class="line">            <span class="string">'image'</span>: tf.FixedLenFeature([], tf.string),</span><br><span class="line">            <span class="string">'label0'</span>: tf.FixedLenFeature([], tf.int64),</span><br><span class="line">            <span class="string">'label1'</span>: tf.FixedLenFeature([], tf.int64),</span><br><span class="line">            <span class="string">'label2'</span>: tf.FixedLenFeature([], tf.int64),</span><br><span class="line">            <span class="string">'label3'</span>: tf.FixedLenFeature([], tf.int64),</span><br><span class="line">        &#125;)</span><br><span class="line">    <span class="comment">#获取图片数据</span></span><br><span class="line">    image = tf.decode_raw(features[<span class="string">"image"</span>], tf.uint8)</span><br><span class="line">    <span class="comment"># 没有经过预处理的灰度图</span></span><br><span class="line">    image_raw = tf.reshape(image, [<span class="number">224</span>,<span class="number">224</span>])</span><br><span class="line">    <span class="comment">#tf.train.shuffle_batch必须确定shape</span></span><br><span class="line">    image = tf.reshape(image, [<span class="number">224</span>,<span class="number">224</span>])</span><br><span class="line">    <span class="comment"># 图片预处理</span></span><br><span class="line">    image = tf.cast(image, tf.float32) /<span class="number">255.0</span></span><br><span class="line">    image = tf.subtract(image,<span class="number">0.5</span>)</span><br><span class="line">    image = tf.multiply(image,<span class="number">2.0</span>)</span><br><span class="line">    <span class="comment"># 获取label</span></span><br><span class="line">    label0 = tf.cast(features[<span class="string">'label0'</span>], tf.int32)</span><br><span class="line">    label1 = tf.cast(features[<span class="string">'label1'</span>], tf.int32)</span><br><span class="line">    label2 = tf.cast(features[<span class="string">'label2'</span>], tf.int32)</span><br><span class="line">    label3 = tf.cast(features[<span class="string">'label3'</span>], tf.int32)</span><br><span class="line">    <span class="keyword">return</span> image, image_raw, label0, label1, label2, label3</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取图片数据和标签</span></span><br><span class="line">image, image_raw, label0, label1, label2, label3 = read_and_decode(TFRECORD_FILE)</span><br><span class="line"><span class="comment"># 使用shuffle_batch可以随机打乱输入 next_batch挨着往下取</span></span><br><span class="line"><span class="comment"># shuffle_batch才能实现[img,label]的同步,也即特征和label的同步,不然可能输入的特征和label不匹配</span></span><br><span class="line"><span class="comment"># 比如只有这样使用,才能使img和label一一对应,每次提取一个image和对应的label</span></span><br><span class="line"><span class="comment"># shuffle_batch返回的值就是RandomShuffleQueue.dequeue_many()的结果</span></span><br><span class="line"><span class="comment"># Shuffle_batch构建了一个RandomShuffleQueue，并不断地把单个的[img,label],送入队列中</span></span><br><span class="line">image_batch, image_raw_batch, label_batch0, label_batch1, label_batch2, label_batch3 = tf.train.shuffle_batch(</span><br><span class="line">                                         [image,image_raw, label0,label1,label2,label3],</span><br><span class="line">                                        batch_size=BATCH_SIZE, capacity=<span class="number">5000</span>,</span><br><span class="line">                                        min_after_dequeue=<span class="number">1000</span>,num_threads=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># 定义网络结构</span></span><br><span class="line">train_network_fn = nets_factory.get_network_fn(</span><br><span class="line">    <span class="string">'alexnet_v2'</span>,</span><br><span class="line">    num_classes=CHAR_SET_LEN,</span><br><span class="line">    weight_decay=<span class="number">0.0005</span>,</span><br><span class="line">    is_training=<span class="keyword">False</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    X = tf.reshape(x,[BATCH_SIZE,<span class="number">224</span>,<span class="number">224</span>,<span class="number">1</span>])</span><br><span class="line">    <span class="comment"># 数据输入网络得到输出值</span></span><br><span class="line">    logits0,logits1,logits2,logits3,end_points = train_network_fn(X)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 预测值</span></span><br><span class="line">    predict0 = tf.reshape(logits0,[<span class="number">-1</span>,CHAR_SET_LEN])</span><br><span class="line">    predict0 = tf.argmax(predict0,<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    predict1 = tf.reshape(logits1, [<span class="number">-1</span>, CHAR_SET_LEN])</span><br><span class="line">    predict1 = tf.argmax(predict1, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    predict2 = tf.reshape(logits2, [<span class="number">-1</span>, CHAR_SET_LEN])</span><br><span class="line">    predict2 = tf.argmax(predict2, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    predict3 = tf.reshape(logits3, [<span class="number">-1</span>, CHAR_SET_LEN])</span><br><span class="line">    predict3 = tf.argmax(predict3, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 初始化</span></span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    <span class="comment">#载入训练好的模型</span></span><br><span class="line">    saver = tf.train.Saver()</span><br><span class="line">    saver.restore(sess, MOD_DIR + <span class="string">"captcha.model-3000"</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 创建一个协调器，管理线程</span></span><br><span class="line">    coord = tf.train.Coordinator()</span><br><span class="line">    <span class="comment"># 启动队列</span></span><br><span class="line">    threads = tf.train.start_queue_runners(sess=sess,coord=coord)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">5</span>):</span><br><span class="line">        <span class="comment"># 获取一个批次的数据和标签</span></span><br><span class="line">        b_image,b_image_raw, b_label0,b_label1,b_label2,b_label3 = sess.run([image_batch,image_raw_batch,</span><br><span class="line">                                                                 label_batch0, label_batch1, label_batch2, label_batch3])</span><br><span class="line">        <span class="comment"># 显示图片</span></span><br><span class="line">        img = Image.fromarray(b_image_raw[<span class="number">0</span>], <span class="string">"L"</span>)</span><br><span class="line">        plt.imshow(np.array(img))</span><br><span class="line">        plt.axis(<span class="string">'off'</span>)</span><br><span class="line">        plt.show()</span><br><span class="line">        <span class="comment"># 打印标签</span></span><br><span class="line">        print(<span class="string">'label:'</span>,b_label0,b_label1,b_label2,b_label3)</span><br><span class="line">        <span class="comment"># 预测</span></span><br><span class="line">        label0,label1,label2,label3 = sess.run([predict0,predict1,predict2,predict3],</span><br><span class="line">                                               feed_dict=&#123;x:b_image&#125;)</span><br><span class="line">        <span class="comment"># print</span></span><br><span class="line">        print(<span class="string">'predict:'</span>,label0,label1,label2,label3)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 通知其他线程关闭</span></span><br><span class="line">    coord.request_stop()</span><br><span class="line">    <span class="comment"># 其他所有线程关闭之后，这一函数才能返回</span></span><br><span class="line">    coord.join(threads)</span><br></pre></td></tr></table></figure></p><pre><code>INFO:tensorflow:Restoring parameters from D:/Tensorflow/captcha/model/captcha.model-3000</code></pre><p><img src="/2018/04/26/tensorflow/Tensorflow学习10-2：验证码识别——训练和测试/output_4_1.png" alt="png"></p><p>label: [3] [1] [8] [3]<br>predict: [3] [1] [8] [3]</p><p><img src="/2018/04/26/tensorflow/Tensorflow学习10-2：验证码识别——训练和测试/output_4_3.png" alt="png"></p><p>label: [8] [1] [1] [7]<br>predict: [8] [1] [1] [7]</p><p><img src="/2018/04/26/tensorflow/Tensorflow学习10-2：验证码识别——训练和测试/output_4_5.png" alt="png"></p><p>label: [4] [7] [3] [4]<br>predict: [4] [7] [3] [4]</p><p><img src="/2018/04/26/tensorflow/Tensorflow学习10-2：验证码识别——训练和测试/output_4_7.png" alt="png"></p><p>label: [5] [2] [9] [4]<br>predict: [5] [6] [9] [8]</p><p><img src="/2018/04/26/tensorflow/Tensorflow学习10-2：验证码识别——训练和测试/output_4_9.png" alt="png"></p><p>label: [1] [6] [6] [8]<br>predict: [1] [4] [8] [8]</p><hr><p>总结：<br>如何训练带字母字符的验证码呢？其实很简单，A-Z，一共26个字母，我们可以映射为11~35这26个数字，A：10，B：11，，，Z :35,那么，这种数字+字母的组合一共有10+26=36个字符，同样采用one-hot编码，label是一个36维的向量，只有1个值为1，其余为0，A：000000000010000…..000；</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;1-简介&quot;&gt;&lt;a href=&quot;#1-简介&quot; class=&quot;headerlink&quot; title=&quot;1 简介&quot;&gt;&lt;/a&gt;1 简介&lt;/h2&gt;&lt;p&gt;如题，本篇介绍的是tensorflow实现验证码的识别，之前我们已经生成了数据集，并且转换成了tfrecord格式的文件，现
      
    
    </summary>
    
      <category term="tensorflow" scheme="http://yoursite.com/categories/tensorflow/"/>
    
    
      <category term="alexnet" scheme="http://yoursite.com/tags/alexnet/"/>
    
      <category term="slim" scheme="http://yoursite.com/tags/slim/"/>
    
      <category term="Multi-task Learning" scheme="http://yoursite.com/tags/Multi-task-Learning/"/>
    
  </entry>
  
  <entry>
    <title>Tensorflow学习10-1：验证码识别——生成验证码和tfrecord文件</title>
    <link href="http://yoursite.com/2018/04/25/tensorflow/Tensorflow%E5%AD%A6%E4%B9%A010-1%EF%BC%9A%E9%AA%8C%E8%AF%81%E7%A0%81%E8%AF%86%E5%88%AB%E2%80%94%E2%80%94%E7%94%9F%E6%88%90%E9%AA%8C%E8%AF%81%E7%A0%81%E5%92%8Ctfrecord%E6%96%87%E4%BB%B6/"/>
    <id>http://yoursite.com/2018/04/25/tensorflow/Tensorflow学习10-1：验证码识别——生成验证码和tfrecord文件/</id>
    <published>2018-04-24T16:10:27.000Z</published>
    <updated>2018-07-16T06:26:20.721Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-生成验证码图片"><a href="#1-生成验证码图片" class="headerlink" title="1 生成验证码图片"></a>1 生成验证码图片</h2><p>这些生成的图片位于同一个文件夹下，而且图片名就是 label 值。<br><img src="/2018/04/25/tensorflow/Tensorflow学习10-1：验证码识别——生成验证码和tfrecord文件/2018-07-16-13-46-22.png" alt=""></p><p>生成代码如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 验证码生成库</span></span><br><span class="line"><span class="keyword">from</span> captcha.image <span class="keyword">import</span> ImageCaptcha <span class="comment"># pip install captcha</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line">number = [<span class="string">'0'</span>,<span class="string">'1'</span>,<span class="string">'2'</span>,<span class="string">'3'</span>,<span class="string">'4'</span>,<span class="string">'5'</span>,<span class="string">'6'</span>,<span class="string">'7'</span>,<span class="string">'8'</span>,<span class="string">'9'</span>]</span><br><span class="line"><span class="comment"># letter = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']</span></span><br><span class="line"><span class="comment"># LETTER = ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z']</span></span><br><span class="line">CAPTCHA_SAVE_DIR = <span class="string">"D:/Tensorflow/captcha/images/"</span></span><br></pre></td></tr></table></figure></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''随机生成4个数字的字符串成。</span></span><br><span class="line"><span class="string">char_set：用于生成的字符list</span></span><br><span class="line"><span class="string">captcha_size：生成的验证码位数</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">random_captcha_text</span><span class="params">(char_set=number, captcha_size=<span class="number">4</span>)</span>:</span></span><br><span class="line">    <span class="comment"># 验证码列表</span></span><br><span class="line">    captcha_text = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(captcha_size):</span><br><span class="line">        <span class="comment">#随机选择</span></span><br><span class="line">        c = random.choice(char_set)</span><br><span class="line">        <span class="comment">#加入验证码列表</span></span><br><span class="line">        captcha_text.append(c)</span><br><span class="line">    <span class="keyword">return</span> captcha_text</span><br><span class="line"></span><br><span class="line"><span class="string">'''生成字符对应的验证码'''</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gen_captcha_text_and_iamge</span><span class="params">()</span>:</span></span><br><span class="line">    image = ImageCaptcha()</span><br><span class="line">    <span class="comment">#获得随机生成的验证码</span></span><br><span class="line">    captcha_text = random_captcha_text()</span><br><span class="line">    <span class="comment">#把验证码列表转为字符串</span></span><br><span class="line">    captcha_text = <span class="string">""</span>.join(captcha_text)</span><br><span class="line">    <span class="comment">#生成验证码</span></span><br><span class="line">    captcha = image.generate(captcha_text)</span><br><span class="line">    image.write(captcha_text, CAPTCHA_SAVE_DIR + captcha_text + <span class="string">".jpg"</span>) <span class="comment">#写到文件</span></span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line"><span class="comment">#循环生成10000次，但是重复的会被覆盖，所以&lt;10000</span></span><br><span class="line">num = <span class="number">10000</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(num):</span><br><span class="line">        gen_captcha_text_and_iamge()</span><br><span class="line">        sys.stdout.write(<span class="string">"\r&gt;&gt; Creating image %d/%d"</span> % (i+<span class="number">1</span>, num))</span><br><span class="line">        sys.stdout.flush()</span><br><span class="line">    sys.stdout.write(<span class="string">"\n"</span>)</span><br><span class="line">    sys.stdout.flush()</span><br><span class="line">    </span><br><span class="line">    print(<span class="string">"Generate finished."</span>)</span><br></pre></td></tr></table></figure><blockquote><blockquote><p>Creating image 10000/10000<br>Generate finished.</p></blockquote></blockquote><h2 id="2-将这些图片转为tfrecord文件"><a href="#2-将这些图片转为tfrecord文件" class="headerlink" title="2 将这些图片转为tfrecord文件"></a>2 将这些图片转为tfrecord文件</h2><p>我们生成tfrecord文件用于验证码识别程序的训练和测试，生成好后会产生2个.tfrecord文件<br><img src="/2018/04/25/tensorflow/Tensorflow学习10-1：验证码识别——生成验证码和tfrecord文件/2018-07-16-13-47-48.png" alt=""></p><p>生成tfrecord代码如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br></pre></td><td class="code"><pre><span class="line">-<span class="comment"># image_to_tfrecord_by_filename.py——把验证码转换成tfrecord文件</span></span><br><span class="line"><span class="comment">#tfrecord文件，底层就是protobuf格式</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line"><span class="comment">#验证集数量</span></span><br><span class="line">tf.app.flags.DEFINE_integer(<span class="string">"num_validation"</span>, <span class="number">500</span>, </span><br><span class="line">    <span class="string">"the divisiory number of validation data"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#随机种子</span></span><br><span class="line">tf.app.flags.DEFINE_integer(<span class="string">"random_seed"</span>, <span class="number">7</span>, </span><br><span class="line">    <span class="string">"random seed"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#图片目录</span></span><br><span class="line">tf.app.flags.DEFINE_string(<span class="string">"dataset_dir"</span>, <span class="string">"D:/Tensorflow/captcha/images/"</span>, </span><br><span class="line">    <span class="string">"dir of images and save position"</span>)</span><br><span class="line">    </span><br><span class="line"><span class="comment">#保存tfrecord目录</span></span><br><span class="line">tf.app.flags.DEFINE_string(<span class="string">"tfrecord_dir"</span>, <span class="string">"D:/Tensorflow/captcha/"</span>, </span><br><span class="line">    <span class="string">"dir of tfrecord"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">FLAGS = tf.app.flags.FLAGS</span><br><span class="line"></span><br><span class="line"><span class="comment">#判断tfrecord文件是否存在</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_dataset_exists</span><span class="params">(dataset_dir)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> split_name <span class="keyword">in</span> [<span class="string">"train"</span>, <span class="string">"validation"</span>]:</span><br><span class="line">        output_filename = os.path.join(dataset_dir, split_name + <span class="string">".tfrecord"</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> tf.gfile.Exists(output_filename):</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">False</span></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">True</span></span><br><span class="line">    </span><br><span class="line"><span class="comment">#获取总图片文件夹下的 所有图片文件名以及分类（子文件夹名）</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_get_filenames_and_classes</span><span class="params">(dataset_dir)</span>:</span></span><br><span class="line">    photo_filenames = []</span><br><span class="line">    <span class="keyword">for</span> filename <span class="keyword">in</span> os.listdir(dataset_dir):</span><br><span class="line">        <span class="comment">#合并文件路径</span></span><br><span class="line">        path = os.path.join(dataset_dir, filename)</span><br><span class="line">        photo_filenames.append(path) </span><br><span class="line">    <span class="keyword">return</span> photo_filenames</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">int64_feature</span><span class="params">(values)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> isinstance(values, (tuple, list)):</span><br><span class="line">        values = [values]</span><br><span class="line">    <span class="keyword">return</span> tf.train.Feature(int64_list=tf.train.Int64List(value=values))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bytes_feature</span><span class="params">(values)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> tf.train.Feature(bytes_list=tf.train.BytesList(value=[values]))</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">image_to_tfexample</span><span class="params">(image_data, label0, label1, label2, label3)</span>:</span></span><br><span class="line">    <span class="comment">#Abstract base class for protocol message</span></span><br><span class="line">    <span class="keyword">return</span> tf.train.Example(features=tf.train.Features(feature=&#123;</span><br><span class="line">        <span class="string">"image"</span>: bytes_feature(image_data),</span><br><span class="line">        <span class="string">"label0"</span>: int64_feature(label0),</span><br><span class="line">        <span class="string">"label1"</span>: int64_feature(label1),</span><br><span class="line">        <span class="string">"label2"</span>: int64_feature(label2),</span><br><span class="line">        <span class="string">"label3"</span>: int64_feature(label3),</span><br><span class="line">    &#125;))</span><br><span class="line"></span><br><span class="line"><span class="comment">#把数据转为tfrecord格式</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_convert_dataset</span><span class="params">(split_name, filenames, dataset_dir)</span>:</span></span><br><span class="line">    <span class="keyword">assert</span> split_name <span class="keyword">in</span> [<span class="string">"train"</span>, <span class="string">"validation"</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        <span class="comment">#定义tfrecord文件路径</span></span><br><span class="line">        output_filename = os.path.join(FLAGS.tfrecord_dir, split_name + <span class="string">".tfrecord"</span>)</span><br><span class="line">        <span class="keyword">with</span> tf.python_io.TFRecordWriter(output_filename) <span class="keyword">as</span> tfrecord_writer:</span><br><span class="line">            <span class="keyword">for</span> i, filename <span class="keyword">in</span> enumerate(filenames):</span><br><span class="line">                <span class="keyword">try</span>:</span><br><span class="line">                    sys.stdout.write(<span class="string">"\r&gt;&gt; Converting image(%s) %d/%d"</span> % (split_name, i+<span class="number">1</span>, len(filenames)))</span><br><span class="line">                    sys.stdout.flush()</span><br><span class="line">                    </span><br><span class="line">                    <span class="comment">#读取图片</span></span><br><span class="line">                    image_data = Image.open(filename)</span><br><span class="line">                    <span class="comment">#根据模型的结构resize</span></span><br><span class="line">                    image_data = image_data.resize((<span class="number">224</span>, <span class="number">224</span>))</span><br><span class="line">                    <span class="comment">#灰度化</span></span><br><span class="line">                    image_data = np.array(image_data.convert(<span class="string">"L"</span>))</span><br><span class="line">                    <span class="comment">#将图片转化为bytes</span></span><br><span class="line">                    image_data = image_data.tobytes()</span><br><span class="line">                    </span><br><span class="line">                    <span class="comment">#获取label</span></span><br><span class="line">                    labels = filename.split(<span class="string">"/"</span>)[<span class="number">-1</span>][<span class="number">0</span>:<span class="number">4</span>]</span><br><span class="line">                    num_labels = []</span><br><span class="line">                    <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">4</span>):</span><br><span class="line">                        num_labels.append(int(labels[j]))</span><br><span class="line"></span><br><span class="line">                    <span class="comment">#生成tfrecord文件</span></span><br><span class="line">                    example = image_to_tfexample(image_data, num_labels[<span class="number">0</span>], num_labels[<span class="number">1</span>], num_labels[<span class="number">2</span>], num_labels[<span class="number">3</span>])</span><br><span class="line">                    tfrecord_writer.write(example.SerializeToString())</span><br><span class="line">                <span class="keyword">except</span> IOError <span class="keyword">as</span> e:</span><br><span class="line">                    print(<span class="string">"Could not read:"</span>, filenames[i])</span><br><span class="line">                    print(<span class="string">"Error:"</span>,e)</span><br><span class="line">                    print(<span class="string">"Skip the pic.\n"</span>)</span><br><span class="line">    sys.stdout.write(<span class="string">"\n"</span>)</span><br><span class="line">    sys.stdout.flush()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(_)</span>:</span></span><br><span class="line">    <span class="comment">#判断tfrecord文件是否存在</span></span><br><span class="line">    <span class="keyword">if</span> _dataset_exists(FLAGS.tfrecord_dir):</span><br><span class="line">        print(<span class="string">"tfrecord文件已存在"</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment">#获得所有图片以及分类</span></span><br><span class="line">        photo_filenames = _get_filenames_and_classes(FLAGS.dataset_dir)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#数据切分为训练集和测试集</span></span><br><span class="line">        random.seed(FLAGS.random_seed)</span><br><span class="line">        random.shuffle(photo_filenames)</span><br><span class="line">        training_filenames = photo_filenames[FLAGS.num_validation:] <span class="comment">#500之后的图片作为训练</span></span><br><span class="line">        validation_filenames = photo_filenames[:FLAGS.num_validation] <span class="comment">#0-500的图片作为训练</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">#数据转换</span></span><br><span class="line">        _convert_dataset(<span class="string">"train"</span>, training_filenames, FLAGS.dataset_dir)</span><br><span class="line">        _convert_dataset(<span class="string">"validation"</span>, validation_filenames, FLAGS.dataset_dir)</span><br><span class="line">        print(<span class="string">"finished."</span>)</span><br><span class="line">                            </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    tf.app.run()</span><br></pre></td></tr></table></figure></p><blockquote><blockquote><p>Converting image(train) 5858/5858<br>Converting image(validation) 500/500<br>finished.</p></blockquote></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;1-生成验证码图片&quot;&gt;&lt;a href=&quot;#1-生成验证码图片&quot; class=&quot;headerlink&quot; title=&quot;1 生成验证码图片&quot;&gt;&lt;/a&gt;1 生成验证码图片&lt;/h2&gt;&lt;p&gt;这些生成的图片位于同一个文件夹下，而且图片名就是 label 值。&lt;br&gt;&lt;img 
      
    
    </summary>
    
      <category term="tensorflow" scheme="http://yoursite.com/categories/tensorflow/"/>
    
    
      <category term="alexnet" scheme="http://yoursite.com/tags/alexnet/"/>
    
      <category term="slim" scheme="http://yoursite.com/tags/slim/"/>
    
      <category term="tfrecord" scheme="http://yoursite.com/tags/tfrecord/"/>
    
  </entry>
  
  <entry>
    <title>anaconda安装命令整理</title>
    <link href="http://yoursite.com/2018/04/25/install%20and%20config/anaconda%E5%AE%89%E8%A3%85%E5%91%BD%E4%BB%A4%E6%95%B4%E7%90%86/"/>
    <id>http://yoursite.com/2018/04/25/install and config/anaconda安装命令整理/</id>
    <published>2018-04-24T16:00:00.000Z</published>
    <updated>2018-06-24T13:16:52.554Z</updated>
    
    <content type="html"><![CDATA[<h1 id="查看库版本"><a href="#查看库版本" class="headerlink" title="查看库版本"></a>查看库版本</h1><p>anaconda 查看版本号，以tensorflow为例</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda list tensorflow</span><br></pre></td></tr></table></figure><h1 id="安装命令"><a href="#安装命令" class="headerlink" title="安装命令"></a>安装命令</h1><h2 id="Tensorflow-安装（以windows版本为例）"><a href="#Tensorflow-安装（以windows版本为例）" class="headerlink" title="Tensorflow 安装（以windows版本为例）"></a>Tensorflow 安装（以windows版本为例）</h2><p>S1. 查找所有Tensorflow版本：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">anaconda search -t conda tensorflow</span><br></pre></td></tr></table></figure></p><p>找到windows版本<br><img src="/2018/04/25/install and config/anaconda安装命令整理/2018-04-25-14-17-21.png" alt=""><br>S2. 显示该版本的安装命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">anaconda show dhirschfeld/tensorflow</span><br></pre></td></tr></table></figure></p><p>S3. 使用所提示的安装命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install --channel https://conda.anaconda.org/dhirschfeld tensorflow</span><br></pre></td></tr></table></figure></p><h2 id="tflearn-安装（以windows版本为例）"><a href="#tflearn-安装（以windows版本为例）" class="headerlink" title="tflearn 安装（以windows版本为例）"></a>tflearn 安装（以windows版本为例）</h2><p>用<code>pip install tflearn</code>命令安装tflearn后，运行下面代码，如果出现警告<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> division, print_function, absolute_import  </span><br><span class="line"><span class="keyword">import</span> tflearn</span><br></pre></td></tr></table></figure></p><p>“curses is not supported on this machine (please install/reinstall curses for an optimal experience”</p><p>使用命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip search curses</span><br></pre></td></tr></table></figure></p><p>再执行下面命令以安装windows版本的curses<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install windows-curses</span><br></pre></td></tr></table></figure></p><h1 id="卸载命令"><a href="#卸载命令" class="headerlink" title="卸载命令"></a>卸载命令</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip uninstall xxx</span><br></pre></td></tr></table></figure><p>or<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda uninstall xxx</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;查看库版本&quot;&gt;&lt;a href=&quot;#查看库版本&quot; class=&quot;headerlink&quot; title=&quot;查看库版本&quot;&gt;&lt;/a&gt;查看库版本&lt;/h1&gt;&lt;p&gt;anaconda 查看版本号，以tensorflow为例&lt;/p&gt;
&lt;figure class=&quot;highlight 
      
    
    </summary>
    
      <category term="install and config" scheme="http://yoursite.com/categories/install-and-config/"/>
    
    
      <category term="anaconda" scheme="http://yoursite.com/tags/anaconda/"/>
    
  </entry>
  
  <entry>
    <title>jupyter设置</title>
    <link href="http://yoursite.com/2018/04/25/install%20and%20config/jupyter%E8%AE%BE%E7%BD%AE/"/>
    <id>http://yoursite.com/2018/04/25/install and config/jupyter设置/</id>
    <published>2018-04-24T16:00:00.000Z</published>
    <updated>2018-06-24T13:17:12.253Z</updated>
    
    <content type="html"><![CDATA[<h2 id="更改启动目录"><a href="#更改启动目录" class="headerlink" title="更改启动目录"></a>更改启动目录</h2><p>右键jupyter notebook快捷方式属性，把“目标”属性最后的变量改为自己的路径，如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;C:\\Users\\lenovo\\Desktop\\Python WORK SPACE\\&quot;</span><br></pre></td></tr></table></figure></p><p>注意前面一个空格要保留</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;更改启动目录&quot;&gt;&lt;a href=&quot;#更改启动目录&quot; class=&quot;headerlink&quot; title=&quot;更改启动目录&quot;&gt;&lt;/a&gt;更改启动目录&lt;/h2&gt;&lt;p&gt;右键jupyter notebook快捷方式属性，把“目标”属性最后的变量改为自己的路径，如下：&lt;br&gt;&lt;f
      
    
    </summary>
    
      <category term="install and config" scheme="http://yoursite.com/categories/install-and-config/"/>
    
    
  </entry>
  
  <entry>
    <title>Tensorflow学习9-5：谷歌inception-v3模型 之 fine-tune slim alexnet</title>
    <link href="http://yoursite.com/2018/04/24/tensorflow/Tensorflow%E5%AD%A6%E4%B9%A09-5%EF%BC%9A%E8%B0%B7%E6%AD%8Cinception-v3%E6%A8%A1%E5%9E%8B%20%E4%B9%8B%20fine-tune%20slim%20alexnet/"/>
    <id>http://yoursite.com/2018/04/24/tensorflow/Tensorflow学习9-5：谷歌inception-v3模型 之 fine-tune slim alexnet/</id>
    <published>2018-04-23T16:10:27.000Z</published>
    <updated>2018-07-16T05:50:55.134Z</updated>
    
    <content type="html"><![CDATA[<p>进行 fine-tune 操作需要微调训练所有层，所以迭代训练次数比较多。</p><h2 id="1-数据准备"><a href="#1-数据准备" class="headerlink" title="1 数据准备"></a>1 数据准备</h2><p>准备好tfrecord格式的图片数据文件，和labels.txt。可以参考上篇。</p><h2 id="2-定义新的dataset文件"><a href="#2-定义新的dataset文件" class="headerlink" title="2 定义新的dataset文件"></a>2 定义新的dataset文件</h2><p>首先，在dataset/目录下新建一个文件夹 satellite.py，并将flowers.py文件夹中的内容复制到 satellite.py 中，接下来需要修改以下几处内容。</p><p>第一处修改，<br><img src="/2018/04/24/tensorflow/Tensorflow学习9-5：谷歌inception-v3模型 之 fine-tune slim alexnet/Tensorflow学习9-5：谷歌inception-v3模型%20之%20fine-tune%20slim%20alexnet/2018-07-09-18-44-03.png" alt=""></p><p>第二处修改修改为image/format部分<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'image/format'</span>: tf.FixedLenFeature((), tf.string, default_value=<span class="string">'jpg'</span>),</span><br></pre></td></tr></table></figure></p><p>修改完 satellite.py后，还需要在同目录的dataset_factory.py文件夹中注册satellite数据库。红色框内为新增加的satellite数据<br><img src="/2018/04/24/tensorflow/Tensorflow学习9-5：谷歌inception-v3模型 之 fine-tune slim alexnet/Tensorflow学习9-5：谷歌inception-v3模型%20之%20fine-tune%20slim%20alexnet/2018-07-09-18-47-23.png" alt=""></p><h2 id="3-下载训练好的inception-v3模型"><a href="#3-下载训练好的inception-v3模型" class="headerlink" title="3 下载训练好的inception-v3模型"></a>3 下载训练好的inception-v3模型</h2><p>在<a href="http://download.tensorflow.org/models/inception_v3_2016_08_28.tar.gz" target="_blank" rel="noopener">http://download.tensorflow.org/models/inception_v3_2016_08_28.tar.gz</a> 下载并解压后，会得到一个inception_v3.ckpt 文件</p><h2 id="4-开始训练"><a href="#4-开始训练" class="headerlink" title="4 开始训练"></a>4 开始训练</h2><p>在slim文件夹下运行下面脚本开始训练：<br>（★注意：如果softmax报错，修改文件<code>D:\Anaconda3\Lib\site-packages\tensorflow\python\framework\ops.py</code>第3385行，在函数 create_op() 内新增一行<code>with tf.device(&#39;/cpu:0&#39;):</code></p><p><img src="/2018/04/24/tensorflow/Tensorflow学习9-5：谷歌inception-v3模型 之 fine-tune slim alexnet/Tensorflow学习9-5：谷歌inception-v3模型%20之%20fine-tune%20slim%20alexnet/2018-07-16-13-50-37.png" alt=""><br>）<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">python train_image_classifier.py ^</span><br><span class="line">--train_dir=model2:训练好的模型存放目录 ^</span><br><span class="line">--dataset_name=satellite :用于读取tfrecord数据集的python文件 ^</span><br><span class="line">--dataset_split_name=train :这里使用切分的训练集 ^</span><br><span class="line">--dataset_dir=images2 :tfrecord文件目录 ^</span><br><span class="line">--batch_size=5 :GPU内存小的建议不要改大，否则报错 ^</span><br><span class="line">--max_number_of_steps=1000 :训练次数 ^</span><br><span class="line">--model_name=inception_v3 :训练模型 ^</span><br><span class="line">--checkpoint_path=D:/Tensorflow/models/inception2016/inception_v3.ckpt :fine-tune专用^</span><br><span class="line">--checkpoint_exclude_scopes=InceptionV3/Logits,InceptionV3/AuxLogits :fine-tune专用^</span><br><span class="line">--trainable_scopes=InceptionV3/Logits,InceptionV3/AuxLogits :fine-tune专用^</span><br><span class="line">--learning_rate=0.001  ^</span><br><span class="line">--learning_rate_decay_type=fixed  ^</span><br><span class="line">--save_interval_secs=300  ^</span><br><span class="line">--save_summaries_secs=2  ^</span><br><span class="line">--log_every_n_steps=10  ^</span><br><span class="line">--optimizer=rmsprop  ^</span><br><span class="line">--weight_decay=0.00004  ^</span><br><span class="line">--clone_on_cpu=false   :可以设置为true指定CPU执行</span><br><span class="line">pause</span><br></pre></td></tr></table></figure></p><p>如图，一般训练10000步左右可以达到准确率要求，ctrl+c 停止脚本程序<br><img src="/2018/04/24/tensorflow/Tensorflow学习9-5：谷歌inception-v3模型 之 fine-tune slim alexnet/Tensorflow学习9-5：谷歌inception-v3模型%20之%20fine-tune%20slim%20alexnet/2018-07-09-20-10-03.png" alt=""></p><h2 id="5-验证模型准确率"><a href="#5-验证模型准确率" class="headerlink" title="5 验证模型准确率"></a>5 验证模型准确率</h2><p>可以用eval_image_classifier.py程序进行验证，在slim文件夹下运行以下脚本</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">python test_image_classifier.py ^</span><br><span class="line">--checkpoint_path=model2 ^</span><br><span class="line">--eval_dir=validation_result ^</span><br><span class="line">--dataset_name=satellite ^</span><br><span class="line">--dataset_split_name=validation ^</span><br><span class="line">--dataset_dir=images2 ^</span><br><span class="line">--model_name=inception_v3</span><br><span class="line">pause</span><br></pre></td></tr></table></figure><p>得到训练后模型的accuracy结果：</p><p><img src="/2018/04/24/tensorflow/Tensorflow学习9-5：谷歌inception-v3模型 之 fine-tune slim alexnet/Tensorflow学习9-5：谷歌inception-v3模型%20之%20fine-tune%20slim%20alexnet/2018-07-09-20-14-09.png" alt=""></p><h2 id="6-导出模型，并对单张图片进行识别"><a href="#6-导出模型，并对单张图片进行识别" class="headerlink" title="6 导出模型，并对单张图片进行识别"></a>6 导出模型，并对单张图片进行识别</h2><h3 id="STEP-1-导出网络结构"><a href="#STEP-1-导出网络结构" class="headerlink" title="STEP 1:导出网络结构"></a>STEP 1:导出网络结构</h3><p>在slim文件夹下运行以下脚本<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">python export_inference_graph.py ^</span><br><span class="line">--alsologtostderr ^</span><br><span class="line">--model_name=inception_v3 ^</span><br><span class="line">--output_file=model2/inception_v3_inf_graph.pb ^</span><br><span class="line">--dataset_name=satellite</span><br><span class="line">pause</span><br></pre></td></tr></table></figure></p><p>这个命令会在 model2 文件夹下生成一个inception_v3_inf_graph.pb文件。（注：inception_v3_inf_graph.pb文件夹只保存了inception_v3的网络结构并不包含训练得到的模型。</p><h3 id="STEP-2-生成完整的-pd-模型文件"><a href="#STEP-2-生成完整的-pd-模型文件" class="headerlink" title="STEP 2:生成完整的 .pd 模型文件"></a>STEP 2:生成完整的 .pd 模型文件</h3><p>运行下面脚本，将checkpoint中的模型参数保存进来，转换成完整的模型文件。（需将8100改成model文件夹中保存的实际的模型训练步数）<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">python freeze_graph.py ^</span><br><span class="line">--input_graph=model2/inception_v3_inf_graph.pb ^</span><br><span class="line">--input_checkpoint=model2/model.ckpt-8100 ^</span><br><span class="line">--input_binary=true ^</span><br><span class="line">--output_node_names=InceptionV3/Predictions/Reshape_1 ^</span><br><span class="line">--output_graph=model2/frozen_graph.pb</span><br><span class="line">pause</span><br></pre></td></tr></table></figure></p><h3 id="STEP-3-运行导出模型分类单张图片"><a href="#STEP-3-运行导出模型分类单张图片" class="headerlink" title="STEP 3:运行导出模型分类单张图片"></a>STEP 3:运行导出模型分类单张图片</h3><p>运行下面脚本<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">python test_image_classifier.py ^</span><br><span class="line">--model_path model2/frozen_graph.pb ^</span><br><span class="line">--label_path images2/labels.txt ^</span><br><span class="line">--image_file test_images/water.jpg</span><br><span class="line">pause</span><br></pre></td></tr></table></figure></p><p>分类结果如下：</p><p><img src="/2018/04/24/tensorflow/Tensorflow学习9-5：谷歌inception-v3模型 之 fine-tune slim alexnet/Tensorflow学习9-5：谷歌inception-v3模型%20之%20fine-tune%20slim%20alexnet/2018-07-09-20-24-10.png" alt=""></p><hr><p>总结：<br>脚本的运行顺序如图编号所示<br><img src="/2018/04/24/tensorflow/Tensorflow学习9-5：谷歌inception-v3模型 之 fine-tune slim alexnet/Tensorflow学习9-5：谷歌inception-v3模型%20之%20fine-tune%20slim%20alexnet/2018-07-15-19-31-55.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;进行 fine-tune 操作需要微调训练所有层，所以迭代训练次数比较多。&lt;/p&gt;
&lt;h2 id=&quot;1-数据准备&quot;&gt;&lt;a href=&quot;#1-数据准备&quot; class=&quot;headerlink&quot; title=&quot;1 数据准备&quot;&gt;&lt;/a&gt;1 数据准备&lt;/h2&gt;&lt;p&gt;准备好tfreco
      
    
    </summary>
    
      <category term="tensorflow" scheme="http://yoursite.com/categories/tensorflow/"/>
    
    
      <category term="slim" scheme="http://yoursite.com/tags/slim/"/>
    
      <category term="fine-tune" scheme="http://yoursite.com/tags/fine-tune/"/>
    
      <category term="inception-v3" scheme="http://yoursite.com/tags/inception-v3/"/>
    
  </entry>
  
  <entry>
    <title>markdown语法</title>
    <link href="http://yoursite.com/2018/04/24/hexo/markdown%E8%AF%AD%E6%B3%95/"/>
    <id>http://yoursite.com/2018/04/24/hexo/markdown语法/</id>
    <published>2018-04-23T16:00:00.000Z</published>
    <updated>2018-04-24T15:35:19.893Z</updated>
    
    <content type="html"><![CDATA[<h2 id="markdown语法"><a href="#markdown语法" class="headerlink" title="markdown语法"></a>markdown语法</h2><p>空格：输入法全角状态下space</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;markdown语法&quot;&gt;&lt;a href=&quot;#markdown语法&quot; class=&quot;headerlink&quot; title=&quot;markdown语法&quot;&gt;&lt;/a&gt;markdown语法&lt;/h2&gt;&lt;p&gt;空格：输入法全角状态下space&lt;/p&gt;

      
    
    </summary>
    
      <category term="hexo" scheme="http://yoursite.com/categories/hexo/"/>
    
    
      <category term="markdown" scheme="http://yoursite.com/tags/markdown/"/>
    
  </entry>
  
  <entry>
    <title>Tensorflow学习5-3：Tensorboard可视化</title>
    <link href="http://yoursite.com/2018/04/23/tensorflow/Tensorflow%E5%AD%A6%E4%B9%A05-3%EF%BC%9ATensorboard%E5%8F%AF%E8%A7%86%E5%8C%96/"/>
    <id>http://yoursite.com/2018/04/23/tensorflow/Tensorflow学习5-3：Tensorboard可视化/</id>
    <published>2018-04-22T19:51:27.000Z</published>
    <updated>2018-07-15T09:21:30.709Z</updated>
    
    <content type="html"><![CDATA[<p>对 5-2 进行修改，加入放映器（projector）实现分类过程中图片可视化</p><h2 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line"><span class="keyword">from</span> tensorflow.contrib.tensorboard.plugins <span class="keyword">import</span> projector</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#载入数据集</span></span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">"MNIST_data"</span>, one_hot=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ---------------------------NEW ADD 1</span></span><br><span class="line"><span class="comment">#运行次数</span></span><br><span class="line">max_steps = <span class="number">31</span></span><br><span class="line"><span class="comment">#图片数量</span></span><br><span class="line">image_num = <span class="number">3000</span></span><br><span class="line"><span class="comment">#文件路径</span></span><br><span class="line">DIR = <span class="string">"D:/Tensorflow/"</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#定义会话 </span></span><br><span class="line">sess = tf.Session()</span><br><span class="line"></span><br><span class="line"><span class="comment">#载入图片（将n个行向量堆叠起来）</span></span><br><span class="line">embedding = tf.Variable(tf.stack(mnist.test.images[:image_num]), trainable=<span class="keyword">False</span>, name = <span class="string">"embadding"</span>)</span><br><span class="line"><span class="comment"># ------------------------------------</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#每个批次大小</span></span><br><span class="line">batch_size = <span class="number">100</span></span><br></pre></td></tr></table></figure><p>Extracting MNIST_data\train-images-idx3-ubyte.gz<br>Extracting MNIST_data\train-labels-idx1-ubyte.gz<br>Extracting MNIST_data\t10k-images-idx3-ubyte.gz<br>Extracting MNIST_data\t10k-labels-idx1-ubyte.gz</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># STEP 1 设计统计函数，用于计算传入的张量的各种统计量</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">variable_summary</span><span class="params">(var)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">"summary"</span>):</span><br><span class="line">        mean = tf.reduce_mean(var)</span><br><span class="line">        tf.summary.scalar(<span class="string">"mean"</span>, mean) <span class="comment">#平均值</span></span><br><span class="line">        <span class="keyword">with</span> tf.name_scope(<span class="string">"stddev"</span>):</span><br><span class="line">            stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))</span><br><span class="line">        tf.summary.scalar(<span class="string">"stddev"</span>, stddev) <span class="comment">#标准差</span></span><br><span class="line">        tf.summary.scalar(<span class="string">"max"</span>, tf.reduce_max(var)) <span class="comment">#最大值</span></span><br><span class="line">        tf.summary.scalar(<span class="string">"min"</span>, tf.reduce_min(var)) <span class="comment">#最小值</span></span><br><span class="line">        tf.summary.histogram(<span class="string">"histogram"</span>, var) <span class="comment">#直方图</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">''' DEL  这次数据集很大，不计算批次数，而是自己指定 batch_num 即 max_steps</span></span><br><span class="line"><span class="string">#计算有多少批次 = 总数 // 批次</span></span><br><span class="line"><span class="string">batch_num = mnist.train.num_examples // batch_size</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"input"</span>):</span><br><span class="line">    input_x = tf.placeholder(tf.float32, [<span class="keyword">None</span>, <span class="number">784</span>], name=<span class="string">"input_x"</span>)</span><br><span class="line">    input_y = tf.placeholder(tf.float32, [<span class="keyword">None</span>, <span class="number">10</span>], name=<span class="string">"input_y"</span>)</span><br><span class="line">    </span><br><span class="line"><span class="comment"># --------------------------------NEW ADD 2</span></span><br><span class="line"><span class="comment">#显示图片</span></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"input_reshape"</span>):</span><br><span class="line">    image_shape_input = tf.reshape(input_x, [<span class="number">-1</span>,<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>]) <span class="comment"># -1表示未知</span></span><br><span class="line">    tf.summary.image(<span class="string">"input"</span>, image_shape_input, <span class="number">10</span>) <span class="comment"># 10张图片用来在 IMAGES 选项中预览</span></span><br><span class="line"><span class="comment"># ------------------------------------</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#创建神经网络模型</span></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"layers"</span>):</span><br><span class="line">    W1 = tf.Variable(tf.truncated_normal([<span class="number">784</span>,<span class="number">128</span>], <span class="number">0.</span>,<span class="number">0.5</span>), name=<span class="string">"W1"</span>)</span><br><span class="line">    variable_summary(W1) <span class="comment"># STEP 2.1</span></span><br><span class="line">    b1 = tf.Variable(tf.zeros([<span class="number">128</span>]) + <span class="number">0.1</span>, name=<span class="string">"b1"</span>)</span><br><span class="line">    variable_summary(b1) <span class="comment"># STEP 2.1</span></span><br><span class="line">    L1 = tf.nn.relu(tf.matmul(input_x, W1) + b1, name=<span class="string">"L1"</span>)</span><br><span class="line"></span><br><span class="line">    W2 = tf.Variable(tf.truncated_normal([<span class="number">128</span>,<span class="number">10</span>], <span class="number">0.</span>,<span class="number">0.5</span>), name=<span class="string">"W2"</span>)</span><br><span class="line">    b2 = tf.Variable(tf.zeros([<span class="number">10</span>]) + <span class="number">0.1</span>, name=<span class="string">"b2"</span>)</span><br><span class="line">    L2 = tf.add(tf.matmul(L1, W2), b2, name=<span class="string">"L2"</span>)</span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"loss"</span>):</span><br><span class="line">    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=L2, labels=input_y))</span><br><span class="line">    tf.summary.scalar(<span class="string">"loss"</span>, loss) <span class="comment"># STEP 2.2</span></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"train_and_optimizer"</span>):</span><br><span class="line">    train = tf.train.GradientDescentOptimizer(<span class="number">0.2</span>).minimize(loss)</span><br><span class="line"></span><br><span class="line"><span class="comment">#获取用于显示的精度——优化效果</span></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"accuracy"</span>):</span><br><span class="line">    correct_indices = tf.equal(tf.argmax(input_y, <span class="number">1</span>), tf.argmax(L2, <span class="number">1</span>))</span><br><span class="line">    accuracy = tf.reduce_mean(tf.cast(correct_indices, tf.float32))</span><br><span class="line">    tf.summary.scalar(<span class="string">"accuracy"</span>, accuracy) <span class="comment"># STEP 2.2</span></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"><span class="comment"># -----------------------NEW ADD 3</span></span><br><span class="line"><span class="comment">#产生metadata文件，写入测试集的10进制labels</span></span><br><span class="line"><span class="keyword">if</span> tf.gfile.Exists(DIR + <span class="string">"projector/projector/meadata.tsv"</span>):</span><br><span class="line">    tf.gfile.DeleteRecursively(DIR + <span class="string">"projector/projector/metadata.tsv"</span>)</span><br><span class="line"><span class="keyword">with</span> open(DIR + <span class="string">"projector/projector/metadata.tsv"</span>, <span class="string">"w"</span>) <span class="keyword">as</span> f:</span><br><span class="line">    labels = sess.run(tf.argmax(mnist.test.labels[:], <span class="number">1</span>)) <span class="comment"># 把one-hot转为10进制标签</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(image_num):</span><br><span class="line">        f.write(str(labels[i]) + <span class="string">"\n"</span>)</span><br><span class="line">        </span><br><span class="line">projector_writer = tf.summary.FileWriter(DIR + <span class="string">"projector/projector/"</span>, sess.graph)     </span><br><span class="line">saver = tf.train.Saver() <span class="comment">#保存模型</span></span><br><span class="line">config = projector.ProjectorConfig()</span><br><span class="line">embed = config.embeddings.add()</span><br><span class="line">embed.tensor_name = embedding.name</span><br><span class="line">embed.metadata_path = DIR + <span class="string">"projector/projector/metadata.tsv"</span></span><br><span class="line">embed.sprite.image_path = DIR + <span class="string">"projector/data/mnist_10k_sprite.png"</span></span><br><span class="line">embed.sprite.single_image_dim.extend([<span class="number">28</span>,<span class="number">28</span>])</span><br><span class="line">projector.visualize_embeddings(projector_writer, config)</span><br><span class="line"><span class="comment"># ------------------------------------</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># STEP 3:合并所有summary</span></span><br><span class="line">merged = tf.summary.merge_all()</span><br><span class="line"></span><br><span class="line"><span class="string">''' DEL </span></span><br><span class="line"><span class="string">init = tf.global_variables_initializer()</span></span><br><span class="line"><span class="string">with tf.Session() as sess:</span></span><br><span class="line"><span class="string">    sess.run(init)</span></span><br><span class="line"><span class="string">    # STEP 2</span></span><br><span class="line"><span class="string">    writer = tf.summary.FileWriter("D:/Tensorflow/logs", sess.graph)</span></span><br><span class="line"><span class="string">    for epoch in range(5):</span></span><br><span class="line"><span class="string">        for batch in range(batch_num):</span></span><br><span class="line"><span class="string">            batch_xs, batch_ys = mnist.train.next_batch(batch_size)</span></span><br><span class="line"><span class="string">            # STEP 4:每次训练，计算一次merge summary</span></span><br><span class="line"><span class="string">            summary,_ = sess.run([merged, train], feed_dict=&#123;input_x:batch_xs, input_y:batch_ys&#125;)</span></span><br><span class="line"><span class="string">        # STEP 5:选择多久更新写入一次summary</span></span><br><span class="line"><span class="string">        writer.add_summary(summary, epoch)</span></span><br><span class="line"><span class="string">        _accuracy = sess.run(accuracy, feed_dict=&#123;input_x:mnist.test.images, input_y:mnist.test.labels&#125;)</span></span><br><span class="line"><span class="string">        print("epoch:"+ str(epoch) + ", accuracy:"+ str(_accuracy))</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># -----------------------NEW ADD 4：由于自己指定batch_num 数量很多，所以不需要来回迭代，修改如下</span></span><br><span class="line">sess.run(tf.global_variables_initializer())</span><br><span class="line"></span><br><span class="line">writer = tf.summary.FileWriter(<span class="string">"D:/Tensorflow/logs"</span>, sess.graph)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(max_steps):</span><br><span class="line">    batch_xs, batch_ys = mnist.train.next_batch(batch_size)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 这里加入2个参数</span></span><br><span class="line">    run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)</span><br><span class="line">    run_metadata = tf.RunMetadata()</span><br><span class="line">    summary,_ = sess.run([merged, train], feed_dict=&#123;input_x:batch_xs, input_y:batch_ys&#125;, </span><br><span class="line">                         options = run_options, run_metadata = run_metadata)</span><br><span class="line">    </span><br><span class="line">    projector_writer.add_run_metadata(run_metadata, <span class="string">"step%03d"</span> % i)</span><br><span class="line">    projector_writer.add_summary(summary, i)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> i%<span class="number">3</span> == <span class="number">0</span>:</span><br><span class="line">        _accuracy = sess.run(accuracy, feed_dict=&#123;input_x:mnist.test.images, input_y:mnist.test.labels&#125;)</span><br><span class="line">        print(<span class="string">"step:"</span>+ str(i) + <span class="string">", accuracy:"</span>+ str(_accuracy))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型保存到如下路径</span></span><br><span class="line">saver.save(sess, DIR + <span class="string">"projector/projector/a_model.ckpt"</span>, global_step = max_steps)</span><br><span class="line">projector_writer.close()</span><br><span class="line">sess.close()</span><br><span class="line"></span><br><span class="line"><span class="comment"># -----------------------------</span></span><br></pre></td></tr></table></figure><p>step:0, accuracy:0.1275<br>step:3, accuracy:0.3143<br>step:6, accuracy:0.5248<br>step:9, accuracy:0.5986<br>step:12, accuracy:0.6266<br>step:15, accuracy:0.6751<br>step:18, accuracy:0.6905<br>step:21, accuracy:0.7041<br>step:24, accuracy:0.7387<br>step:27, accuracy:0.747<br>step:30, accuracy:0.7538</p><hr><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>输入下面代码运行</p><pre><code>tensorboard --logdir=D:/Tensorflow/projector/projector</code></pre><p>可以在 Tensorboard 的 IMAGES 和 EMBEDDINGS 选项卡查看新效果</p><p>效果如图：</p><p><img src="/2018/04/23/tensorflow/Tensorflow学习5-3：Tensorboard可视化/2018-07-14-22-38-30.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;对 5-2 进行修改，加入放映器（projector）实现分类过程中图片可视化&lt;/p&gt;
&lt;h2 id=&quot;例子&quot;&gt;&lt;a href=&quot;#例子&quot; class=&quot;headerlink&quot; title=&quot;例子&quot;&gt;&lt;/a&gt;例子&lt;/h2&gt;&lt;figure class=&quot;highlight p
      
    
    </summary>
    
      <category term="tensorflow" scheme="http://yoursite.com/categories/tensorflow/"/>
    
    
      <category term="Tensorboard" scheme="http://yoursite.com/tags/Tensorboard/"/>
    
  </entry>
  
  <entry>
    <title>Tensorflow学习9-4：谷歌inception-v3模型 之 生成tfrecord文件</title>
    <link href="http://yoursite.com/2018/04/23/tensorflow/Tensorflow%E5%AD%A6%E4%B9%A09-4%EF%BC%9A%E8%B0%B7%E6%AD%8Cinception-v3%E6%A8%A1%E5%9E%8B%20%E4%B9%8B%20%E7%94%9F%E6%88%90tfrecord%E6%96%87%E4%BB%B6/"/>
    <id>http://yoursite.com/2018/04/23/tensorflow/Tensorflow学习9-4：谷歌inception-v3模型 之 生成tfrecord文件/</id>
    <published>2018-04-22T16:10:27.000Z</published>
    <updated>2018-07-15T23:37:50.901Z</updated>
    
    <content type="html"><![CDATA[<p>生成tfrecord文件，用于从零训练自己的模型或者fine-tune微调训练。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#tfrecord文件，底层就是protobuf格式</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"><span class="comment">#验证集数量</span></span><br><span class="line">_NUM_VALID = <span class="number">1000</span></span><br><span class="line"><span class="comment">#随机种子</span></span><br><span class="line">_RANDOM_SEED = <span class="number">7</span></span><br><span class="line"><span class="comment">#数据块</span></span><br><span class="line">_NUM_SHARDS = <span class="number">2</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line">DATASET_DIR = <span class="string">"D:/Tensorflow/slim/images2/"</span></span><br><span class="line"><span class="comment">#标签文件名</span></span><br><span class="line">LABELS_FILENAME = <span class="string">"D:/Tensorflow/slim/images2/labels.txt"</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#定义tfrecord文件的路径+名字</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_get_dataset_filename</span><span class="params">(dataset_dir, split_name, shard_id)</span>:</span></span><br><span class="line">    output_filename = <span class="string">"image_%s_%05d-of-%05d.tfrecord"</span> % (split_name, shard_id, _NUM_SHARDS)</span><br><span class="line">    <span class="keyword">return</span> os.path.join(dataset_dir, output_filename)</span><br><span class="line"></span><br><span class="line"><span class="comment">#判断tfrecord文件是否存在</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_dataset_exists</span><span class="params">(dataset_dir)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> split_name <span class="keyword">in</span> [<span class="string">"train"</span>, <span class="string">"validation"</span>]:</span><br><span class="line">        <span class="keyword">for</span> shard_id <span class="keyword">in</span> range(_NUM_SHARDS):</span><br><span class="line">            output_filename = _get_dataset_filename(dataset_dir, split_name, shard_id)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> tf.gfile.Exists(output_filename):</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">False</span></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">True</span></span><br><span class="line">    </span><br><span class="line"><span class="comment">#获取总图片文件夹下的 所有图片文件名以及分类（子文件夹名）</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_get_filenames_and_classes</span><span class="params">(dataset_dir)</span>:</span></span><br><span class="line">    <span class="comment">#数据目录</span></span><br><span class="line">    directories = []</span><br><span class="line">    <span class="comment">#分类名称</span></span><br><span class="line">    class_names = []</span><br><span class="line">    <span class="keyword">for</span> filename <span class="keyword">in</span> os.listdir(dataset_dir):</span><br><span class="line">        <span class="comment">#合并文件路径</span></span><br><span class="line">        path = os.path.join(dataset_dir, filename)</span><br><span class="line">        <span class="comment">#判断该路径是否为目录</span></span><br><span class="line">        <span class="keyword">if</span> os.path.isdir(path):</span><br><span class="line">            <span class="comment">#加入数据目录</span></span><br><span class="line">            directories.append(path)</span><br><span class="line">            <span class="comment">#加入类别名称</span></span><br><span class="line">            class_names.append(filename)</span><br><span class="line">            </span><br><span class="line">    photo_filenames = []</span><br><span class="line">    <span class="comment">#循环每个分类的文件夹</span></span><br><span class="line">    <span class="keyword">for</span> directory <span class="keyword">in</span> directories:</span><br><span class="line">        <span class="keyword">for</span> filename <span class="keyword">in</span> os.listdir(directory):</span><br><span class="line">            path = os.path.join(directory, filename)</span><br><span class="line">            <span class="comment">#把图片加入图片列表</span></span><br><span class="line">            photo_filenames.append(path)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> photo_filenames, class_names</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">int64_feature</span><span class="params">(values)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> isinstance(values, (tuple, list)):</span><br><span class="line">        values = [values]</span><br><span class="line">    <span class="keyword">return</span> tf.train.Feature(int64_list=tf.train.Int64List(value=values))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bytes_feature</span><span class="params">(values)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> tf.train.Feature(bytes_list=tf.train.BytesList(value=[values]))</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">image_to_tfexample</span><span class="params">(image_data, image_format, class_id)</span>:</span></span><br><span class="line">    <span class="comment">#Abstract base class for protocol message</span></span><br><span class="line">    <span class="keyword">return</span> tf.train.Example(features=tf.train.Features(feature=&#123;</span><br><span class="line">        <span class="string">"image/encoded"</span>: bytes_feature(image_data),</span><br><span class="line">        <span class="string">"image/format"</span>: bytes_feature(image_format),</span><br><span class="line">        <span class="string">"image/class/label"</span>: int64_feature(class_id),</span><br><span class="line">    &#125;))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">write_label_file</span><span class="params">(labels_to_class_names, dataset_dir, filename=LABELS_FILENAME)</span>:</span></span><br><span class="line">    labels_filename = os.path.join(dataset_dir, filename)</span><br><span class="line">    <span class="keyword">with</span> tf.gfile.Open(labels_filename, <span class="string">"w"</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> label <span class="keyword">in</span> labels_to_class_names:</span><br><span class="line">            class_name = labels_to_class_names[label]</span><br><span class="line">            f.write(<span class="string">"%d:%s\n"</span> % (label, class_name))</span><br><span class="line"></span><br><span class="line"><span class="comment">#把数据转为tfrecord格式</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_convert_dataset</span><span class="params">(split_name, filenames, class_names_to_ids, dataset_dir)</span>:</span></span><br><span class="line">    <span class="keyword">assert</span> split_name <span class="keyword">in</span> [<span class="string">"train"</span>, <span class="string">"validation"</span>]</span><br><span class="line">    <span class="comment">#切分数据块维多个tfrecord文件，计算每个数据块有多少</span></span><br><span class="line">    num_per_shard = int(len(filenames) / _NUM_SHARDS)</span><br><span class="line">    <span class="keyword">with</span> tf.Graph().as_default():</span><br><span class="line">        <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">            <span class="keyword">for</span> shard_id <span class="keyword">in</span> range(_NUM_SHARDS):</span><br><span class="line">                <span class="comment">#定义tfrecord文件路径</span></span><br><span class="line">                output_filename = _get_dataset_filename(dataset_dir, split_name, shard_id)</span><br><span class="line">                <span class="keyword">with</span> tf.python_io.TFRecordWriter(output_filename) <span class="keyword">as</span> tfrecord_writer:</span><br><span class="line">                    <span class="comment">#每一个数据块开始的位置</span></span><br><span class="line">                    start_ndx = shard_id * num_per_shard</span><br><span class="line">                    <span class="comment">#每一个数据块最后的位置</span></span><br><span class="line">                    end_ndx = min((shard_id+<span class="number">1</span>) * num_per_shard, len(filenames))</span><br><span class="line">                    <span class="keyword">for</span> i <span class="keyword">in</span> range(start_ndx, end_ndx):</span><br><span class="line">                        <span class="keyword">try</span>:</span><br><span class="line">                            sys.stdout.write(<span class="string">"\r&gt;&gt; Converting image(%s) %d/%d shard %d"</span> % (split_name, i+<span class="number">1</span>, len(filenames), shard_id))</span><br><span class="line">                            sys.stdout.flush()</span><br><span class="line">                            <span class="comment">#读取图片</span></span><br><span class="line">                            image_data = tf.gfile.FastGFile(filenames[i], <span class="string">"rb"</span>).read()</span><br><span class="line">                            <span class="comment">#获得图片的类别名称</span></span><br><span class="line">                            class_name = os.path.basename(os.path.dirname(filenames[i]))</span><br><span class="line">                            <span class="comment">#找到类别名称对应的ID</span></span><br><span class="line">                            class_id = class_names_to_ids[class_name]</span><br><span class="line">                            <span class="comment">#生成tfrecord文件</span></span><br><span class="line">                            example = image_to_tfexample(image_data, <span class="string">b"jpg"</span>, class_id)</span><br><span class="line">                            tfrecord_writer.write(example.SerializeToString())</span><br><span class="line">                        <span class="keyword">except</span> IOError <span class="keyword">as</span> e:</span><br><span class="line">                            print(<span class="string">"Could not read:"</span>, filenames[i])</span><br><span class="line">                            print(<span class="string">"Error:"</span>,e)</span><br><span class="line">                            print(<span class="string">"Skip the pic.\n"</span>)</span><br><span class="line">    sys.stdout.write(<span class="string">"\n"</span>)</span><br><span class="line">    sys.stdout.flush()</span><br><span class="line">                            </span><br><span class="line">                            </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    <span class="comment">#判断tfrecord文件是否存在</span></span><br><span class="line">    <span class="keyword">if</span> _dataset_exists(DATASET_DIR):</span><br><span class="line">        print(<span class="string">"tfrecord文件已存在"</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment">#获得所有图片以及分类</span></span><br><span class="line">        photo_filenames, class_names = _get_filenames_and_classes(DATASET_DIR)</span><br><span class="line">        <span class="comment">#吧分类转为字典格式，类似于&#123;"house": 3, "flower": 1&#125;</span></span><br><span class="line">        class_names_to_ids = dict(zip(class_names, range(len(class_names))))</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#数据切分为训练集和测试集</span></span><br><span class="line">        random.seed(_RANDOM_SEED)</span><br><span class="line">        random.shuffle(photo_filenames)</span><br><span class="line">        training_filenames = photo_filenames[_NUM_VALID:] <span class="comment">#500之后的图片作为训练</span></span><br><span class="line">        validation_filenames = photo_filenames[:_NUM_VALID] <span class="comment">#0-500的图片作为训练</span></span><br><span class="line"><span class="comment">#         for var in training_filenames:</span></span><br><span class="line"><span class="comment">#             print("training_filenames: ", os.path.basename(var))</span></span><br><span class="line"><span class="comment">#         for var in validation_filenames:</span></span><br><span class="line"><span class="comment">#             print("validation_filenames: ", os.path.basename(var))</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">#数据转换</span></span><br><span class="line">        _convert_dataset(<span class="string">"train"</span>, training_filenames, class_names_to_ids, DATASET_DIR)</span><br><span class="line">        _convert_dataset(<span class="string">"validation"</span>, validation_filenames, class_names_to_ids, DATASET_DIR)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#输出labels文件</span></span><br><span class="line">        labels_to_class_names = dict(zip(range(len(class_names)), class_names))</span><br><span class="line">        write_label_file(labels_to_class_names, DATASET_DIR)</span><br></pre></td></tr></table></figure><blockquote><blockquote><p>Converting image(train) 3800/3800 shard 1<br>Converting image(validation) 1000/1000 shard 1</p></blockquote></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;生成tfrecord文件，用于从零训练自己的模型或者fine-tune微调训练。&lt;/p&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/sp
      
    
    </summary>
    
      <category term="tensorflow" scheme="http://yoursite.com/categories/tensorflow/"/>
    
    
      <category term="slim" scheme="http://yoursite.com/tags/slim/"/>
    
      <category term="tfrecord" scheme="http://yoursite.com/tags/tfrecord/"/>
    
      <category term="inception-v3" scheme="http://yoursite.com/tags/inception-v3/"/>
    
  </entry>
  
  <entry>
    <title>2模型评估与选择</title>
    <link href="http://yoursite.com/2018/04/21/machine_learning_theory/2%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E4%B8%8E%E9%80%89%E6%8B%A9/"/>
    <id>http://yoursite.com/2018/04/21/machine_learning_theory/2模型评估与选择/</id>
    <published>2018-04-21T04:49:42.000Z</published>
    <updated>2018-05-04T07:56:59.584Z</updated>
    
    <content type="html"><![CDATA[<h2 id="性能度量"><a href="#性能度量" class="headerlink" title="性能度量"></a>性能度量</h2><h3 id="二分类任务的-混淆矩阵-和-其衍生的度量指标"><a href="#二分类任务的-混淆矩阵-和-其衍生的度量指标" class="headerlink" title="二分类任务的 混淆矩阵 和 其衍生的度量指标"></a>二分类任务的 混淆矩阵 和 其衍生的度量指标</h3><p><img src="/2018/04/21/machine_learning_theory/2模型评估与选择/2018-05-04-14-38-40.png" alt=""></p><p>True Positive  （真正, TP） 被模型预测为正样本，是真的判断正确。所以就是正样本，也称作正的数。</p><p>True Negative（真负 , TN）被模型判断为负样本，是真的判断正确。所以就是负样本，也称作负的数。</p><p>False Positive  （假正, FP）被模型判断为正样本，是假的判断错误。所以应该是负样本，也称作误报数。</p><p>False Negative（假负 , FN）被模型判断为负样本，是假的判断错误。所以应该是正样本，也称作漏报数。</p><h4 id="1）常用的3个指标（多用于交叉验证）"><a href="#1）常用的3个指标（多用于交叉验证）" class="headerlink" title="1）常用的3个指标（多用于交叉验证）"></a>1）常用的3个指标（多用于交叉验证）</h4><ul><li>accuracy（准确率）——检验模型预测的正确率<script type="math/tex; mode=display">A=\frac {TP+TN}{ALL}</script></li></ul><p>预测正确个数/全部样本数</p><ul><li>precision（精确率）——检验模型预测正例的正确率<script type="math/tex; mode=display">P=\frac {TP}{TP+FP}</script></li></ul><p>预测正确的正样本数 / 预测为的正样本数</p><ul><li>recall/TPR（召回率/真正率）——检验模型正例预测的全面性<script type="math/tex; mode=display">R\ /\ TPR=\frac {TP}{TP+FN}</script></li></ul><p>预测正确的正样本数 / 真实的正样本数</p><h4 id="2）不常用的3个指标（多用于绘图）"><a href="#2）不常用的3个指标（多用于绘图）" class="headerlink" title="2）不常用的3个指标（多用于绘图）"></a>2）不常用的3个指标（多用于绘图）</h4><ul><li>specificity（特异性/真负率）——检验模型负例预测的正确率<script type="math/tex; mode=display">S=\frac {TN}{TN+FP}</script></li></ul><p>预测正确的负样本数 / 真实的负样本数</p><ul><li>FPR（假正率）——用于和TPR一起绘制ROC曲线<script type="math/tex; mode=display">FPR=\frac {FP}{TN+FP}</script></li></ul><p>预测错误的正样本数 / 真实的负样本数</p><ul><li>FNR（假负率）——用的少 <script type="math/tex; mode=display">FNR=\frac {FN}{TP+FN}</script></li></ul><p>预测错误的负样本数 / 真实的正样本数</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;性能度量&quot;&gt;&lt;a href=&quot;#性能度量&quot; class=&quot;headerlink&quot; title=&quot;性能度量&quot;&gt;&lt;/a&gt;性能度量&lt;/h2&gt;&lt;h3 id=&quot;二分类任务的-混淆矩阵-和-其衍生的度量指标&quot;&gt;&lt;a href=&quot;#二分类任务的-混淆矩阵-和-其衍生的度量指标&quot;
      
    
    </summary>
    
      <category term="machine_learning_theory" scheme="http://yoursite.com/categories/machine-learning-theory/"/>
    
    
  </entry>
  
  <entry>
    <title>Tensorflow学习9-3：谷歌inception-v3模型 之 transfer learning retrain</title>
    <link href="http://yoursite.com/2018/04/21/tensorflow/Tensorflow%E5%AD%A6%E4%B9%A09-3%EF%BC%9A%E8%B0%B7%E6%AD%8Cinception-v3%E6%A8%A1%E5%9E%8B%20%E4%B9%8B%20transfer%20learning%20retrain/"/>
    <id>http://yoursite.com/2018/04/21/tensorflow/Tensorflow学习9-3：谷歌inception-v3模型 之 transfer learning retrain/</id>
    <published>2018-04-20T16:10:27.000Z</published>
    <updated>2018-07-15T23:54:06.791Z</updated>
    
    <content type="html"><![CDATA[<p>因为是 transfer learning 操作，所以直到网络的bottleneck部分之前都不需要改变参数和训练。只需要传入图片数据到网络中计算得到结果。再拿到这个结果到后面的全连接层进行训练。</p><p>所以训练的内容不多，迭代200次左右就可以达到要求。</p><h2 id="1-准备模型文件"><a href="#1-准备模型文件" class="headerlink" title="1 准备模型文件"></a>1 准备模型文件</h2><p>.pb模型文件下载地址：<br><a href="http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz" target="_blank" rel="noopener">http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz</a></p><p>解压后得到如下内容：<br><img src="/2018/04/21/tensorflow/Tensorflow学习9-3：谷歌inception-v3模型 之 transfer learning retrain/Tensorflow学习9-3：谷歌inception-v3模型%20之%20transfer%20learning%20retrain/2018-07-16-00-39-05.png" alt=""></p><h2 id="2-准备retrain训练工程目录"><a href="#2-准备retrain训练工程目录" class="headerlink" title="2 准备retrain训练工程目录"></a>2 准备retrain训练工程目录</h2><p>1、在D:/Tensorflow目录下新建retrain文件夹。<br>在里面新建以下文件夹：<br>bottleneck：存放瓶颈部分输出的数据，用于全连接层的训练<br>data<br> └ train：存放用于训练的用文件夹分类好的图片<br>images：存放用于测试的单个图片</p><p>2、把image_retraining中的retrain.py文件拖过来（注意：这个文件不能用最新版的）</p><p>3、新建retrain.bat文件，内容如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">python retrain.py ^</span><br><span class="line">--bottleneck_dir bottleneck ^</span><br><span class="line">--how_many_training_steps 100 ^</span><br><span class="line">--model_dir D:/Tensorflow/models/inception/ ^</span><br><span class="line">--output_graph output_graph.pb ^</span><br><span class="line">--output_labels output_labels.txt ^</span><br><span class="line">--image_dir data/train/ </span><br><span class="line">pause</span><br></pre></td></tr></table></figure></p><p>文件架构如下图：<br><img src="/2018/04/21/tensorflow/Tensorflow学习9-3：谷歌inception-v3模型 之 transfer learning retrain/Tensorflow学习9-3：谷歌inception-v3模型%20之%20transfer%20learning%20retrain/2018-07-16-00-42-58.png" alt=""></p><h2 id="3-执行retrain-bat脚本，进行transfer-learning"><a href="#3-执行retrain-bat脚本，进行transfer-learning" class="headerlink" title="3 执行retrain.bat脚本，进行transfer learning"></a>3 执行retrain.bat脚本，进行transfer learning</h2><p><img src="/2018/04/21/tensorflow/Tensorflow学习9-3：谷歌inception-v3模型 之 transfer learning retrain/Tensorflow学习9-3：谷歌inception-v3模型%20之%20transfer%20learning%20retrain/2018-07-16-07-41-18.png" alt=""></p><p>跌倒200次训练完成后，会在当前目录生成<code>output_graph.pb</code>和<code>output_labels.txt</code>两个文件，至此训练完成。可以用这个pb模型文件来测试分类了。</p><h2 id="4-测试分类效果"><a href="#4-测试分类效果" class="headerlink" title="4 测试分类效果"></a>4 测试分类效果</h2><p>自己写一个测试代码，用自己的图片测试下分类效果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">TEST_IMG_DIR = <span class="string">"D:/Tensorflow/Test Images/"</span></span><br><span class="line">RETRAIN_DIR = <span class="string">"D:/Tensorflow/retrain/"</span> <span class="comment">#模型存放目录</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">lines = tf.gfile.GFile(RETRAIN_DIR + <span class="string">"output_labels.txt"</span>).readlines()</span><br><span class="line">uid_to_human = &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> uid,line <span class="keyword">in</span> enumerate(lines):</span><br><span class="line">    line=line.strip(<span class="string">"\n"</span>)</span><br><span class="line">    uid_to_human[uid] = line</span><br><span class="line"></span><br><span class="line"><span class="comment">#print(uid_to_human)</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">id_to_string</span><span class="params">(node_id)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> node_id <span class="keyword">not</span> <span class="keyword">in</span> uid_to_human:</span><br><span class="line">        print(<span class="string">"node_id not in uid_to_human"</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="string">""</span></span><br><span class="line">    <span class="keyword">return</span> uid_to_human[node_id]</span><br><span class="line"></span><br><span class="line"><span class="comment">#创建一个图来存放google训练好的模型</span></span><br><span class="line"><span class="keyword">with</span> tf.gfile.FastGFile(RETRAIN_DIR + <span class="string">"output_graph.pb"</span>, <span class="string">"rb"</span>) <span class="keyword">as</span> f:</span><br><span class="line">    graph_def = tf.GraphDef()</span><br><span class="line">    graph_def.ParseFromString(f.read())</span><br><span class="line">    tf.import_graph_def(graph_def, name=<span class="string">""</span>)</span><br><span class="line">    </span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    softmax_tensor = sess.graph.get_tensor_by_name(<span class="string">"final_result:0"</span>)</span><br><span class="line">    <span class="comment">#遍历用于测试的图片目录</span></span><br><span class="line">    <span class="keyword">for</span> root,dirs,files <span class="keyword">in</span> os.walk(RETRAIN_DIR + <span class="string">"images/"</span>):</span><br><span class="line">        <span class="keyword">for</span> file <span class="keyword">in</span> files:</span><br><span class="line">            <span class="comment">#载入图片</span></span><br><span class="line">            image_data = tf.gfile.FastGFile(os.path.join(root,file), <span class="string">"rb"</span>).read()</span><br><span class="line">            predictions = sess.run(softmax_tensor, &#123;<span class="string">"DecodeJpeg/contents:0"</span> : image_data&#125;) <span class="comment">#jpg格式图片</span></span><br><span class="line">            <span class="comment">#predictions = sess.run(softmax_tensor, &#123;"DecodeJPGInput:0" : image_data&#125;) #jpg格式图片</span></span><br><span class="line">            predictions = np.squeeze(predictions) <span class="comment">#吧结果转为1维数据</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment">#打印图片路径及名称</span></span><br><span class="line">            image_path = os.path.join(root,file)</span><br><span class="line">            print(image_path)</span><br><span class="line">            <span class="comment">#显示图片</span></span><br><span class="line">            img = Image.open(image_path)</span><br><span class="line">            plt.imshow(img)</span><br><span class="line">            plt.axis(<span class="string">"off"</span>)</span><br><span class="line">            plt.show()</span><br><span class="line">            </span><br><span class="line">            <span class="comment">#排序</span></span><br><span class="line">            top_k = predictions.argsort()[::<span class="number">-1</span>]</span><br><span class="line">            <span class="keyword">for</span> node_id <span class="keyword">in</span> top_k:</span><br><span class="line">                <span class="comment">#获取分类名称</span></span><br><span class="line">                human_string = id_to_string(node_id)</span><br><span class="line">                <span class="comment">#获取该分类的概率</span></span><br><span class="line">                score = predictions[node_id]</span><br><span class="line">                print(<span class="string">"%s (score = %.5f)"</span> % (human_string, score))</span><br><span class="line">            print()</span><br></pre></td></tr></table></figure><p>D:/Tensorflow/retrain/images/111.jpg</p><p><img src="/2018/04/21/tensorflow/Tensorflow学习9-3：谷歌inception-v3模型 之 transfer learning retrain/Tensorflow学习9-3：谷歌inception-v3模型%20之%20transfer%20learning%20retrain/output_1_1.png" alt="png"></p><p>pet (score = 0.80940)<br>flower (score = 0.19060)</p><p>D:/Tensorflow/retrain/images/222.jpg</p><p><img src="/2018/04/21/tensorflow/Tensorflow学习9-3：谷歌inception-v3模型 之 transfer learning retrain/Tensorflow学习9-3：谷歌inception-v3模型%20之%20transfer%20learning%20retrain/output_1_3.png" alt="png"></p><p>flower (score = 0.99097)<br>pet (score = 0.00903)</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;因为是 transfer learning 操作，所以直到网络的bottleneck部分之前都不需要改变参数和训练。只需要传入图片数据到网络中计算得到结果。再拿到这个结果到后面的全连接层进行训练。&lt;/p&gt;
&lt;p&gt;所以训练的内容不多，迭代200次左右就可以达到要求。&lt;/p&gt;

      
    
    </summary>
    
      <category term="tensorflow" scheme="http://yoursite.com/categories/tensorflow/"/>
    
    
      <category term="transfer learning" scheme="http://yoursite.com/tags/transfer-learning/"/>
    
      <category term="inception-v3" scheme="http://yoursite.com/tags/inception-v3/"/>
    
      <category term="retrain" scheme="http://yoursite.com/tags/retrain/"/>
    
  </entry>
  
</feed>
