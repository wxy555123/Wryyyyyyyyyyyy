<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>新日暮里的幻想乡</title>
  
  <subtitle>Do you like Van 游戏？</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2018-04-23T10:45:20.757Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>wxy555123</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Numpy常用功能、函数</title>
    <link href="http://yoursite.com/2018/04/19/numpy/Numpy%E5%B8%B8%E7%94%A8%E5%8A%9F%E8%83%BD%E3%80%81%E5%87%BD%E6%95%B0/"/>
    <id>http://yoursite.com/2018/04/19/numpy/Numpy常用功能、函数/</id>
    <published>2018-04-19T04:49:42.000Z</published>
    <updated>2018-04-23T10:45:20.757Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Numpy"><a href="#Numpy" class="headerlink" title="Numpy"></a>Numpy</h1><h2 id="np-matrix-：矩阵标准写法"><a href="#np-matrix-：矩阵标准写法" class="headerlink" title="np.matrix()：矩阵标准写法"></a>np.matrix()：矩阵标准写法</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = np.matrix(<span class="string">'1 2 7; 3 4 8; 5 6 9'</span>) <span class="comment">#单行写法</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a             <span class="comment">#矩阵的换行必须是用分号(;)隔开，内部数据必须为字符串形式(“ ”)，矩</span></span><br><span class="line">matrix([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">7</span>],       <span class="comment">#阵的元素之间必须以空格隔开。</span></span><br><span class="line">[<span class="number">3</span>, <span class="number">4</span>, <span class="number">8</span>],</span><br><span class="line">[<span class="number">5</span>, <span class="number">6</span>, <span class="number">9</span>]])</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b=np.array([[<span class="number">1</span>,<span class="number">5</span>],[<span class="number">3</span>,<span class="number">2</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x=np.matrix(b)   <span class="comment">#矩阵中的data可以为数组对象。</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x</span><br><span class="line">matrix([[<span class="number">1</span>, <span class="number">5</span>],</span><br><span class="line">[<span class="number">3</span>, <span class="number">2</span>]])</span><br></pre></td></tr></table></figure><h2 id="np-inf：无穷大"><a href="#np-inf：无穷大" class="headerlink" title="np.inf：无穷大"></a>np.inf：无穷大</h2><h2 id="np-set-printoptions-suppress-True"><a href="#np-set-printoptions-suppress-True" class="headerlink" title="np.set_printoptions(suppress=True)"></a>np.set_printoptions(suppress=True)</h2><p>不用科学记数法输出</p><h2 id="np-multiply-：矩阵对应元素相乘"><a href="#np-multiply-：矩阵对应元素相乘" class="headerlink" title="np.multiply()：矩阵对应元素相乘"></a>np.multiply()：矩阵对应元素相乘</h2><h2 id="numpy-linalg：矩阵运算，中的常用函数"><a href="#numpy-linalg：矩阵运算，中的常用函数" class="headerlink" title="numpy.linalg：矩阵运算，中的常用函数"></a>numpy.linalg：矩阵运算，中的常用函数</h2><p>diag    以一维数组的形式返回方阵的对角线元素<br>dot     矩阵乘法<br>det     计算矩阵行列式<br>eig     计算方阵的特征值和特征向量<br>inv     计算方阵的逆<br>lstsq   计算Ax=b的最小二乘解<br>norm　　计算范数（ord=指定范数），默认为２范数<br>pinv    计算矩阵的Moore-Penrose伪逆<br>qr      计算qr分解<br>svd     计算奇异值分解<br>solve   解线性方程组Ax=b，其中A为一个方阵<br>trace   计算对角线元素的和</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Numpy&quot;&gt;&lt;a href=&quot;#Numpy&quot; class=&quot;headerlink&quot; title=&quot;Numpy&quot;&gt;&lt;/a&gt;Numpy&lt;/h1&gt;&lt;h2 id=&quot;np-matrix-：矩阵标准写法&quot;&gt;&lt;a href=&quot;#np-matrix-：矩阵标准写法&quot; class
      
    
    </summary>
    
      <category term="numpy" scheme="http://yoursite.com/categories/numpy/"/>
    
    
      <category term="numpy" scheme="http://yoursite.com/tags/numpy/"/>
    
  </entry>
  
  <entry>
    <title>Pandas常用功能、函数</title>
    <link href="http://yoursite.com/2018/04/19/pandas/Pandas%E5%B8%B8%E7%94%A8%E5%8A%9F%E8%83%BD%E3%80%81%E5%87%BD%E6%95%B0/"/>
    <id>http://yoursite.com/2018/04/19/pandas/Pandas常用功能、函数/</id>
    <published>2018-04-19T04:49:42.000Z</published>
    <updated>2018-04-23T08:35:51.474Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="pandas" scheme="http://yoursite.com/categories/pandas/"/>
    
    
      <category term="pandas" scheme="http://yoursite.com/tags/pandas/"/>
    
  </entry>
  
  <entry>
    <title>PCA 手写主成分分析</title>
    <link href="http://yoursite.com/2018/04/19/machine_learning_in_action/PCA%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90/"/>
    <id>http://yoursite.com/2018/04/19/machine_learning_in_action/PCA主成分分析/</id>
    <published>2018-04-19T04:49:42.000Z</published>
    <updated>2018-04-23T15:43:26.124Z</updated>
    
    <content type="html"><![CDATA[<h1 id="PCA-手写主成分分析"><a href="#PCA-手写主成分分析" class="headerlink" title="PCA 手写主成分分析"></a>PCA 手写主成分分析</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = pd.read_csv(<span class="string">'iris.data'</span>)</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure><div><style>    .dataframe thead tr:only-child th {        text-align: right;    }    .dataframe thead th {        text-align: left;    }    .dataframe tbody tr th {        vertical-align: top;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>5.1</th>      <th>3.5</th>      <th>1.4</th>      <th>0.2</th>      <th>Iris-setosa</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>4.9</td>      <td>3.0</td>      <td>1.4</td>      <td>0.2</td>      <td>Iris-setosa</td>    </tr>    <tr>      <th>1</th>      <td>4.7</td>      <td>3.2</td>      <td>1.3</td>      <td>0.2</td>      <td>Iris-setosa</td>    </tr>    <tr>      <th>2</th>      <td>4.6</td>      <td>3.1</td>      <td>1.5</td>      <td>0.2</td>      <td>Iris-setosa</td>    </tr>    <tr>      <th>3</th>      <td>5.0</td>      <td>3.6</td>      <td>1.4</td>      <td>0.2</td>      <td>Iris-setosa</td>    </tr>    <tr>      <th>4</th>      <td>5.4</td>      <td>3.9</td>      <td>1.7</td>      <td>0.4</td>      <td>Iris-setosa</td>    </tr>  </tbody></table></div><h2 id="1-数据预处理"><a href="#1-数据预处理" class="headerlink" title="1 数据预处理"></a>1 数据预处理</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#加上列名</span></span><br><span class="line">df.columns=[<span class="string">'sepal_len'</span>, <span class="string">'sepal_wid'</span>, <span class="string">'petal_len'</span>, <span class="string">'petal_wid'</span>, <span class="string">'class'</span>]</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure><div><style>    .dataframe thead tr:only-child th {        text-align: right;    }    .dataframe thead th {        text-align: left;    }    .dataframe tbody tr th {        vertical-align: top;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>sepal_len</th>      <th>sepal_wid</th>      <th>petal_len</th>      <th>petal_wid</th>      <th>class</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>4.9</td>      <td>3.0</td>      <td>1.4</td>      <td>0.2</td>      <td>Iris-setosa</td>    </tr>    <tr>      <th>1</th>      <td>4.7</td>      <td>3.2</td>      <td>1.3</td>      <td>0.2</td>      <td>Iris-setosa</td>    </tr>    <tr>      <th>2</th>      <td>4.6</td>      <td>3.1</td>      <td>1.5</td>      <td>0.2</td>      <td>Iris-setosa</td>    </tr>    <tr>      <th>3</th>      <td>5.0</td>      <td>3.6</td>      <td>1.4</td>      <td>0.2</td>      <td>Iris-setosa</td>    </tr>    <tr>      <th>4</th>      <td>5.4</td>      <td>3.9</td>      <td>1.7</td>      <td>0.4</td>      <td>Iris-setosa</td>    </tr>  </tbody></table></div><h2 id="2-画图，进行降维特征分析"><a href="#2-画图，进行降维特征分析" class="headerlink" title="2 画图，进行降维特征分析"></a>2 画图，进行降维特征分析</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># split data table into data X and class labels y</span></span><br><span class="line"></span><br><span class="line">X = df.iloc[:,<span class="number">0</span>:<span class="number">4</span>].values</span><br><span class="line">y = df.iloc[:,<span class="number">4</span>].values</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 把每个特征用于分类的结果，都画成条形图，观察哪个特征更容易划分种类</span></span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line">label_dict = &#123;<span class="number">1</span>: <span class="string">'Iris-Setosa'</span>,</span><br><span class="line">              <span class="number">2</span>: <span class="string">'Iris-Versicolor'</span>,</span><br><span class="line">              <span class="number">3</span>: <span class="string">'Iris-Virgnica'</span>&#125;</span><br><span class="line"></span><br><span class="line">feature_dict = &#123;<span class="number">0</span>: <span class="string">'sepal length [cm]'</span>,</span><br><span class="line">                <span class="number">1</span>: <span class="string">'sepal width [cm]'</span>,</span><br><span class="line">                <span class="number">2</span>: <span class="string">'petal length [cm]'</span>,</span><br><span class="line">                <span class="number">3</span>: <span class="string">'petal width [cm]'</span>&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">8</span>, <span class="number">6</span>))</span><br><span class="line"><span class="keyword">for</span> cnt <span class="keyword">in</span> range(<span class="number">4</span>):</span><br><span class="line">    plt.subplot(<span class="number">2</span>, <span class="number">2</span>, cnt+<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">for</span> lab <span class="keyword">in</span> (<span class="string">'Iris-setosa'</span>, <span class="string">'Iris-versicolor'</span>, <span class="string">'Iris-virginica'</span>):</span><br><span class="line">        plt.hist(X[y==lab, cnt],</span><br><span class="line">                     label=lab,</span><br><span class="line">                     bins=<span class="number">10</span>,</span><br><span class="line">                     alpha=<span class="number">0.3</span>,)</span><br><span class="line">    plt.xlabel(feature_dict[cnt])</span><br><span class="line">    plt.legend(loc=<span class="string">'upper right'</span>, fancybox=<span class="keyword">True</span>, fontsize=<span class="number">8</span>)</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/2018/04/19/machine_learning_in_action/PCA主成分分析/output_7_0.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 特征 归一化</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">X_std = StandardScaler().fit_transform(X)</span><br></pre></td></tr></table></figure><h2 id="3-开始降维（发现有2个有用特征，决定从4维降到2维）"><a href="#3-开始降维（发现有2个有用特征，决定从4维降到2维）" class="headerlink" title="3 开始降维（发现有2个有用特征，决定从4维降到2维）"></a>3 开始降维（发现有2个有用特征，决定从4维降到2维）</h2><h3 id="1-计算样本X的-协方差矩阵（有4个特征，所以是4x4）"><a href="#1-计算样本X的-协方差矩阵（有4个特征，所以是4x4）" class="headerlink" title="1 计算样本X的 协方差矩阵（有4个特征，所以是4x4）"></a>1 计算样本X的 协方差矩阵（有4个特征，所以是4x4）</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 自己算 协方差矩阵</span></span><br><span class="line">mean_vec = np.mean(X_std, axis=<span class="number">0</span>)</span><br><span class="line">cov_mat = (X_std - mean_vec).T.dot((X_std - mean_vec)) / (X_std.shape[<span class="number">0</span>]<span class="number">-1</span>)</span><br><span class="line">print(<span class="string">'Covariance matrix \n%s'</span> %cov_mat)</span><br></pre></td></tr></table></figure><pre><code>Covariance matrix [[ 1.00675676 -0.10448539  0.87716999  0.82249094] [-0.10448539  1.00675676 -0.41802325 -0.35310295] [ 0.87716999 -0.41802325  1.00675676  0.96881642] [ 0.82249094 -0.35310295  0.96881642  1.00675676]]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># numpy算 协方差矩阵</span></span><br><span class="line">print(<span class="string">'NumPy covariance matrix: \n%s'</span> %np.cov(X_std.T))</span><br></pre></td></tr></table></figure><pre><code>NumPy covariance matrix: [[ 1.00675676 -0.10448539  0.87716999  0.82249094] [-0.10448539  1.00675676 -0.41802325 -0.35310295] [ 0.87716999 -0.41802325  1.00675676  0.96881642] [ 0.82249094 -0.35310295  0.96881642  1.00675676]]</code></pre><h3 id="2-对协方差矩阵进行-特征值分解"><a href="#2-对协方差矩阵进行-特征值分解" class="headerlink" title="2 对协方差矩阵进行 特征值分解"></a>2 对协方差矩阵进行 特征值分解</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cov_mat = np.cov(X_std.T)</span><br><span class="line"></span><br><span class="line">eig_vals, eig_vecs = np.linalg.eig(cov_mat)</span><br><span class="line"></span><br><span class="line">print(<span class="string">'Eigenvectors \n%s'</span> %eig_vecs)</span><br><span class="line">print(<span class="string">'\nEigenvalues \n%s'</span> %eig_vals)</span><br></pre></td></tr></table></figure><pre><code>Eigenvectors [[ 0.52308496 -0.36956962 -0.72154279  0.26301409] [-0.25956935 -0.92681168  0.2411952  -0.12437342] [ 0.58184289 -0.01912775  0.13962963 -0.80099722] [ 0.56609604 -0.06381646  0.63380158  0.52321917]]Eigenvalues [ 2.92442837  0.93215233  0.14946373  0.02098259]</code></pre><h3 id="3-把特征值从大到小排列，并配对特征向量"><a href="#3-把特征值从大到小排列，并配对特征向量" class="headerlink" title="3 把特征值从大到小排列，并配对特征向量"></a>3 把特征值从大到小排列，并配对特征向量</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Make a list of (eigenvalue, eigenvector) tuples</span></span><br><span class="line">eig_pairs = [(np.abs(eig_vals[i]), eig_vecs[:,i]) <span class="keyword">for</span> i <span class="keyword">in</span> range(len(eig_vals))]</span><br><span class="line"><span class="keyword">print</span> (eig_pairs)</span><br><span class="line"><span class="keyword">print</span> (<span class="string">'----------'</span>)</span><br><span class="line"><span class="comment"># Sort the (eigenvalue, eigenvector) tuples from high to low</span></span><br><span class="line">eig_pairs.sort(key=<span class="keyword">lambda</span> x: x[<span class="number">0</span>], reverse=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Visually confirm that the list is correctly sorted by decreasing eigenvalues</span></span><br><span class="line">print(<span class="string">'Eigenvalues in descending order:'</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> eig_pairs:</span><br><span class="line">    print(i[<span class="number">0</span>],<span class="string">"对应"</span>,i[<span class="number">1</span>])</span><br></pre></td></tr></table></figure><pre><code>[(2.9244283691111144, array([ 0.52308496, -0.25956935,  0.58184289,  0.56609604])), (0.93215233025350641, array([-0.36956962, -0.92681168, -0.01912775, -0.06381646])), (0.14946373489813314, array([-0.72154279,  0.2411952 ,  0.13962963,  0.63380158])), (0.020982592764270606, array([ 0.26301409, -0.12437342, -0.80099722,  0.52321917]))]----------Eigenvalues in descending order:2.92442836911 对应 [ 0.52308496 -0.25956935  0.58184289  0.56609604]0.932152330254 对应 [-0.36956962 -0.92681168 -0.01912775 -0.06381646]0.149463734898 对应 [-0.72154279  0.2411952   0.13962963  0.63380158]0.0209825927643 对应 [ 0.26301409 -0.12437342 -0.80099722  0.52321917]</code></pre><h3 id="4-通过前面特征值累加所占比重-的图像，判断取前多少特征值合适，组成投影矩阵W"><a href="#4-通过前面特征值累加所占比重-的图像，判断取前多少特征值合适，组成投影矩阵W" class="headerlink" title="4 通过前面特征值累加所占比重 的图像，判断取前多少特征值合适，组成投影矩阵W"></a>4 通过前面特征值累加所占比重 的图像，判断取前多少特征值合适，组成投影矩阵W</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tot = sum(eig_vals)</span><br><span class="line">var_exp = [(i / tot)*<span class="number">100</span> <span class="keyword">for</span> i <span class="keyword">in</span> sorted(eig_vals, reverse=<span class="keyword">True</span>)]</span><br><span class="line"><span class="keyword">print</span> (var_exp)</span><br><span class="line">cum_var_exp = np.cumsum(var_exp)</span><br><span class="line">cum_var_exp</span><br></pre></td></tr></table></figure><pre><code>[72.620033326920336, 23.147406858644135, 3.7115155645845164, 0.52104424985101538]array([  72.62003333,   95.76744019,   99.47895575,  100.        ])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>])</span><br><span class="line"><span class="keyword">print</span> (a)</span><br><span class="line"><span class="keyword">print</span> (<span class="string">'-----------'</span>)</span><br><span class="line"><span class="keyword">print</span> (np.cumsum(a))</span><br></pre></td></tr></table></figure><pre><code>[1 2 3 4]-----------[ 1  3  6 10]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">6</span>, <span class="number">4</span>))</span><br><span class="line"></span><br><span class="line">plt.bar(range(<span class="number">4</span>), var_exp, alpha=<span class="number">0.5</span>, align=<span class="string">'center'</span>,</span><br><span class="line">            label=<span class="string">'individual explained variance'</span>)</span><br><span class="line">plt.step(range(<span class="number">4</span>), cum_var_exp, where=<span class="string">'mid'</span>,</span><br><span class="line">             label=<span class="string">'cumulative explained variance'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Explained variance ratio'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'Principal components'</span>)</span><br><span class="line">plt.legend(loc=<span class="string">'best'</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/2018/04/19/machine_learning_in_action/PCA主成分分析/output_20_0.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">matrix_w = np.hstack((eig_pairs[<span class="number">0</span>][<span class="number">1</span>].reshape(<span class="number">4</span>,<span class="number">1</span>),</span><br><span class="line">                      eig_pairs[<span class="number">1</span>][<span class="number">1</span>].reshape(<span class="number">4</span>,<span class="number">1</span>)))</span><br><span class="line"></span><br><span class="line">print(<span class="string">'Matrix W:\n'</span>, matrix_w)</span><br></pre></td></tr></table></figure><pre><code>Matrix W: [[ 0.52308496 -0.36956962] [-0.25956935 -0.92681168] [ 0.58184289 -0.01912775] [ 0.56609604 -0.06381646]]</code></pre><h3 id="5-用投影矩阵降维样本矩阵X"><a href="#5-用投影矩阵降维样本矩阵X" class="headerlink" title="5 用投影矩阵降维样本矩阵X"></a>5 用投影矩阵降维样本矩阵X</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Y = X_std.dot(matrix_w)</span><br></pre></td></tr></table></figure><h2 id="4-画图观察-降维前-和-降维后的样本分布"><a href="#4-画图观察-降维前-和-降维后的样本分布" class="headerlink" title="4 画图观察 降维前 和 降维后的样本分布"></a>4 画图观察 降维前 和 降维后的样本分布</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">6</span>, <span class="number">4</span>))</span><br><span class="line"><span class="keyword">for</span> lab, col <span class="keyword">in</span> zip((<span class="string">'Iris-setosa'</span>, <span class="string">'Iris-versicolor'</span>, <span class="string">'Iris-virginica'</span>),</span><br><span class="line">                        (<span class="string">'blue'</span>, <span class="string">'red'</span>, <span class="string">'green'</span>)):</span><br><span class="line">     plt.scatter(X[y==lab, <span class="number">0</span>],</span><br><span class="line">                X[y==lab, <span class="number">1</span>],</span><br><span class="line">                label=lab,</span><br><span class="line">                c=col)</span><br><span class="line">plt.xlabel(<span class="string">'sepal_len'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'sepal_wid'</span>)</span><br><span class="line">plt.legend(loc=<span class="string">'best'</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/2018/04/19/machine_learning_in_action/PCA主成分分析/output_25_0.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">6</span>, <span class="number">4</span>))</span><br><span class="line"><span class="keyword">for</span> lab, col <span class="keyword">in</span> zip((<span class="string">'Iris-setosa'</span>, <span class="string">'Iris-versicolor'</span>, <span class="string">'Iris-virginica'</span>),</span><br><span class="line">                        (<span class="string">'blue'</span>, <span class="string">'red'</span>, <span class="string">'green'</span>)):</span><br><span class="line">     plt.scatter(Y[y==lab, <span class="number">0</span>],</span><br><span class="line">                Y[y==lab, <span class="number">1</span>],</span><br><span class="line">                label=lab,</span><br><span class="line">                c=col)</span><br><span class="line">plt.xlabel(<span class="string">'Principal Component 1'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Principal Component 2'</span>)</span><br><span class="line">plt.legend(loc=<span class="string">'lower center'</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/2018/04/19/machine_learning_in_action/PCA主成分分析/output_26_0.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;PCA-手写主成分分析&quot;&gt;&lt;a href=&quot;#PCA-手写主成分分析&quot; class=&quot;headerlink&quot; title=&quot;PCA 手写主成分分析&quot;&gt;&lt;/a&gt;PCA 手写主成分分析&lt;/h1&gt;&lt;figure class=&quot;highlight python&quot;&gt;&lt;tab
      
    
    </summary>
    
      <category term="machine_learning_in_action" scheme="http://yoursite.com/categories/machine-learning-in-action/"/>
    
    
      <category term="PCA" scheme="http://yoursite.com/tags/PCA/"/>
    
  </entry>
  
  <entry>
    <title>备忘记录</title>
    <link href="http://yoursite.com/2018/04/19/OTHERS/%E5%A4%87%E5%BF%98%E8%AE%B0%E5%BD%95/"/>
    <id>http://yoursite.com/2018/04/19/OTHERS/备忘记录/</id>
    <published>2018-04-18T16:51:27.000Z</published>
    <updated>2018-04-23T08:35:22.280Z</updated>
    
    <content type="html"><![CDATA[<h2 id="变量命名标准"><a href="#变量命名标准" class="headerlink" title="变量命名标准"></a>变量命名标准</h2><p>整型：语义名<br>数组：语义名+S 或 语义名+Arr<br>一般：语义名+数据结构名+其他特征</p><p>比如：classArrTry</p><h2 id="标签tags设置标准"><a href="#标签tags设置标准" class="headerlink" title="标签tags设置标准"></a>标签tags设置标准</h2><p>文章内所包含的 技术点名称</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;变量命名标准&quot;&gt;&lt;a href=&quot;#变量命名标准&quot; class=&quot;headerlink&quot; title=&quot;变量命名标准&quot;&gt;&lt;/a&gt;变量命名标准&lt;/h2&gt;&lt;p&gt;整型：语义名&lt;br&gt;数组：语义名+S 或 语义名+Arr&lt;br&gt;一般：语义名+数据结构名+其他特征&lt;/p&gt;

      
    
    </summary>
    
      <category term="其他" scheme="http://yoursite.com/categories/%E5%85%B6%E4%BB%96/"/>
    
    
  </entry>
  
  <entry>
    <title>Python常用功能、函数</title>
    <link href="http://yoursite.com/2018/04/19/python/Python%E5%B8%B8%E7%94%A8%E5%8A%9F%E8%83%BD%E3%80%81%E5%87%BD%E6%95%B0/"/>
    <id>http://yoursite.com/2018/04/19/python/Python常用功能、函数/</id>
    <published>2018-04-18T16:51:27.000Z</published>
    <updated>2018-04-23T08:35:43.383Z</updated>
    
    <content type="html"><![CDATA[<h2 id="open"><a href="#open" class="headerlink" title="open()"></a>open()</h2><p>1简单的文件读写</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">f = open(<span class="string">"123.txt"</span>, <span class="string">"r"</span>);</span><br><span class="line">content = f.read();</span><br><span class="line">print(content);</span><br><span class="line">f.close();</span><br><span class="line"></span><br><span class="line">f = open(<span class="string">"123.txt"</span>, <span class="string">"a+"</span>);</span><br><span class="line">f.write(<span class="string">"\n"</span>);</span><br><span class="line">f.write(<span class="string">"222222222222"</span>);</span><br><span class="line">f.close();</span><br></pre></td></tr></table></figure><p>2读取数据到矩阵</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#读取txt二维数据到矩阵</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadDataSet</span><span class="params">(fileName)</span>:</span>    </span><br><span class="line">    dataMat = np.mat([<span class="number">0</span>,<span class="number">0</span>])               </span><br><span class="line">    f = open(fileName)</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> f.readlines():</span><br><span class="line">        curLine = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line">        <span class="keyword">if</span> len(curLine)==<span class="number">1</span> : </span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        curLineMat = np.mat(curLine)</span><br><span class="line">        dataMat = np.vstack((dataMat, curLineMat))  <span class="comment">#拼接矩阵</span></span><br><span class="line">    dataMat = dataMat[<span class="number">1</span>:,:].astype(float)   <span class="comment">#不要第一行；转为纯数字</span></span><br><span class="line">    <span class="keyword">return</span> dataMat</span><br></pre></td></tr></table></figure><h2 id="set"><a href="#set" class="headerlink" title="set()"></a>set()</h2><p>将一个字符串拆成 单个字符 组成的字符集，可进行关系测试，删除重复数据，还可以计算交集、差集、并集等。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = set(<span class="string">'runoob'</span>) </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y = set(<span class="string">'google'</span>) </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x, y (set([<span class="string">'b'</span>, <span class="string">'r'</span>, <span class="string">'u'</span>, <span class="string">'o'</span>, <span class="string">'n'</span>]), set([<span class="string">'e'</span>, <span class="string">'o'</span>, <span class="string">'g'</span>, <span class="string">'l'</span>])) <span class="comment"># 重复的被删除 </span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x &amp; y <span class="comment"># 交集 set(['o']) </span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x | y <span class="comment"># 并集 set(['b', 'e', 'g', 'l', 'o', 'n', 'r', 'u']) </span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x - y <span class="comment"># 差集 set(['r', 'b', 'u', 'n']) </span></span><br><span class="line">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure><h2 id="copy"><a href="#copy" class="headerlink" title="copy()"></a>copy()</h2><ol><li>= 赋值 传引用 =》内存不独立 =》 同步跟随变化</li><li>copy 浅拷贝 只拷贝父对象 =》父对象内存独立 =》只有子对象跟随变化</li><li>deepcopy 深拷贝 拷贝对象及其子对象 =》全部内存独立 =》 不跟随变化<br>（深拷贝 和 浅拷贝——只对数组结构有用，int之类的没用）<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">a = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, [<span class="string">'a'</span>, <span class="string">'b'</span>]] <span class="comment">#原始对象</span></span><br><span class="line"> </span><br><span class="line">b = a <span class="comment">#赋值，传对象的引用</span></span><br><span class="line">c = copy.copy(a) <span class="comment">#对象拷贝，浅拷贝</span></span><br><span class="line">d = copy.deepcopy(a) <span class="comment">#对象拷贝，深拷贝</span></span><br><span class="line"> </span><br><span class="line">a.append(<span class="number">5</span>) <span class="comment">#修改对象a</span></span><br><span class="line">a[<span class="number">4</span>].append(<span class="string">'c'</span>) <span class="comment">#修改对象a中的['a', 'b']数组对象</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">print</span> <span class="string">'a = '</span>, a</span><br><span class="line"><span class="keyword">print</span> <span class="string">'b = '</span>, b</span><br><span class="line"><span class="keyword">print</span> <span class="string">'c = '</span>, c</span><br><span class="line"><span class="keyword">print</span> <span class="string">'d = '</span>, d</span><br><span class="line">输出结果：</span><br><span class="line">a =  [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, [<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>], <span class="number">5</span>]</span><br><span class="line">b =  [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, [<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>], <span class="number">5</span>]</span><br><span class="line">c =  [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, [<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>]]</span><br><span class="line">d =  [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, [<span class="string">'a'</span>, <span class="string">'b'</span>]]</span><br></pre></td></tr></table></figure></li></ol><h2 id="zip"><a href="#zip" class="headerlink" title="zip()"></a>zip()</h2><p>zip函数接受任意多个序列作为参数，返回一个tuple列表<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">print(zip(range(<span class="number">3</span>),range(<span class="number">5</span>)))</span><br><span class="line">[(<span class="number">0</span>, <span class="number">0</span>), (<span class="number">1</span>, <span class="number">1</span>), (<span class="number">2</span>, <span class="number">2</span>)]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i,j <span class="keyword">in</span> zip(range(<span class="number">3</span>),range(<span class="number">5</span>)):</span><br><span class="line">    print(i)</span><br><span class="line">    print(j)</span><br><span class="line"><span class="number">0</span></span><br><span class="line"><span class="number">0</span></span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="number">2</span></span><br><span class="line"><span class="number">2</span></span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;open&quot;&gt;&lt;a href=&quot;#open&quot; class=&quot;headerlink&quot; title=&quot;open()&quot;&gt;&lt;/a&gt;open()&lt;/h2&gt;&lt;p&gt;1简单的文件读写&lt;/p&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;
      
    
    </summary>
    
      <category term="python" scheme="http://yoursite.com/categories/python/"/>
    
    
      <category term="python" scheme="http://yoursite.com/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>1向量、矩阵、向量范数、矩阵范数</title>
    <link href="http://yoursite.com/2018/04/19/math/linear_algebra/1%E5%90%91%E9%87%8F%E3%80%81%E7%9F%A9%E9%98%B5%E3%80%81%E5%90%91%E9%87%8F%E8%8C%83%E6%95%B0%E3%80%81%E7%9F%A9%E9%98%B5%E8%8C%83%E6%95%B0/"/>
    <id>http://yoursite.com/2018/04/19/math/linear_algebra/1向量、矩阵、向量范数、矩阵范数/</id>
    <published>2018-04-18T16:51:27.000Z</published>
    <updated>2018-04-23T08:33:01.267Z</updated>
    
    <content type="html"><![CDATA[<h2 id="向量"><a href="#向量" class="headerlink" title="向量"></a>向量</h2><h3 id="向量内积-和-投影"><a href="#向量内积-和-投影" class="headerlink" title="向量内积 和 投影"></a>向量内积 和 投影</h3><p><img src="/2018/04/19/math/linear_algebra/1向量、矩阵、向量范数、矩阵范数/2018-04-20-19-52-26.png" alt=""><br>内积：<br>1用点乘：a•b<br>2用转置乘：a^T b<br>3向量的模是范数的一种<br>4 wT w《=》向量自己做内积 = 自身长度（模）²，因为投影结果还是w向量本身</p><p>投影：<br>1 b在a上的投影 = |b|cosθ<br>2 内积 = 向量1在向量2上的投影 * 他的长度（模，绝对值符号）；<br>3 由2又有：b在a上的投影 = $\frac {a^T b} {||a||}$ ★</p><h3 id="向量外积"><a href="#向量外积" class="headerlink" title="向量外积"></a>向量外积</h3><h3 id="向量范数"><a href="#向量范数" class="headerlink" title="向量范数"></a>向量范数</h3><ol><li>向量范数的定义和性质：</li></ol><p><img src="/2018/04/19/math/linear_algebra/1向量、矩阵、向量范数、矩阵范数/2018-04-20-19-56-23.png" alt=""><br>齐次性：数乘以后会放大相应的倍数</p><ol><li>1-范数、2-范数、无穷范数：</li></ol><p><img src="/2018/04/19/math/linear_algebra/1向量、矩阵、向量范数、矩阵范数/2018-04-20-19-56-55.png" alt=""></p><ol><li><p>稀疏性 和 0-范数：<br><img src="/2018/04/19/math/linear_algebra/1向量、矩阵、向量范数、矩阵范数/2018-04-20-19-57-09.png" alt=""><br>稀疏性用到的范数：<br>特殊的0-范数，他不满足齐次性；<br>所以需要1-范数来辅助解决；</p></li><li><p>范数的几何意义：<br><img src="/2018/04/19/math/linear_algebra/1向量、矩阵、向量范数、矩阵范数/2018-04-20-20-32-56.png" alt=""><br><img src="/2018/04/19/math/linear_algebra/1向量、矩阵、向量范数、矩阵范数/2018-04-20-22-29-03.png" alt=""></p></li></ol><h3 id="向量组"><a href="#向量组" class="headerlink" title="向量组"></a>向量组</h3><ol><li><p>初始单位向两组<br><img src="/2018/04/19/math/linear_algebra/1向量、矩阵、向量范数、矩阵范数/2018-04-20-22-30-44.png" alt=""></p></li><li><p>向量组等价<br><img src="/2018/04/19/math/linear_algebra/1向量、矩阵、向量范数、矩阵范数/2018-04-20-23-10-16.png" alt=""></p></li><li>线性相关 和 线性无关<br><img src="/2018/04/19/math/linear_algebra/1向量、矩阵、向量范数、矩阵范数/2018-04-20-23-10-28.png" alt=""></li><li>施密特正交化<br><img src="/2018/04/19/math/linear_algebra/1向量、矩阵、向量范数、矩阵范数/2018-04-20-23-10-41.png" alt=""><br>由施密特正交化生成的 正交向量组 和 之前的线性无关向量组 可以互相线性表示</li></ol><h2 id="矩阵"><a href="#矩阵" class="headerlink" title="矩阵"></a>矩阵</h2><ul><li>O矩阵<br>所有元素都为0的矩阵<br><br></li><li>一阶矩阵(a)<br>等同于数a<br><br></li><li>矩阵的内积<br>内积 A·B  &lt;=&gt;  ${A^T}B$<h2 id="矩阵范数"><a href="#矩阵范数" class="headerlink" title="矩阵范数"></a>矩阵范数</h2><img src="/2018/04/19/math/linear_algebra/1向量、矩阵、向量范数、矩阵范数/2018-04-22-17-47-24.png" alt=""><br>矩阵的范数比向量的范数多一条相容性</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;向量&quot;&gt;&lt;a href=&quot;#向量&quot; class=&quot;headerlink&quot; title=&quot;向量&quot;&gt;&lt;/a&gt;向量&lt;/h2&gt;&lt;h3 id=&quot;向量内积-和-投影&quot;&gt;&lt;a href=&quot;#向量内积-和-投影&quot; class=&quot;headerlink&quot; title=&quot;向量内积 和 
      
    
    </summary>
    
      <category term="math" scheme="http://yoursite.com/categories/math/"/>
    
      <category term="linear_algebra" scheme="http://yoursite.com/categories/math/linear-algebra/"/>
    
    
      <category term="范数" scheme="http://yoursite.com/tags/%E8%8C%83%E6%95%B0/"/>
    
      <category term="外积" scheme="http://yoursite.com/tags/%E5%A4%96%E7%A7%AF/"/>
    
  </entry>
  
  <entry>
    <title>2矩阵的运算、行列式</title>
    <link href="http://yoursite.com/2018/04/19/math/linear_algebra/2%E7%9F%A9%E9%98%B5%E7%9A%84%E8%BF%90%E7%AE%97%E3%80%81%E8%A1%8C%E5%88%97%E5%BC%8F/"/>
    <id>http://yoursite.com/2018/04/19/math/linear_algebra/2矩阵的运算、行列式/</id>
    <published>2018-04-18T16:51:27.000Z</published>
    <updated>2018-04-23T08:33:39.337Z</updated>
    
    <content type="html"><![CDATA[<h2 id="矩阵的运算"><a href="#矩阵的运算" class="headerlink" title="矩阵的运算"></a>矩阵的运算</h2><p>1 矩阵乘法的具体应用<br><img src="/2018/04/19/math/linear_algebra/2矩阵的运算、行列式/2018-04-22-18-51-07.png" alt=""><br>总结：<br>A中每个元素和B中每个元素相乘是有意义的；<br>B矩阵和最终C矩阵指标数相等，相当于对应指标类元素的求和</p><h2 id="几种特殊的矩阵"><a href="#几种特殊的矩阵" class="headerlink" title="几种特殊的矩阵"></a>几种特殊的矩阵</h2><p>1.对角矩阵<br>2.数量矩阵★<br><img src="/2018/04/19/math/linear_algebra/2矩阵的运算、行列式/2018-04-22-19-08-14.png" alt=""><br>3.单矩阵<br>4.三角矩阵<br>5.对称矩阵</p><h2 id="分块矩阵和其运算"><a href="#分块矩阵和其运算" class="headerlink" title="分块矩阵和其运算"></a>分块矩阵和其运算</h2><p>1 简介：<br><img src="/2018/04/19/math/linear_algebra/2矩阵的运算、行列式/2018-04-22-19-09-25.png" alt=""><br>2 分块矩阵相加和相乘<br>A+B 和 AB<br>相加：要求每个子块矩阵有相同的行数和列数<br>相乘：要求A的列 = B的行</p><h2 id="行列式"><a href="#行列式" class="headerlink" title="行列式"></a>行列式</h2><p>1 矩阵的行列式和他的转置的行列式相等</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;矩阵的运算&quot;&gt;&lt;a href=&quot;#矩阵的运算&quot; class=&quot;headerlink&quot; title=&quot;矩阵的运算&quot;&gt;&lt;/a&gt;矩阵的运算&lt;/h2&gt;&lt;p&gt;1 矩阵乘法的具体应用&lt;br&gt;&lt;img src=&quot;/2018/04/19/math/linear_algebra/2
      
    
    </summary>
    
      <category term="math" scheme="http://yoursite.com/categories/math/"/>
    
      <category term="linear_algebra" scheme="http://yoursite.com/categories/math/linear-algebra/"/>
    
    
  </entry>
  
  <entry>
    <title>数据挖掘——信用卡欺诈检测</title>
    <link href="http://yoursite.com/2018/04/19/machine_learning_in_action/CreditCard/"/>
    <id>http://yoursite.com/2018/04/19/machine_learning_in_action/CreditCard/</id>
    <published>2018-04-18T16:51:27.000Z</published>
    <updated>2018-04-23T08:45:47.082Z</updated>
    
    <content type="html"><![CDATA[<h1 id="案例：用-逻辑回归-预测-信用卡欺诈"><a href="#案例：用-逻辑回归-预测-信用卡欺诈" class="headerlink" title="案例：用 逻辑回归 预测 信用卡欺诈"></a>案例：用 逻辑回归 预测 信用卡欺诈</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data = pd.read_csv(<span class="string">"creditcard.csv"</span>)</span><br><span class="line">data.head()</span><br></pre></td></tr></table></figure><div><style>    .dataframe thead tr:only-child th {        text-align: right;    }    .dataframe thead th {        text-align: left;    }    .dataframe tbody tr th {        vertical-align: top;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>Time</th>      <th>V1</th>      <th>V2</th>      <th>V3</th>      <th>V4</th>      <th>V5</th>      <th>V6</th>      <th>V7</th>      <th>V8</th>      <th>V9</th>      <th>...</th>      <th>V21</th>      <th>V22</th>      <th>V23</th>      <th>V24</th>      <th>V25</th>      <th>V26</th>      <th>V27</th>      <th>V28</th>      <th>Amount</th>      <th>Class</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>0.0</td>      <td>-1.359807</td>      <td>-0.072781</td>      <td>2.536347</td>      <td>1.378155</td>      <td>-0.338321</td>      <td>0.462388</td>      <td>0.239599</td>      <td>0.098698</td>      <td>0.363787</td>      <td>...</td>      <td>-0.018307</td>      <td>0.277838</td>      <td>-0.110474</td>      <td>0.066928</td>      <td>0.128539</td>      <td>-0.189115</td>      <td>0.133558</td>      <td>-0.021053</td>      <td>149.62</td>      <td>0</td>    </tr>    <tr>      <th>1</th>      <td>0.0</td>      <td>1.191857</td>      <td>0.266151</td>      <td>0.166480</td>      <td>0.448154</td>      <td>0.060018</td>      <td>-0.082361</td>      <td>-0.078803</td>      <td>0.085102</td>      <td>-0.255425</td>      <td>...</td>      <td>-0.225775</td>      <td>-0.638672</td>      <td>0.101288</td>      <td>-0.339846</td>      <td>0.167170</td>      <td>0.125895</td>      <td>-0.008983</td>      <td>0.014724</td>      <td>2.69</td>      <td>0</td>    </tr>    <tr>      <th>2</th>      <td>1.0</td>      <td>-1.358354</td>      <td>-1.340163</td>      <td>1.773209</td>      <td>0.379780</td>      <td>-0.503198</td>      <td>1.800499</td>      <td>0.791461</td>      <td>0.247676</td>      <td>-1.514654</td>      <td>...</td>      <td>0.247998</td>      <td>0.771679</td>      <td>0.909412</td>      <td>-0.689281</td>      <td>-0.327642</td>      <td>-0.139097</td>      <td>-0.055353</td>      <td>-0.059752</td>      <td>378.66</td>      <td>0</td>    </tr>    <tr>      <th>3</th>      <td>1.0</td>      <td>-0.966272</td>      <td>-0.185226</td>      <td>1.792993</td>      <td>-0.863291</td>      <td>-0.010309</td>      <td>1.247203</td>      <td>0.237609</td>      <td>0.377436</td>      <td>-1.387024</td>      <td>...</td>      <td>-0.108300</td>      <td>0.005274</td>      <td>-0.190321</td>      <td>-1.175575</td>      <td>0.647376</td>      <td>-0.221929</td>      <td>0.062723</td>      <td>0.061458</td>      <td>123.50</td>      <td>0</td>    </tr>    <tr>      <th>4</th>      <td>2.0</td>      <td>-1.158233</td>      <td>0.877737</td>      <td>1.548718</td>      <td>0.403034</td>      <td>-0.407193</td>      <td>0.095921</td>      <td>0.592941</td>      <td>-0.270533</td>      <td>0.817739</td>      <td>...</td>      <td>-0.009431</td>      <td>0.798278</td>      <td>-0.137458</td>      <td>0.141267</td>      <td>-0.206010</td>      <td>0.502292</td>      <td>0.219422</td>      <td>0.215153</td>      <td>69.99</td>      <td>0</td>    </tr>  </tbody></table><p>5 rows × 31 columns</p></div><h1 id="1数据预处理——归一化、去掉不用的列"><a href="#1数据预处理——归一化、去掉不用的列" class="headerlink" title="1数据预处理——归一化、去掉不用的列"></a>1数据预处理——归一化、去掉不用的列</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">count_classes = pd.value_counts(data[<span class="string">'Class'</span>], sort = <span class="keyword">True</span>).sort_index()</span><br><span class="line">count_classes.plot(kind = <span class="string">'bar'</span>)</span><br><span class="line">plt.title(<span class="string">"Fraud class histogram"</span>)</span><br><span class="line">plt.xlabel(<span class="string">"Class"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"Frequency"</span>)</span><br><span class="line"><span class="comment">#发现样本分布十分不均衡</span></span><br><span class="line"><span class="comment">#策略：统一不同类别样本总数 </span></span><br><span class="line"><span class="comment">#1）oversample——过采样，把少的增多 </span></span><br><span class="line"><span class="comment">#2) undersample——欠采样，把多的减少</span></span><br></pre></td></tr></table></figure><pre><code>&lt;matplotlib.text.Text at 0x5d32f27ef0&gt;</code></pre><p><img src="/2018/04/19/machine_learning_in_action/CreditCard/output_4_1.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#用sklearn 函数来进行归一化(自带合并到原dataframe功能)</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler  </span><br><span class="line"></span><br><span class="line">data[<span class="string">'normAmount'</span>] = StandardScaler().fit_transform(data[<span class="string">'Amount'</span>].values.reshape(<span class="number">-1</span>, <span class="number">1</span>))</span><br><span class="line">data = data.drop([<span class="string">'Time'</span>,<span class="string">'Amount'</span>],axis=<span class="number">1</span>)</span><br><span class="line">data.head()</span><br></pre></td></tr></table></figure><div><style>    .dataframe thead tr:only-child th {        text-align: right;    }    .dataframe thead th {        text-align: left;    }    .dataframe tbody tr th {        vertical-align: top;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>V1</th>      <th>V2</th>      <th>V3</th>      <th>V4</th>      <th>V5</th>      <th>V6</th>      <th>V7</th>      <th>V8</th>      <th>V9</th>      <th>V10</th>      <th>...</th>      <th>V21</th>      <th>V22</th>      <th>V23</th>      <th>V24</th>      <th>V25</th>      <th>V26</th>      <th>V27</th>      <th>V28</th>      <th>Class</th>      <th>normAmount</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>-1.359807</td>      <td>-0.072781</td>      <td>2.536347</td>      <td>1.378155</td>      <td>-0.338321</td>      <td>0.462388</td>      <td>0.239599</td>      <td>0.098698</td>      <td>0.363787</td>      <td>0.090794</td>      <td>...</td>      <td>-0.018307</td>      <td>0.277838</td>      <td>-0.110474</td>      <td>0.066928</td>      <td>0.128539</td>      <td>-0.189115</td>      <td>0.133558</td>      <td>-0.021053</td>      <td>0</td>      <td>0.244964</td>    </tr>    <tr>      <th>1</th>      <td>1.191857</td>      <td>0.266151</td>      <td>0.166480</td>      <td>0.448154</td>      <td>0.060018</td>      <td>-0.082361</td>      <td>-0.078803</td>      <td>0.085102</td>      <td>-0.255425</td>      <td>-0.166974</td>      <td>...</td>      <td>-0.225775</td>      <td>-0.638672</td>      <td>0.101288</td>      <td>-0.339846</td>      <td>0.167170</td>      <td>0.125895</td>      <td>-0.008983</td>      <td>0.014724</td>      <td>0</td>      <td>-0.342475</td>    </tr>    <tr>      <th>2</th>      <td>-1.358354</td>      <td>-1.340163</td>      <td>1.773209</td>      <td>0.379780</td>      <td>-0.503198</td>      <td>1.800499</td>      <td>0.791461</td>      <td>0.247676</td>      <td>-1.514654</td>      <td>0.207643</td>      <td>...</td>      <td>0.247998</td>      <td>0.771679</td>      <td>0.909412</td>      <td>-0.689281</td>      <td>-0.327642</td>      <td>-0.139097</td>      <td>-0.055353</td>      <td>-0.059752</td>      <td>0</td>      <td>1.160686</td>    </tr>    <tr>      <th>3</th>      <td>-0.966272</td>      <td>-0.185226</td>      <td>1.792993</td>      <td>-0.863291</td>      <td>-0.010309</td>      <td>1.247203</td>      <td>0.237609</td>      <td>0.377436</td>      <td>-1.387024</td>      <td>-0.054952</td>      <td>...</td>      <td>-0.108300</td>      <td>0.005274</td>      <td>-0.190321</td>      <td>-1.175575</td>      <td>0.647376</td>      <td>-0.221929</td>      <td>0.062723</td>      <td>0.061458</td>      <td>0</td>      <td>0.140534</td>    </tr>    <tr>      <th>4</th>      <td>-1.158233</td>      <td>0.877737</td>      <td>1.548718</td>      <td>0.403034</td>      <td>-0.407193</td>      <td>0.095921</td>      <td>0.592941</td>      <td>-0.270533</td>      <td>0.817739</td>      <td>0.753074</td>      <td>...</td>      <td>-0.009431</td>      <td>0.798278</td>      <td>-0.137458</td>      <td>0.141267</td>      <td>-0.206010</td>      <td>0.502292</td>      <td>0.219422</td>      <td>0.215153</td>      <td>0</td>      <td>-0.073403</td>    </tr>  </tbody></table><p>5 rows × 30 columns</p></div><h1 id="1数据预处理——解决样本分布不均衡问题之undersample"><a href="#1数据预处理——解决样本分布不均衡问题之undersample" class="headerlink" title="1数据预处理——解决样本分布不均衡问题之undersample"></a>1数据预处理——解决样本分布不均衡问题之undersample</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 方式一：采用“undersample”构建模型</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#把数据集切分为 样本 和 标记 存变量</span></span><br><span class="line">X = data.loc[:, data.columns != <span class="string">'Class'</span>]</span><br><span class="line">y = data.loc[:, data.columns == <span class="string">'Class'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">#计算欺诈样本总数</span></span><br><span class="line">number_records_fraud = len(data[data.Class == <span class="number">1</span>])  </span><br><span class="line"><span class="comment">#取得欺诈行为的样本index</span></span><br><span class="line">fraud_indices = np.array(data[data.Class == <span class="number">1</span>].index)  </span><br><span class="line"></span><br><span class="line"><span class="comment">#取得正常的样本index</span></span><br><span class="line">normal_indices = data[data.Class == <span class="number">0</span>].index   </span><br><span class="line"></span><br><span class="line"><span class="comment"># 随机选出 和 欺诈类数量相同的 正常Index</span></span><br><span class="line">random_normal_indices = np.random.choice(normal_indices, number_records_fraud, replace = <span class="keyword">False</span>)</span><br><span class="line">random_normal_indices = np.array(random_normal_indices)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 合并取得的两组index，作为欠采样index</span></span><br><span class="line">under_sample_indices = np.concatenate([fraud_indices,random_normal_indices])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 取得欠采样dataset</span></span><br><span class="line">under_sample_data = data.iloc[under_sample_indices,:]</span><br><span class="line"></span><br><span class="line"><span class="comment">#把undersample数据集切分为 样本 和 标记 存变量</span></span><br><span class="line">X_undersample = under_sample_data.loc[:, under_sample_data.columns != <span class="string">'Class'</span>]</span><br><span class="line">y_undersample = under_sample_data.loc[:, under_sample_data.columns == <span class="string">'Class'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示处理结果</span></span><br><span class="line">print(<span class="string">"Percentage of normal transactions: "</span>, len(under_sample_data[under_sample_data.Class == <span class="number">0</span>])/len(under_sample_data))</span><br><span class="line">print(<span class="string">"Percentage of fraud transactions: "</span>, len(under_sample_data[under_sample_data.Class == <span class="number">1</span>])/len(under_sample_data))</span><br><span class="line">print(<span class="string">"Total number of transactions in resampled data: "</span>, len(under_sample_data))</span><br></pre></td></tr></table></figure><pre><code>Percentage of normal transactions:  0.5Percentage of fraud transactions:  0.5Total number of transactions in resampled data:  984</code></pre><h1 id="1数据预处理——划分训练和测试集"><a href="#1数据预处理——划分训练和测试集" class="headerlink" title="1数据预处理——划分训练和测试集"></a>1数据预处理——划分训练和测试集</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#引入数据集切分函数</span></span><br><span class="line"><span class="keyword">from</span> sklearn.cross_validation <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line"><span class="comment"># Whole dataset 划分全部数据</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = <span class="number">0.3</span>, random_state = <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"Number transactions train dataset: "</span>, len(X_train))</span><br><span class="line">print(<span class="string">"Number transactions test dataset: "</span>, len(X_test))</span><br><span class="line">print(<span class="string">"Total number of transactions: "</span>, len(X_train)+len(X_test))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Undersampled dataset 划分欠采样数据</span></span><br><span class="line">X_train_undersample, X_test_undersample, y_train_undersample, y_test_undersample = train_test_split(X_undersample</span><br><span class="line">                                                                                                   ,y_undersample</span><br><span class="line">                                                                                                   ,test_size = <span class="number">0.3</span></span><br><span class="line">                                                                                                   ,random_state = <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">""</span>)</span><br><span class="line">print(<span class="string">"Number transactions train dataset: "</span>, len(X_train_undersample))</span><br><span class="line">print(<span class="string">"Number transactions test dataset: "</span>, len(X_test_undersample))</span><br><span class="line">print(<span class="string">"Total number of transactions: "</span>, len(X_train_undersample)+len(X_test_undersample))</span><br></pre></td></tr></table></figure><pre><code>Number transactions train dataset:  199364Number transactions test dataset:  85443Total number of transactions:  284807Number transactions train dataset:  688Number transactions test dataset:  296Total number of transactions:  984</code></pre><h1 id="2-交叉验证——在训练集上做，找最好的逻辑回归正则惩罚系数C"><a href="#2-交叉验证——在训练集上做，找最好的逻辑回归正则惩罚系数C" class="headerlink" title="2 交叉验证——在训练集上做，找最好的逻辑回归正则惩罚系数C"></a>2 交叉验证——在训练集上做，找最好的逻辑回归正则惩罚系数C</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Recall = TP/(TP+FN)  这里适用召回率来检测</span></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.cross_validation <span class="keyword">import</span> KFold, cross_val_score</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix,recall_score,classification_report</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 自己实现召回率的 K=5的交叉验证函数（注意：此处是在训练集上的交叉验证）</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">printing_Kfold_scores</span><span class="params">(x_train_data,y_train_data)</span>:</span></span><br><span class="line">    fold = KFold(len(y_train_data),<span class="number">5</span>,shuffle=<span class="keyword">False</span>) </span><br><span class="line"></span><br><span class="line">    <span class="comment"># Different C parameters   </span></span><br><span class="line">    <span class="comment">#在sklearn里面，惩罚系数是倒数，比如100其实是0.01</span></span><br><span class="line">    <span class="comment">#每个都试一遍，看哪个模型最好</span></span><br><span class="line">    c_param_range = [<span class="number">0.01</span>,<span class="number">0.1</span>,<span class="number">1</span>,<span class="number">10</span>,<span class="number">100</span>]</span><br><span class="line"></span><br><span class="line">    results_table = pd.DataFrame(index = range(len(c_param_range),<span class="number">2</span>), columns = [<span class="string">'C_parameter'</span>,<span class="string">'Mean recall score'</span>])</span><br><span class="line">    results_table[<span class="string">'C_parameter'</span>] = c_param_range</span><br><span class="line"></span><br><span class="line">    <span class="comment"># the k-fold will give 2 lists: train_indices = indices[0], test_indices = indices[1]</span></span><br><span class="line">    j = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> c_param <span class="keyword">in</span> c_param_range:</span><br><span class="line">        print(<span class="string">'-------------------------------------------'</span>)</span><br><span class="line">        print(<span class="string">'C parameter: '</span>, c_param)</span><br><span class="line">        print(<span class="string">'-------------------------------------------'</span>)</span><br><span class="line">        print(<span class="string">''</span>)</span><br><span class="line"></span><br><span class="line">        recall_accs = []</span><br><span class="line">        <span class="comment"># iteration：迭代轮数1-5</span></span><br><span class="line">        <span class="comment"># indices：[0]表示训练集索引集合，[1]表示测试集索引集合</span></span><br><span class="line">        <span class="keyword">for</span> iteration, indices <span class="keyword">in</span> enumerate(fold,start=<span class="number">1</span>):</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Call the logistic regression model with a certain C parameter</span></span><br><span class="line">            <span class="comment"># C：指定惩罚项的参数</span></span><br><span class="line">            <span class="comment"># penalty：指定惩罚项的算法</span></span><br><span class="line">            lr = LogisticRegression(C = c_param, penalty = <span class="string">'l1'</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Use the training data to fit the model. In this case, we use the portion of the fold to train the model</span></span><br><span class="line">            <span class="comment"># with indices[0]. We then predict on the portion assigned as the 'test cross validation' with indices[1]</span></span><br><span class="line">            lr.fit(x_train_data.iloc[indices[<span class="number">0</span>],:],y_train_data.iloc[indices[<span class="number">0</span>],:].values.ravel())</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Predict values using the test indices in the training data</span></span><br><span class="line">            y_pred_undersample = lr.predict(x_train_data.iloc[indices[<span class="number">1</span>],:].values)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Calculate the recall score and append it to a list for recall scores representing the current c_parameter</span></span><br><span class="line">            recall_acc = recall_score(y_train_data.iloc[indices[<span class="number">1</span>],:].values,y_pred_undersample)</span><br><span class="line">            recall_accs.append(recall_acc)</span><br><span class="line">            print(<span class="string">'Iteration '</span>, iteration,<span class="string">': recall score = '</span>, recall_acc)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># The mean value of those recall scores is the metric we want to save and get hold of.</span></span><br><span class="line">        results_table.loc[j,<span class="string">'Mean recall score'</span>] = np.mean(recall_accs)</span><br><span class="line">        j += <span class="number">1</span></span><br><span class="line">        print(<span class="string">''</span>)</span><br><span class="line">        print(<span class="string">'Mean recall score '</span>, np.mean(recall_accs))</span><br><span class="line">        print(<span class="string">''</span>)</span><br><span class="line"></span><br><span class="line">    best_c = results_table.loc[results_table[<span class="string">'Mean recall score'</span>].idxmax()][<span class="string">'C_parameter'</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Finally, we can check which C parameter is the best amongst the chosen.</span></span><br><span class="line">    print(<span class="string">'*********************************************************************************'</span>)</span><br><span class="line">    print(<span class="string">'Best model to choose from cross validation is with C parameter = '</span>, best_c)</span><br><span class="line">    print(<span class="string">'*********************************************************************************'</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> best_c</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">best_c = printing_Kfold_scores(X_train_undersample,y_train_undersample)</span><br></pre></td></tr></table></figure><pre><code>-------------------------------------------C parameter:  0.01-------------------------------------------Iteration  1 : recall score =  0.931506849315Iteration  2 : recall score =  0.931506849315Iteration  3 : recall score =  1.0Iteration  4 : recall score =  0.972972972973Iteration  5 : recall score =  0.969696969697Mean recall score  0.96113672826-------------------------------------------C parameter:  0.1-------------------------------------------Iteration  1 : recall score =  0.849315068493Iteration  2 : recall score =  0.86301369863Iteration  3 : recall score =  0.932203389831Iteration  4 : recall score =  0.945945945946Iteration  5 : recall score =  0.893939393939Mean recall score  0.896883499368-------------------------------------------C parameter:  1-------------------------------------------Iteration  1 : recall score =  0.86301369863Iteration  2 : recall score =  0.890410958904Iteration  3 : recall score =  0.983050847458Iteration  4 : recall score =  0.945945945946Iteration  5 : recall score =  0.909090909091Mean recall score  0.918302472006-------------------------------------------C parameter:  10-------------------------------------------Iteration  1 : recall score =  0.86301369863Iteration  2 : recall score =  0.904109589041Iteration  3 : recall score =  0.983050847458Iteration  4 : recall score =  0.945945945946Iteration  5 : recall score =  0.909090909091Mean recall score  0.921042198033-------------------------------------------C parameter:  100-------------------------------------------Iteration  1 : recall score =  0.876712328767Iteration  2 : recall score =  0.890410958904Iteration  3 : recall score =  0.983050847458Iteration  4 : recall score =  0.945945945946Iteration  5 : recall score =  0.909090909091Mean recall score  0.921042198033*********************************************************************************Best model to choose from cross validation is with C parameter =  0.01*********************************************************************************</code></pre><h1 id="3训练-测试——用best-C在训练集上重新训练一遍，再在undersample测试集上预测用-混淆矩阵-计算recall值"><a href="#3训练-测试——用best-C在训练集上重新训练一遍，再在undersample测试集上预测用-混淆矩阵-计算recall值" class="headerlink" title="3训练 + 测试——用best_C在训练集上重新训练一遍，再在undersample测试集上预测用 混淆矩阵 计算recall值"></a>3训练 + 测试——用best_C在训练集上重新训练一遍，再在undersample测试集上预测用 混淆矩阵 计算recall值</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> itertools</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_confusion_matrix</span><span class="params">(cm, classes,</span></span></span><br><span class="line"><span class="function"><span class="params">                          title=<span class="string">'Confusion matrix'</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                          cmap=plt.cm.Blues)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    This function prints and plots the confusion matrix.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    plt.imshow(cm, interpolation=<span class="string">'nearest'</span>, cmap=cmap)</span><br><span class="line">    plt.title(title)</span><br><span class="line">    plt.colorbar()</span><br><span class="line">    tick_marks = np.arange(len(classes))</span><br><span class="line">    plt.xticks(tick_marks, classes, rotation=<span class="number">0</span>)</span><br><span class="line">    plt.yticks(tick_marks, classes)</span><br><span class="line"></span><br><span class="line">    thresh = cm.max() / <span class="number">2.</span></span><br><span class="line">    <span class="keyword">for</span> i, j <span class="keyword">in</span> itertools.product(range(cm.shape[<span class="number">0</span>]), range(cm.shape[<span class="number">1</span>])):</span><br><span class="line">        plt.text(j, i, cm[i, j],</span><br><span class="line">                 horizontalalignment=<span class="string">"center"</span>,</span><br><span class="line">                 color=<span class="string">"white"</span> <span class="keyword">if</span> cm[i, j] &gt; thresh <span class="keyword">else</span> <span class="string">"black"</span>)</span><br><span class="line"></span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    plt.ylabel(<span class="string">'True label'</span>)</span><br><span class="line">    plt.xlabel(<span class="string">'Predicted label'</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">lr = LogisticRegression(C = best_c, penalty = <span class="string">'l1'</span>)</span><br><span class="line">lr.fit(X_train_undersample,y_train_undersample.values.ravel())</span><br><span class="line">y_pred_undersample = lr.predict(X_test_undersample.values)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute confusion matrix</span></span><br><span class="line">cnf_matrix = confusion_matrix(y_test_undersample,y_pred_undersample)</span><br><span class="line">np.set_printoptions(precision=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"Recall metric in the testing dataset: "</span>, cnf_matrix[<span class="number">1</span>,<span class="number">1</span>]/(cnf_matrix[<span class="number">1</span>,<span class="number">0</span>]+cnf_matrix[<span class="number">1</span>,<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot non-normalized confusion matrix</span></span><br><span class="line">class_names = [<span class="number">0</span>,<span class="number">1</span>]</span><br><span class="line">plt.figure()</span><br><span class="line">plot_confusion_matrix(cnf_matrix</span><br><span class="line">                      , classes=class_names</span><br><span class="line">                      , title=<span class="string">'Confusion matrix'</span>)</span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment">#混淆矩阵 显示模型分类效果</span></span><br></pre></td></tr></table></figure><pre><code>Recall metric in the testing dataset:  0.931972789116</code></pre><p><img src="/2018/04/19/machine_learning_in_action/CreditCard/output_16_1.png" alt="png"></p><h1 id="3训练-测试——用best-C在训练集上重新训练一遍，再在-完整-测试集上预测用-混淆矩阵-计算recall值"><a href="#3训练-测试——用best-C在训练集上重新训练一遍，再在-完整-测试集上预测用-混淆矩阵-计算recall值" class="headerlink" title="3训练 + 测试——用best_C在训练集上重新训练一遍，再在 完整 测试集上预测用 混淆矩阵 计算recall值"></a>3训练 + 测试——用best_C在训练集上重新训练一遍，再在 完整 测试集上预测用 混淆矩阵 计算recall值</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">lr = LogisticRegression(C = best_c, penalty = <span class="string">'l1'</span>)</span><br><span class="line">lr.fit(X_train_undersample,y_train_undersample.values.ravel())</span><br><span class="line">y_pred = lr.predict(X_test.values)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute confusion matrix</span></span><br><span class="line">cnf_matrix = confusion_matrix(y_test,y_pred)</span><br><span class="line">np.set_printoptions(precision=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"Recall metric in the testing dataset: "</span>, cnf_matrix[<span class="number">1</span>,<span class="number">1</span>]/(cnf_matrix[<span class="number">1</span>,<span class="number">0</span>]+cnf_matrix[<span class="number">1</span>,<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot non-normalized confusion matrix</span></span><br><span class="line">class_names = [<span class="number">0</span>,<span class="number">1</span>]</span><br><span class="line">plt.figure()</span><br><span class="line">plot_confusion_matrix(cnf_matrix</span><br><span class="line">                      , classes=class_names</span><br><span class="line">                      , title=<span class="string">'Confusion matrix'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><pre><code>Recall metric in the testing dataset:  0.918367346939</code></pre><p><img src="/2018/04/19/machine_learning_in_action/CreditCard/output_18_1.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">这里发现虽然recall值还可以，但是误伤了<span class="number">8581</span>个（被检测成欺诈了），也就是精度accuracy有点低。</span><br><span class="line">故要权衡两者，都要较高才行</span><br></pre></td></tr></table></figure><h1 id="这里展示的是：不做样本平衡处理，直接把所有样本做交叉验证，发现效果很差"><a href="#这里展示的是：不做样本平衡处理，直接把所有样本做交叉验证，发现效果很差" class="headerlink" title="这里展示的是：不做样本平衡处理，直接把所有样本做交叉验证，发现效果很差"></a>这里展示的是：不做样本平衡处理，直接把所有样本做交叉验证，发现效果很差</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">best_c = printing_Kfold_scores(X_train,y_train)</span><br></pre></td></tr></table></figure><pre><code>-------------------------------------------C parameter:  0.01-------------------------------------------Iteration  1 : recall score =  0.492537313433Iteration  2 : recall score =  0.602739726027Iteration  3 : recall score =  0.683333333333Iteration  4 : recall score =  0.569230769231Iteration  5 : recall score =  0.45Mean recall score  0.559568228405-------------------------------------------C parameter:  0.1-------------------------------------------Iteration  1 : recall score =  0.567164179104Iteration  2 : recall score =  0.616438356164Iteration  3 : recall score =  0.683333333333Iteration  4 : recall score =  0.584615384615Iteration  5 : recall score =  0.525Mean recall score  0.595310250644-------------------------------------------C parameter:  1-------------------------------------------Iteration  1 : recall score =  0.55223880597Iteration  2 : recall score =  0.616438356164Iteration  3 : recall score =  0.716666666667Iteration  4 : recall score =  0.615384615385Iteration  5 : recall score =  0.5625Mean recall score  0.612645688837-------------------------------------------C parameter:  10-------------------------------------------Iteration  1 : recall score =  0.55223880597Iteration  2 : recall score =  0.616438356164Iteration  3 : recall score =  0.733333333333Iteration  4 : recall score =  0.615384615385Iteration  5 : recall score =  0.575Mean recall score  0.61847902217-------------------------------------------C parameter:  100-------------------------------------------Iteration  1 : recall score =  0.55223880597Iteration  2 : recall score =  0.616438356164Iteration  3 : recall score =  0.733333333333Iteration  4 : recall score =  0.615384615385Iteration  5 : recall score =  0.575Mean recall score  0.61847902217*********************************************************************************Best model to choose from cross validation is with C parameter =  10.0*********************************************************************************</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">lr = LogisticRegression(C = best_c, penalty = <span class="string">'l1'</span>)</span><br><span class="line">lr.fit(X_train,y_train.values.ravel())</span><br><span class="line">y_pred_undersample = lr.predict(X_test.values)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute confusion matrix</span></span><br><span class="line">cnf_matrix = confusion_matrix(y_test,y_pred_undersample)</span><br><span class="line">np.set_printoptions(precision=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"Recall metric in the testing dataset: "</span>, cnf_matrix[<span class="number">1</span>,<span class="number">1</span>]/(cnf_matrix[<span class="number">1</span>,<span class="number">0</span>]+cnf_matrix[<span class="number">1</span>,<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot non-normalized confusion matrix</span></span><br><span class="line">class_names = [<span class="number">0</span>,<span class="number">1</span>]</span><br><span class="line">plt.figure()</span><br><span class="line">plot_confusion_matrix(cnf_matrix</span><br><span class="line">                      , classes=class_names</span><br><span class="line">                      , title=<span class="string">'Confusion matrix'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><pre><code>Recall metric in the testing dataset:  0.619047619048</code></pre><p><img src="/2018/04/19/machine_learning_in_action/CreditCard/output_22_1.png" alt="png"></p><h1 id="4-用predict-proba来测试-最好的逻辑回归-阈值"><a href="#4-用predict-proba来测试-最好的逻辑回归-阈值" class="headerlink" title="4 用predict_proba来测试 最好的逻辑回归 阈值"></a>4 用predict_proba来测试 最好的逻辑回归 阈值</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">lr = LogisticRegression(C = <span class="number">0.01</span>, penalty = <span class="string">'l1'</span>)</span><br><span class="line">lr.fit(X_train_undersample,y_train_undersample.values.ravel())</span><br><span class="line">y_pred_undersample_proba = lr.predict_proba(X_test_undersample.values)</span><br><span class="line"></span><br><span class="line">thresholds = [<span class="number">0.1</span>,<span class="number">0.2</span>,<span class="number">0.3</span>,<span class="number">0.4</span>,<span class="number">0.5</span>,<span class="number">0.6</span>,<span class="number">0.7</span>,<span class="number">0.8</span>,<span class="number">0.9</span>]</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">10</span>))</span><br><span class="line"></span><br><span class="line">j = <span class="number">1</span></span><br><span class="line"><span class="keyword">for</span> threshold <span class="keyword">in</span> thresholds:</span><br><span class="line">    y_test_predictions_high_recall = y_pred_undersample_proba[:,<span class="number">1</span>] &gt; threshold</span><br><span class="line">    </span><br><span class="line">    plt.subplot(<span class="number">3</span>,<span class="number">3</span>,j)</span><br><span class="line">    j += <span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Compute confusion matrix</span></span><br><span class="line">    cnf_matrix = confusion_matrix(y_test_undersample,y_test_predictions_high_recall)</span><br><span class="line">    np.set_printoptions(precision=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"Recall metric in the testing dataset: "</span>, cnf_matrix[<span class="number">1</span>,<span class="number">1</span>]/(cnf_matrix[<span class="number">1</span>,<span class="number">0</span>]+cnf_matrix[<span class="number">1</span>,<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Plot non-normalized confusion matrix</span></span><br><span class="line">    class_names = [<span class="number">0</span>,<span class="number">1</span>]</span><br><span class="line">    plot_confusion_matrix(cnf_matrix</span><br><span class="line">                          , classes=class_names</span><br><span class="line">                          , title=<span class="string">'Threshold &gt;= %s'</span>%threshold)</span><br></pre></td></tr></table></figure><pre><code>Recall metric in the testing dataset:  1.0Recall metric in the testing dataset:  1.0Recall metric in the testing dataset:  1.0Recall metric in the testing dataset:  0.993197278912Recall metric in the testing dataset:  0.931972789116Recall metric in the testing dataset:  0.884353741497Recall metric in the testing dataset:  0.843537414966Recall metric in the testing dataset:  0.748299319728Recall metric in the testing dataset:  0.578231292517</code></pre><p><img src="/2018/04/19/machine_learning_in_action/CreditCard/output_24_1.png" alt="png"></p><h1 id="1数据预处理——解决样本分布不均衡问题之oversample"><a href="#1数据预处理——解决样本分布不均衡问题之oversample" class="headerlink" title="1数据预处理——解决样本分布不均衡问题之oversample"></a>1数据预处理——解决样本分布不均衡问题之oversample</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="comment"># 安装命令：pip install imblearn</span></span><br><span class="line"><span class="keyword">from</span> imblearn.over_sampling <span class="keyword">import</span> SMOTE</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">credit_cards=pd.read_csv(<span class="string">'creditcard.csv'</span>)</span><br><span class="line"></span><br><span class="line">columns=credit_cards.columns</span><br><span class="line"><span class="comment"># The labels are in the last column ('Class'). Simply remove it to obtain features columns</span></span><br><span class="line">features_columns=columns.delete(len(columns)<span class="number">-1</span>)</span><br><span class="line"></span><br><span class="line">features=credit_cards[features_columns]</span><br><span class="line">labels=credit_cards[<span class="string">'Class'</span>]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#划分数据集</span></span><br><span class="line">features_train, features_test, labels_train, labels_test = train_test_split(features, </span><br><span class="line">                                                                            labels, </span><br><span class="line">                                                                            test_size=<span class="number">0.2</span>, </span><br><span class="line">                                                                            random_state=<span class="number">0</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#★SMOTE算法通过给定的训练集，生成新的随机扩充训练集</span></span><br><span class="line">oversampler=SMOTE(random_state=<span class="number">0</span>)</span><br><span class="line">os_features,os_labels=oversampler.fit_sample(features_train,labels_train)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#生成前，label=0</span></span><br><span class="line">print(len(labels_train[labels_train == <span class="number">0</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment">#生成以后，label=1的变成和=0的一样多</span></span><br><span class="line">print(len(os_labels[os_labels == <span class="number">1</span>]))</span><br></pre></td></tr></table></figure><pre><code>227454227454</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">os_features = pd.DataFrame(os_features)</span><br><span class="line">os_labels = pd.DataFrame(os_labels)</span><br><span class="line">best_c = printing_Kfold_scores(os_features,os_labels)</span><br></pre></td></tr></table></figure><pre><code>-------------------------------------------C parameter:  0.01-------------------------------------------Iteration  1 : recall score =  0.890322580645Iteration  2 : recall score =  0.894736842105Iteration  3 : recall score =  0.968617904172Iteration  4 : recall score =  0.944471922709Iteration  5 : recall score =  0.958397907255Mean recall score  0.931309431377-------------------------------------------C parameter:  0.1-------------------------------------------Iteration  1 : recall score =  0.890322580645Iteration  2 : recall score =  0.894736842105Iteration  3 : recall score =  0.970255615802Iteration  4 : recall score =  0.959991646608Iteration  5 : recall score =  0.96051922929Mean recall score  0.93516518289-------------------------------------------C parameter:  1-------------------------------------------Iteration  1 : recall score =  0.890322580645Iteration  2 : recall score =  0.894736842105Iteration  3 : recall score =  0.970211353325Iteration  4 : recall score =  0.960134533584Iteration  5 : recall score =  0.960442290148Mean recall score  0.935169519962-------------------------------------------C parameter:  10-------------------------------------------Iteration  1 : recall score =  0.890322580645Iteration  2 : recall score =  0.894736842105Iteration  3 : recall score =  0.970322009516Iteration  4 : recall score =  0.95977182049Iteration  5 : recall score =  0.960783020631Mean recall score  0.935187254678-------------------------------------------C parameter:  100-------------------------------------------Iteration  1 : recall score =  0.890322580645Iteration  2 : recall score =  0.894736842105Iteration  3 : recall score =  0.969635941131Iteration  4 : recall score =  0.960255437949Iteration  5 : recall score =  0.960398324925Mean recall score  0.935069825351*********************************************************************************Best model to choose from cross validation is with C parameter =  10.0*********************************************************************************</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">lr = LogisticRegression(C = best_c, penalty = <span class="string">'l1'</span>)</span><br><span class="line">lr.fit(os_features,os_labels.values.ravel())</span><br><span class="line">y_pred = lr.predict(features_test.values)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute confusion matrix</span></span><br><span class="line">cnf_matrix = confusion_matrix(labels_test,y_pred)</span><br><span class="line">np.set_printoptions(precision=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"Recall metric in the testing dataset: "</span>, cnf_matrix[<span class="number">1</span>,<span class="number">1</span>]/(cnf_matrix[<span class="number">1</span>,<span class="number">0</span>]+cnf_matrix[<span class="number">1</span>,<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot non-normalized confusion matrix</span></span><br><span class="line">class_names = [<span class="number">0</span>,<span class="number">1</span>]</span><br><span class="line">plt.figure()</span><br><span class="line">plot_confusion_matrix(cnf_matrix</span><br><span class="line">                      , classes=class_names</span><br><span class="line">                      , title=<span class="string">'Confusion matrix'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><pre><code>Recall metric in the testing dataset:  0.910891089109</code></pre><p><img src="/2018/04/19/machine_learning_in_action/CreditCard/output_32_1.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;案例：用-逻辑回归-预测-信用卡欺诈&quot;&gt;&lt;a href=&quot;#案例：用-逻辑回归-预测-信用卡欺诈&quot; class=&quot;headerlink&quot; title=&quot;案例：用 逻辑回归 预测 信用卡欺诈&quot;&gt;&lt;/a&gt;案例：用 逻辑回归 预测 信用卡欺诈&lt;/h1&gt;&lt;figure c
      
    
    </summary>
    
      <category term="machine_learning_in_action" scheme="http://yoursite.com/categories/machine-learning-in-action/"/>
    
    
      <category term="usersample" scheme="http://yoursite.com/tags/usersample/"/>
    
      <category term="oversample" scheme="http://yoursite.com/tags/oversample/"/>
    
      <category term="K折交叉验证" scheme="http://yoursite.com/tags/K%E6%8A%98%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81/"/>
    
      <category term="混淆矩阵" scheme="http://yoursite.com/tags/%E6%B7%B7%E6%B7%86%E7%9F%A9%E9%98%B5/"/>
    
  </entry>
  
  <entry>
    <title>Hexo Next优化&amp;踩坑</title>
    <link href="http://yoursite.com/2018/04/16/hexo/Hexo%20Next%E4%BC%98%E5%8C%96&amp;%E8%B8%A9%E5%9D%91/"/>
    <id>http://yoursite.com/2018/04/16/hexo/Hexo Next优化&amp;踩坑/</id>
    <published>2018-04-15T16:00:00.000Z</published>
    <updated>2018-04-22T08:01:27.912Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一、界面-篇"><a href="#一、界面-篇" class="headerlink" title="一、界面 篇"></a>一、界面 篇</h1><h2 id="1-添加动态背景"><a href="#1-添加动态背景" class="headerlink" title="1 添加动态背景"></a>1 添加动态背景</h2><h3 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h3><p>在主题配置文件中找到canvas_nest: false，把它改为canvas_nest: true</p><h3 id="修改-layout-swig"><a href="#修改-layout-swig" class="headerlink" title="修改_layout.swig"></a>修改<code>_layout.swig</code></h3><p>打开 <code>next/layout/_layout.swig</code><br>在 <code>&lt; /body&gt;</code>之前添加代码</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#123;% if theme.canvas_nest %&#125;</span><br><span class="line">&lt;script type=&quot;text/javascript&quot;</span><br><span class="line">color=&quot;0,0,0&quot; opacity=&apos;0.5&apos; zIndex=&quot;-2&quot; count=&quot;50&quot; src=&quot;//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js&quot;&gt;&lt;/script&gt;</span><br><span class="line">&#123;% endif %&#125;</span><br></pre></td></tr></table></figure><h4 id="配置项说明"><a href="#配置项说明" class="headerlink" title="配置项说明"></a>配置项说明</h4><ul><li><code>color</code> ：线条颜色, 默认: <code>&#39;0,0,0&#39;</code>；三个数字分别为(R,G,B)</li><li><code>opacity</code>: 线条透明度（0~1）, 默认: <code>0.5</code></li><li><code>count</code>: 线条的总数量, 默认: <code>150</code></li><li><code>zIndex:</code> 背景的z-index属性，css属性用于控制所在层的位置, 默认: <code>-1</code></li></ul><h2 id="2-直接展开文章全部目录"><a href="#2-直接展开文章全部目录" class="headerlink" title="2 直接展开文章全部目录"></a>2 直接展开文章全部目录</h2><p>搜索打开这个文件：sidebar-toc.styl</p><p>把下面的内容注释掉：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">//取消逐渐展开，改为直接展开所有TOC</span><br><span class="line">//.post-toc .nav .nav-child &#123; display: none; &#125;</span><br><span class="line">.post-toc .nav .active &gt; .nav-child &#123; display: block; &#125;</span><br><span class="line">.post-toc .nav .active-current &gt; .nav-child &#123;</span><br><span class="line">  display: block;</span><br><span class="line">  &amp; &gt; .nav-item &#123; display: block; &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="3-添加文章结束标记"><a href="#3-添加文章结束标记" class="headerlink" title="3 添加文章结束标记"></a>3 添加文章结束标记</h2><p>在 next\layout_macro\post.swig 中<code>wechat-subscriber.swig</code> 上面加入如下代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- 添加文章结束标记 --&gt;</span><br><span class="line">&#123;% if not is_index %&#125;</span><br><span class="line">&lt;div style=&quot;text-align:center;color: #000;font-size:14px;&quot;&gt;----------------- The End -----------------&lt;/div&gt;</span><br><span class="line">&#123;% endif %&#125;</span><br></pre></td></tr></table></figure><h2 id="4-实现主页文章预览效果"><a href="#4-实现主页文章预览效果" class="headerlink" title="4 实现主页文章预览效果"></a>4 实现主页文章预览效果</h2><p>进入hexo博客项目的themes/next目录<br>用文本编辑器打开_config.yml文件<br>搜索”auto_excerpt”,找到如下部分：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># Automatically Excerpt. Not recommand.</span><br><span class="line"># Please use &lt;!-- more --&gt; in the post to control excerpt accurately.</span><br><span class="line">auto_excerpt:</span><br><span class="line">  enable: true</span><br><span class="line">  length: 150</span><br></pre></td></tr></table></figure></p><p>把enable值设置为true，就可以控制文章在主页的显示了</p><h2 id="5-添加MathJax数学公式支持"><a href="#5-添加MathJax数学公式支持" class="headerlink" title="5 添加MathJax数学公式支持"></a>5 添加MathJax数学公式支持</h2><h3 id="在主题中开启mathjax开关"><a href="#在主题中开启mathjax开关" class="headerlink" title="在主题中开启mathjax开关"></a>在主题中开启mathjax开关</h3><p>如何使用了主题了，别忘了在主题（Theme）中开启mathjax开关，下面以next主题为例，介绍下如何打开mathjax开关。</p><p>进入到主题目录，找到_config.yml配置问题，把mathjax默认的false修改为true，具体如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># MathJax Support</span><br><span class="line">mathjax:</span><br><span class="line">  enable: true</span><br><span class="line">  per_page: true</span><br></pre></td></tr></table></figure><p>别着急，这样还不够，还需要在文章的Front-matter里打开mathjax开关，如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">title: index.html</span><br><span class="line">date: 2016-12-28 21:01:30</span><br><span class="line">tags:</span><br><span class="line">mathjax: true</span><br><span class="line">--</span><br></pre></td></tr></table></figure><h3 id="更换Hexo的markdown渲染引擎"><a href="#更换Hexo的markdown渲染引擎" class="headerlink" title="更换Hexo的markdown渲染引擎"></a>更换Hexo的markdown渲染引擎</h3><p><a href="https://link.jianshu.com?t=https%3A%2F%2Fgithub.com%2Fsun11%2Fhexo-renderer-kramed" target="_blank" rel="noopener">hexo-renderer-kramed</a>引擎是在默认的渲染引擎<a href="https://link.jianshu.com?t=https%3A%2F%2Fgithub.com%2Fhexojs%2Fhexo-renderer-marked" target="_blank" rel="noopener">hexo-renderer-marked</a>的基础上修改了一些bug，两者比较接近，也比较轻量级。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">npm uninstall hexo-renderer-marked --save</span><br><span class="line">npm install hexo-renderer-kramed --save</span><br></pre></td></tr></table></figure><p>执行上面的命令即可，先卸载原来的渲染引擎，再安装新的。</p><p>然后，跟换引擎后行间公式可以正确渲染了，但是这样还没有完全解决问题，行内公式的渲染还是有问题，因为<a href="https://link.jianshu.com?t=https%3A%2F%2Fgithub.com%2Fsun11%2Fhexo-renderer-kramed" target="_blank" rel="noopener">hexo-renderer-kramed</a>引擎也有语义冲突的问题。接下来到博客根目录下，找到node_modules\kramed\lib\rules\inline.js，把第11行的escape变量的值做相应的修改：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">//  escape: /^\\([\\`*&#123;&#125;\[\]()#$+\-.!_&gt;])/,</span><br><span class="line">  escape: /^\\([`*\[\]()#+\-.!_&gt;])/</span><br></pre></td></tr></table></figure><p>同时把第20行的em变量也要做相应的修改。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">//  em: /^\b_((?:__|[\s\S])+?)_\b|^\*((?:\*\*|[\s\S])+?)\*(?!\*)/,</span><br><span class="line">  em: /^\*((?:\*\*|[\s\S])+?)\*(?!\*)/</span><br></pre></td></tr></table></figure><p>重新启动hexo（先clean再generate）,问题完美解决。</p><h2 id="6-调整页面CSS布局"><a href="#6-调整页面CSS布局" class="headerlink" title="6 调整页面CSS布局"></a>6 调整页面CSS布局</h2><p>为了加宽文章页面显示，在下面两个文件中添加自定义代码<br>在 themes\next\source\css_custom\custom.styl 中：<br><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line">// Custom styles.</span><br><span class="line">//边框效果</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">// 最上面</span></span><br><span class="line"><span class="comment">.content-wrap &#123;</span></span><br><span class="line"><span class="comment">padding: 0 40px 40px 40px;</span></span><br><span class="line"><span class="comment">&#125;</span></span><br><span class="line"><span class="comment">.posts-expand &#123;</span></span><br><span class="line"><span class="comment">padding-top: 0;</span></span><br><span class="line"><span class="comment">&#125;</span></span><br><span class="line"><span class="comment">// 文章</span></span><br><span class="line"><span class="comment">.post &#123;</span></span><br><span class="line"><span class="comment">   margin-top: 60px;</span></span><br><span class="line"><span class="comment">   margin-bottom: 60px;</span></span><br><span class="line"><span class="comment">   padding: 25px;</span></span><br><span class="line"><span class="comment">   -webkit-box-shadow: 1px 1px 1px 1px rgba(202, 203, 203, .5);</span></span><br><span class="line"><span class="comment">   -moz-box-shadow: 1px 1px 1px 1px rgba(202, 203, 204, .5);</span></span><br><span class="line"><span class="comment">  &#125;</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">// 右上</span></span><br><span class="line"><span class="comment">.sidebar-position-right .header-inner &#123;</span></span><br><span class="line"><span class="comment">   -webkit-box-shadow: 1px 1px 1px 1px rgba(202, 203, 203, .5);</span></span><br><span class="line"><span class="comment">   -moz-box-shadow: 1px 1px 1px 1px rgba(202, 203, 204, .5);</span></span><br><span class="line"><span class="comment">&#125;</span></span><br><span class="line"><span class="comment">// 右下</span></span><br><span class="line"><span class="comment">.sidebar .sidebar-inner &#123;</span></span><br><span class="line"><span class="comment">   -webkit-box-shadow: 1px 1px 1px 1px rgba(202, 203, 203, .5);</span></span><br><span class="line"><span class="comment">   -moz-box-shadow: 1px 1px 1px 1px rgba(202, 203, 204, .5);</span></span><br><span class="line"><span class="comment">&#125;</span></span><br><span class="line"><span class="comment">// 右上</span></span><br><span class="line"><span class="comment">.sidebar-position-right .header-inner &#123;</span></span><br><span class="line"><span class="comment">   -webkit-box-shadow: 0 1px 0 0 #262a30;</span></span><br><span class="line"><span class="comment">   -moz-box-shadow: 0 1px 0 0 #262a30;</span></span><br><span class="line"><span class="comment">&#125;</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line">// 最下面</span><br><span class="line"><span class="selector-class">.sidebar-position-right</span> <span class="selector-class">.footer-inner</span> &#123;</span><br><span class="line"><span class="attribute">padding-left</span>: <span class="number">40px</span>;</span><br><span class="line"><span class="attribute">padding-right</span>: <span class="number">280px</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 首页文章添加分割线</span><br><span class="line"><span class="selector-class">.posts-expand</span> <span class="selector-class">.post-eof</span> &#123;</span><br><span class="line">    <span class="attribute">display</span>: block;</span><br><span class="line">    <span class="attribute">margin</span>: <span class="number">80px</span> auto <span class="number">60px</span>;</span><br><span class="line">    <span class="attribute">width</span>: <span class="number">61.8%</span>;</span><br><span class="line">    <span class="attribute">height</span>: <span class="number">1px</span>;</span><br><span class="line">    <span class="attribute">background</span>: <span class="number">#bbb</span>;</span><br><span class="line">    <span class="attribute">text-align</span>: center;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.sidebar-inner</span> &#123;</span><br><span class="line"><span class="attribute">padding</span>: <span class="number">20px</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-class">.music163</span> &#123;</span><br><span class="line"><span class="attribute">margin</span>: <span class="number">20px</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>在 D:\wxy555123.github.io\themes\next\source\css_variables\custom.styl 中：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">// base.stylLayout sizes</span><br><span class="line">// --------------------------------------------------</span><br><span class="line"></span><br><span class="line">//$main-desktop                   = 960px </span><br><span class="line">$main-desktop                   = 1230px  //new 主宽度，也调大防止sidebar遮挡</span><br><span class="line">$main-desktop-large             = 1200px</span><br><span class="line"></span><br><span class="line">//$content-desktop                = 700px</span><br><span class="line">$content-desktop                = 990px //new 文章宽度调大</span><br><span class="line">$content-desktop-large          = 900px</span><br><span class="line"></span><br><span class="line">$content-desktop-padding        = 40px</span><br><span class="line">$content-tablet-padding         = 10px</span><br><span class="line">$content-mobile-padding         = 8px</span><br><span class="line"></span><br><span class="line">$sidebar-desktop                = 240px</span><br><span class="line"></span><br><span class="line">$footer-height                  = 50px</span><br><span class="line"></span><br><span class="line">$gap-between-main-and-footer    = 100px</span><br></pre></td></tr></table></figure></p><h2 id="7-添加-Gitment-评论系统"><a href="#7-添加-Gitment-评论系统" class="headerlink" title="7 添加 Gitment 评论系统"></a>7 添加 Gitment 评论系统</h2><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>本文介绍hexo next主题(5.1.2)集成giment评论系统的过程。所谓gitment就是把评论放到github的issues系统里，评论支持md，比较适合程序员. </p><h2 id="一-注册OAuth-Application"><a href="#一-注册OAuth-Application" class="headerlink" title="一.注册OAuth Application"></a>一.注册OAuth Application</h2><p>点击<a href="https://github.com/settings/applications/new" target="_blank" rel="noopener">https://github.com/settings/applications/new</a>注册，注意<code>Authorization callback URL</code>填自己的网站url<code>http://yangq.me/</code>.记下<strong>Client ID</strong>和<strong>Client Secret</strong>.</p><h2 id="二-修改themes-next-config-yml"><a href="#二-修改themes-next-config-yml" class="headerlink" title="二.修改themes/next/_config.yml"></a>二.修改<code>themes/next/_config.yml</code></h2><p>在其中添加:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># Gitment</span><br><span class="line"># Introduction: https://imsun.net/posts/gitment-introduction/</span><br><span class="line">gitment:</span><br><span class="line">  enable: true</span><br><span class="line">  githubID: yourid</span><br><span class="line">  repo: yourrepo</span><br><span class="line">  ClientID: yourid</span><br><span class="line">  ClientSecret: yoursecret</span><br><span class="line">  lazy: true123456789</span><br></pre></td></tr></table></figure><p><strong>注意:格式要正确，该空格的一定要空格。所有的yourXXX都换成自己的.</strong></p><h2 id="三-修改gitment-swig"><a href="#三-修改gitment-swig" class="headerlink" title="三.修改gitment.swig"></a>三.修改<code>gitment.swig</code></h2><p>在主题下<code>layout/_third-party/comments/</code>目录下中修改文件<code>gitment.swig</code>使得能够正确初始化：</p><p><img src="/2018/04/16/hexo/Hexo Next优化&踩坑/Hexo Next优化&amp;踩坑/2018-04-21-19-40-01.png" alt=""></p><p>修改红框标记的id字段，用日期时间戳代替，使得id不会超过50个字符</p><h1 id="二、操作-篇"><a href="#二、操作-篇" class="headerlink" title="二、操作 篇"></a>二、操作 篇</h1><h2 id="1-Hexo命令"><a href="#1-Hexo命令" class="headerlink" title="1 Hexo命令"></a>1 Hexo命令</h2><ul><li><p>安装主题：用git clone到themes文件夹中</p></li><li><p>生成静态文件：hexo g</p></li><li><p>启动本地服务器：hexo s</p></li><li><p>发布到远程网站：hexo d （hexo d -g 生成的后自动发布）</p><p>​</p></li></ul><ul><li><p>创建文章：hexo new “标题” （默认就在“post”目录里）</p></li><li><p>创建草稿：hexo new draft “标题”</p></li><li><p>把草稿转到“post”目录：hexo publish “标题”</p><p>​</p><p>（注：中间的命令可以用哦个首字母简写）</p></li></ul><h2 id="2-Git命令"><a href="#2-Git命令" class="headerlink" title="2 Git命令"></a>2 Git命令</h2><ul><li>清空你的 github.io 仓库项目中所有文件<br>进入到.deploy_git 文件夹下<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git rm -rf *</span><br><span class="line">git commit -m &apos;clean all file&apos;</span><br><span class="line">git push</span><br></pre></td></tr></table></figure></li></ul><h2 id="3-修改Hexo生成文件模版"><a href="#3-修改Hexo生成文件模版" class="headerlink" title="3 修改Hexo生成文件模版"></a>3 修改Hexo生成文件模版</h2><p>可在根目录 scaffolds 文件夹下修改3类文章模版</p><h2 id="4-添加创建文件后，用vscode自动打开脚本"><a href="#4-添加创建文件后，用vscode自动打开脚本" class="headerlink" title="4 添加创建文件后，用vscode自动打开脚本"></a>4 添加创建文件后，用vscode自动打开脚本</h2><p>在根目录下新建 scripts 文件夹，里面新建 js 文件 名字随意，代码如下：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> exec = <span class="built_in">require</span>(<span class="string">"child_process"</span>).exec;</span><br><span class="line"></span><br><span class="line">hexo.on(<span class="string">"new"</span>, <span class="function"><span class="keyword">function</span>(<span class="params">data</span>) </span>&#123;</span><br><span class="line">exec(<span class="string">"Code.exe "</span> + [data.path]);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><p>以后每次执行 hexo n 新建文件后都会自动运行 vscode 打开编辑</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;一、界面-篇&quot;&gt;&lt;a href=&quot;#一、界面-篇&quot; class=&quot;headerlink&quot; title=&quot;一、界面 篇&quot;&gt;&lt;/a&gt;一、界面 篇&lt;/h1&gt;&lt;h2 id=&quot;1-添加动态背景&quot;&gt;&lt;a href=&quot;#1-添加动态背景&quot; class=&quot;headerlink&quot; 
      
    
    </summary>
    
      <category term="hexo" scheme="http://yoursite.com/categories/hexo/"/>
    
    
  </entry>
  
  <entry>
    <title>MathJax数学公式语法</title>
    <link href="http://yoursite.com/2018/04/16/hexo/MathJax%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F%E8%AF%AD%E6%B3%95/"/>
    <id>http://yoursite.com/2018/04/16/hexo/MathJax数学公式语法/</id>
    <published>2018-04-15T16:00:00.000Z</published>
    <updated>2018-04-22T08:01:11.942Z</updated>
    
    <content type="html"><![CDATA[<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>在Markdown中输入数学公式需要LaTeX语法的支持。</p><h1 id="基本语法"><a href="#基本语法" class="headerlink" title="基本语法"></a>基本语法</h1><h2 id="呈现位置"><a href="#呈现位置" class="headerlink" title="呈现位置"></a>呈现位置</h2><ul><li><p>正文(inline)中的LaTeX公式用\$…$定义</p><ul><li>语句为<code>\sum_{i=0}^N\int_{a}^{b}g(t,i)\text{d}t</code></li><li>显示为 $\sum_{i=0}^N\int_{a}^{b}g(t,i)\text{d}t$</li></ul></li><li><p>单独显示(display)的LaTeX公式用\$\$…$$定义，此时公式居中并放大显示</p><ul><li><p>语句为<code>\sum_{i=0}^N\int_{a}^{b}g(t,i)\text{d}t</code></p></li><li><p>显示为</p><p>​                   <script type="math/tex">\sum_{i=0}^N\int_{a}^{b}g(t,i)\text{d}t</script></p></li></ul></li><li><p>下列描述语句中若非特别指出均省略\$…$</p></li></ul><h2 id="希腊字母"><a href="#希腊字母" class="headerlink" title="希腊字母"></a>希腊字母</h2><div class="table-container"><table><thead><tr><th>显示</th><th>命令</th><th>显示</th><th>命令</th></tr></thead><tbody><tr><td>α</td><td>\alpha</td><td>β</td><td>\beta</td></tr><tr><td>γ</td><td>\gamma</td><td>δ</td><td>\delta</td></tr><tr><td>ε</td><td>\epsilon</td><td>ζ</td><td>\zeta</td></tr><tr><td>η</td><td>\eta</td><td>θ</td><td>\theta</td></tr><tr><td>ι</td><td>\iota</td><td>κ</td><td>\kappa</td></tr><tr><td>λ</td><td>\lambda</td><td>μ</td><td>\mu</td></tr><tr><td>ν</td><td>\nu</td><td>ξ</td><td>\xi</td></tr><tr><td>π</td><td>\pi</td><td>ρ</td><td>\rho</td></tr><tr><td>σ</td><td>\sigma</td><td>τ</td><td>\tau</td></tr><tr><td>υ</td><td>\upsilon</td><td>φ</td><td>\phi</td></tr><tr><td>χ</td><td>\chi</td><td>ψ</td><td>\psi</td></tr><tr><td>ω</td><td>\omega</td><td></td></tr></tbody></table></div><p>- 若需要大写希腊字母，将命令首字母大写即可。 </p><ul><li><code>\Gamma</code>呈现为 $\Gamma$<br>- 若需要斜体希腊字母，将命令前加上<code>var</code>前缀即可。 </li><li><code>\varGamma</code>呈现为 $\varGamma$</li></ul><h2 id="字母修饰"><a href="#字母修饰" class="headerlink" title="字母修饰"></a>字母修饰</h2><h3 id="上下标"><a href="#上下标" class="headerlink" title="上下标"></a>上下标</h3><ul><li>上标：<code>^</code></li><li>下标：<code>_</code></li><li>举例：<code>C_n^2</code>呈现为 $C_n^2$</li></ul><h3 id="矢量"><a href="#矢量" class="headerlink" title="矢量"></a>矢量</h3><ul><li><code>\vec a</code>呈现为 $\vec a$</li><li><code>\overrightarrow{xy}</code>呈现为 $\overrightarrow{xy}$</li></ul><h3 id="字体"><a href="#字体" class="headerlink" title="字体"></a>字体</h3><ul><li>Typewriter：<code>\mathtt{A}</code>呈现为 $\mathtt{A}$<br>  $\mathtt{ABCDEFGHIJKLMNOPQRSTUVWXYZABCDEFGHIJKLMNOPQRSTUVWXYZ}$</li><li>Blackboard Bold：<code>\mathbb{A}</code>呈现为 $\mathbb{A}$<br>  $\mathbb{ABCDEFGHIJKLMNOPQRSTUVWXYZABCDEFGHIJKLMNOPQRSTUVWXYZ}$</li><li>Sans Serif：<code>\mathsf{A}</code>呈现为 $\mathsf{A}$<br>  $\mathsf{ABCDEFGHIJKLMNOPQRSTUVWXYZABCDEFGHIJKLMNOPQRSTUVWXYZ}$</li></ul><h2 id="分组"><a href="#分组" class="headerlink" title="分组"></a>分组</h2><ul><li>使用<code>{}</code>将具有相同等级的内容扩入其中，成组处理</li><li>举例：<code>10^{10}</code>呈现为 $10^{10}$，而<code>10^10</code>呈现为 $10^10$</li></ul><h2 id="括号"><a href="#括号" class="headerlink" title="括号"></a>括号</h2><ul><li>小括号：<code>()</code>呈现为()</li><li>中括号：<code>[]</code>呈现为[]</li><li>尖括号：<code>\langle,\rangle</code>呈现为⟨⟩<ul><li>此处为与分组符号<code>{}</code>相区别，使用转义字符<code>\</code></li></ul></li><li>使用<code>\left(</code>或<code>\right)</code>使符号大小与邻近的公式相适应；该语句适用于所有括号类型<ul><li><code>(\frac{x}{y})</code>呈现为$(\frac{x}{y})$</li><li>而<code>\left(\frac{x}{y}\right)</code>呈现为$\left(\frac{x}{y}\right)$</li></ul></li></ul><h2 id="求和、极限与积分"><a href="#求和、极限与积分" class="headerlink" title="求和、极限与积分"></a>求和、极限与积分</h2><ul><li><p>求和：<code>\sum</code></p><pre><code>举例：`\sum_{i=1}^n{a_i}`呈现为$\sum_{i=1}^n{a_i}$</code></pre></li><li><p>极限：<code>\lim_{x\to 0}</code>呈现为 $\lim_{x\to 0}$</p></li><li><p>积分：<code>\int</code></p><pre><code>举例：`\int_0^\infty{fxdx}`呈现为 $\int_0^\infty{fxdx}$</code></pre></li></ul><h2 id="分式与根式"><a href="#分式与根式" class="headerlink" title="分式与根式"></a>分式与根式</h2><ul><li>分式(fractions)：<code>\frac{公式1}{公式2}</code>呈现为 $\frac{a+b}{a-b}$</li><li>根式：<code>\sqrt[x]{y}</code>呈现为$\sqrt[x]{y}$</li></ul><h2 id="特殊函数"><a href="#特殊函数" class="headerlink" title="特殊函数"></a>特殊函数</h2><ul><li><code>\函数名</code></li><li>举例：<code>\sin x</code>，<code>\ln x</code>，<code>\max(A,B,C)</code>呈现为 $\sin x ,\ln x,  \max(A,B,C)$</li></ul><h2 id="特殊符号"><a href="#特殊符号" class="headerlink" title="特殊符号"></a>特殊符号</h2><div class="table-container"><table><thead><tr><th>显示</th><th>命令</th></tr></thead><tbody><tr><td>∞</td><td>\infty</td></tr><tr><td>∪</td><td>\cup</td></tr><tr><td>∩</td><td>\cap</td></tr><tr><td>⊂</td><td>\subset</td></tr><tr><td>⊆</td><td>\subseteq</td></tr><tr><td>⊃</td><td>\supset</td></tr><tr><td>∈</td><td>\in</td></tr><tr><td>∉</td><td>\notin</td></tr><tr><td>∅</td><td>\varnothing</td></tr><tr><td>∀</td><td>\forall</td></tr><tr><td>∃</td><td>\exists</td></tr><tr><td>¬</td><td>\lnot</td></tr><tr><td>∇</td><td>\nabla</td></tr><tr><td>∂</td><td>\partial</td></tr></tbody></table></div><h2 id="空格"><a href="#空格" class="headerlink" title="空格"></a>空格</h2><ul><li>LaTeX语法本身会忽略空格的存在</li><li>小空格：<code>a\ b</code>呈现为 $a\ b$</li><li>4格空格：<code>a\quad b</code>呈现为 $a\quad b$</li></ul><h1 id="矩阵"><a href="#矩阵" class="headerlink" title="矩阵"></a>矩阵</h1><h2 id="基本语法-1"><a href="#基本语法-1" class="headerlink" title="基本语法"></a>基本语法</h2><ul><li>起始标记<code>\begin{matrix}``，结束标记``\end{matrix}</code></li><li>每一行末尾标记<code>\\</code>，行间元素之间以<code>&amp;</code>分隔</li><li>举例</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$$\begin&#123;matrix&#125;</span><br><span class="line">1&amp;0&amp;0\\</span><br><span class="line">0&amp;1&amp;0\\</span><br><span class="line">0&amp;0&amp;1\\</span><br><span class="line">\end&#123;matrix&#125;$$</span><br></pre></td></tr></table></figure><p>呈现为 </p><p>​        <script type="math/tex">\begin{matrix}1&0&0\\0&1&0\\0&0&1\\\end{matrix}</script></p><h2 id="矩阵边框"><a href="#矩阵边框" class="headerlink" title="矩阵边框"></a>矩阵边框</h2><ul><li><p>在起始、结束标记处用下列词替换<code>matrix</code></p><ul><li><code>pmatrix</code>：小括号边框</li><li><code>bmatrix</code>：中括号边框</li><li><code>Bmatrix</code>：大括号边框</li><li><code>vmatrix</code>：单竖线边框</li><li><code>Vmatrix</code>：双竖线边框</li></ul></li></ul><h2 id="省略元素"><a href="#省略元素" class="headerlink" title="省略元素"></a>省略元素</h2><ul><li>横省略号：<code>\cdots</code></li><li>竖省略号：<code>\vdots</code></li><li>斜省略号：<code>\ddots</code></li><li>举例</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$$\begin&#123;bmatrix&#125;</span><br><span class="line">&#123;a_&#123;11&#125;&#125;&amp;&#123;a_&#123;12&#125;&#125;&amp;&#123;\cdots&#125;&amp;&#123;a_&#123;1n&#125;&#125;\\</span><br><span class="line">&#123;a_&#123;21&#125;&#125;&amp;&#123;a_&#123;22&#125;&#125;&amp;&#123;\cdots&#125;&amp;&#123;a_&#123;2n&#125;&#125;\\</span><br><span class="line">&#123;\vdots&#125;&amp;&#123;\vdots&#125;&amp;&#123;\ddots&#125;&amp;&#123;\vdots&#125;\\</span><br><span class="line">&#123;a_&#123;m1&#125;&#125;&amp;&#123;a_&#123;m2&#125;&#125;&amp;&#123;\cdots&#125;&amp;&#123;a_&#123;mn&#125;&#125;\\</span><br><span class="line">\end&#123;bmatrix&#125;$$</span><br></pre></td></tr></table></figure><p>呈现为 </p><script type="math/tex; mode=display">\begin{bmatrix}{a_{11}}&{a_{12}}&{\cdots}&{a_{1n}}\\{a_{21}}&{a_{22}}&{\cdots}&{a_{2n}}\\{\vdots}&{\vdots}&{\ddots}&{\vdots}\\{a_{m1}}&{a_{m2}}&{\cdots}&{a_{mn}}\\\end{bmatrix}</script><h2 id="阵列"><a href="#阵列" class="headerlink" title="阵列"></a>阵列</h2><ul><li><p>需要array环境：起始、结束处以<code>{array}</code>声明</p></li><li><p>对齐方式：在<code>{array}</code>后以<code>{}</code>逐行统一声明</p><ul><li>左对齐：<code>l</code>；居中：<code>c</code>；右对齐：<code>r</code></li><li>竖直线：在声明对齐方式时，插入<code>|</code>建立竖直线</li></ul></li><li><p>插入水平线：<code>\hline</code></p></li><li><p>举例</p></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$$\begin&#123;array&#125;&#123;c|lll&#125;</span><br><span class="line">&#123;↓&#125;&amp;&#123;a&#125;&amp;&#123;b&#125;&amp;&#123;c&#125;\\</span><br><span class="line">&#123;R_1&#125;&amp;&#123;c&#125;&amp;&#123;b&#125;&amp;&#123;a&#125;\\</span><br><span class="line">&#123;R_2&#125;&amp;&#123;b&#125;&amp;&#123;c&#125;&amp;&#123;c&#125;\\</span><br><span class="line">\end&#123;array&#125;$$</span><br></pre></td></tr></table></figure><p>呈现为 </p><script type="math/tex; mode=display">\begin{array}{c|lll}{↓}&{a}&{b}&{c}\\{R_1}&{c}&{b}&{a}\\{R_2}&{b}&{c}&{c}\\\end{array}</script><h2 id="方程组"><a href="#方程组" class="headerlink" title="方程组"></a>方程组</h2><ul><li>需要cases环境：起始、结束处以<code>{cases}</code>声明</li><li>举例</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$$\begin&#123;cases&#125;</span><br><span class="line">a_1x+b_1y+c_1z=d_1\\</span><br><span class="line">a_2x+b_2y+c_2z=d_2\\</span><br><span class="line">a_3x+b_3y+c_3z=d_3\\</span><br><span class="line">\end&#123;cases&#125;</span><br><span class="line">$$</span><br></pre></td></tr></table></figure><p>呈现为 </p><script type="math/tex; mode=display">\begin{cases}a_1x+b_1y+c_1z=d_1\\a_2x+b_2y+c_2z=d_2\\a_3x+b_3y+c_3z=d_3\\\end{cases}</script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class=&quot;headerlink&quot; title=&quot;概述&quot;&gt;&lt;/a&gt;概述&lt;/h1&gt;&lt;p&gt;在Markdown中输入数学公式需要LaTeX语法的支持。&lt;/p&gt;
&lt;h1 id=&quot;基本语法&quot;&gt;&lt;a href=&quot;#基本语法&quot; class=
      
    
    </summary>
    
      <category term="hexo" scheme="http://yoursite.com/categories/hexo/"/>
    
    
      <category term="MathJax" scheme="http://yoursite.com/tags/MathJax/"/>
    
  </entry>
  
</feed>
